[{"data":1,"prerenderedAt":284},["Reactive",2],{"search-api":3},[4,11,34,44,53,66,78,86,98,111,124,136,148,160,171,183,193,205,215,226,237,247,258,267,278],{"id":5,"path":6,"dir":7,"title":8,"description":7,"keywords":9,"body":10},"content:0.index.md","/","","Home",[],"     The best place to start your documentation.   Write pages in   Markdown , use   Vue  components and enjoy the power of   Nuxt .      +50 Components  ready to build rich pages   Docs  and   Page  layouts  Start from a   README , scale to a framework documentation  Navigation and Table of Contents generation  Fully configurable design system  Leverages    Typography  and    Elements  Used on   Content Documentation      What's included      Nuxt Architecture   Harness the full power of   Nuxt 3  and its   modules  ecosystem.    Nuxt Studio ready   Edit your theme content and appearance with live-preview within   Nuxt Studio .    Vue Components   Use built-in components (or your own!) inside your content.    Write Markdown   Enjoy the ease and simplicity of Markdown and discover   MDC syntax .    Deploy anywhere   Zero config on   Vercel  or   Netlify . Choose between static generation, on-demand rendering (Node) or edge-side rendering on   CloudFlare workers .    Extensible.   Customize the whole design, or add components using slots - you can make Docus your own.",{"id":12,"path":13,"dir":14,"title":15,"description":16,"keywords":17,"body":33},"content:1.api:1.components.md","/api/components","api","Components","Discover every component you can use in your content.",[18,19,20,21,22,23,24,25,26,27,28,29,30,31,32],"\u003CAlert />","\u003CBadge />","\u003CBlockHero />","\u003CButtonLink />","\u003CCallout />","\u003CCard />","\u003CCardGrid />","\u003CCodeGroup />","\u003CCodeBlock />","\u003CCopyButton />","\u003CIcon />","\u003CList />","\u003CSandbox />","\u003CTerminal />","\u003CVideoPlayer />","  Components  Discover every component you can use in your content.   \u003CAlert />     Check out an   info  alert with   code  and a   link .   Check out a   success  alert with   code  and a   link .   Check out a   warning  alert with   code  and a   link .   Check out a   danger  alert with   code  and a   link .     ::alert{type=\"info\"}\n   Check out an   **info**   alert with   `code`   and a [  link  ](  /  ).\n   ::\n   \n   ::alert{type=\"success\"}\n   Check out a   **success**   alert with   `code`   and a [  link  ](  /  ).\n   ::\n   \n   ::alert{type=\"warning\"}\n   Check out a   **warning**   alert with   `code`   and a [  link  ](  /  ).\n   ::\n   \n   ::alert{type=\"danger\"}\n   Check out a   **danger**   alert with   `code`   and a [  link  ](  /  ).\n   ::\n     \u003CBadge />   \u003CBadge />  support same types as   \u003CAlert /> .     v1.2  Deprecated   Not found!     :badge[  v1.2  ]\n   \n   :badge[  Deprecated  ]{type=\"warning\"}\n   \n   ::badge{type=\"danger\"}\n   Not found!\n   ::\n     \u003CBlockHero />      Document-driven framework   Docus reconciles content creators and developers by offering to both the best tools to create and scale content-based websites.     ::block-hero\n   ---\n   cta:\n     -   Get started\n     -   /get-started\n   secondary:\n     -   Open on GitHub →\n     -   https://github.com/nuxtlabs/docus\n   snippet: npx nuxi@latest init docus-app -t nuxtlabs/docus-starter\n   ---\n   #title\n   Document-driven framework\n   \n   #description\n   Docus reconciles content creators and developers by offering to both the best tools to create and scale content-based websites.\n   ::\n     \u003CButtonLink />    Play on StackBlitz     :button-link[Play on StackBlitz]{icon=\"IconStackBlitz\" href=\"https://stackblitz.com/github/nuxtlabs/docus-starter\" blank}\n     \u003CCallout />   \u003CCallout />  support same types as   \u003CAlert /> .      This is a callout! Click me to open.   This is the content of the callout.    This is a callout! Click me to open.   This is the content of the callout.     ::callout\n   #summary\n   This is a callout! Click me to open.\n   \n   #content\n   This is the content of the callout.\n   ::\n    \n   ::callout{type=\"warning\"}\n   #summary\n   This is a callout! Click me to open.\n   \n   #content\n   This is the content of the callout.\n   ::\n     \u003CCard />      Nuxt Architecture.   Based on   Nuxt 3  and   Nuxt Content .   \nUse Nuxt to build a static site, or a serverless app.      ::card{icon=\"logos:nuxt-icon\"}\n    #title\n    Nuxt Architecture.\n    #description\n    Based on   **Nuxt 3**   and   **Nuxt Content**  . :br\n    Use Nuxt to build a static site, or a serverless app.\n    ::\n     \u003CCardGrid />      What's included?      Nuxt Architecture.   Harness the full power of Nuxt and the Nuxt ecosystem.    Vue Components.   Use built-in components (or your own!) inside your content.    Write Markdown.   Enjoy the ease and simplicity of Markdown and discover MDC syntax.     ::card-grid\n   #title\n   What's included\n   \n   #root\n   :ellipsis\n   \n   #default\n     ::card\n     #title\n     Nuxt Architecture.\n     #description\n     Harness the full power of Nuxt and the Nuxt ecosystem.\n     ::\n     ::card\n     #title\n     Vue Components.\n     #description\n     Use built-in components (or your own!) inside your content.\n     ::\n     ::card\n     #title\n     Write Markdown.\n     #description\n     Enjoy the ease and simplicity of Markdown and discover MDC syntax.\n     ::\n   ::\n     \u003CCodeGroup />  This component uses   slots  to create a tab panel of your code examples or preview.        yarn   add   docus\n     npm   install   docus\n     ::code-group\n     ```bash [Yarn]\n     yarn   add   docus\n     ```\n     ```bash [NPM]\n     npm   install   docus\n     ```\n   ::\n     \u003CCodeBlock />  To be used inside a   \u003CCodeGroup />  component to display a preview of some rendered code.     Hello World!     /* Added as a child of   `\u003CCodeGroup />`   */\n   \n   ::code-block{label=\"Preview\" preview}\n     ::badge\n     Hello World!\n     ::\n   ::\n     \u003CCopyButton />        :copy-button{content=\"hey!\"}\n     \u003CIcon />  Icon component gives you access to all   100,000+  icons from   icones.js.org .          :icon{name=\"logos:nuxt-icon\"}\n   :icon{name=\"logos:vue\"}\n   :icon{name=\"logos:nuxt-icon\"}\n     \u003CList />       Important  Always    Amazing  Congrats    Do you know?  You can also do this    Be careful  Use with precautions    Drinking too much  Driving drunk     ::list{type=\"primary\"}\n   -   **Important**\n   -   Always\n   ::\n   \n   ::list{type=\"success\"}\n   -   Amazing\n   -   Congrats\n   ::\n   \n   ::list{type=\"info\"}\n   -   Do you know?\n   -   You can also do this\n   ::\n   \n   ::list{type=\"warning\"}\n   -   Be careful\n   -   Use with precautions\n   ::\n   \n   ::list{type=\"danger\"}\n   -   Drinking too much\n   -   Driving drunk\n   ::\n    \u003CSandbox />  Embed CodeSandbox/StackBlitz easily in your documentation with great performances.  Using the   IntersectionObserver  to load when visible in the viewport.        :sandbox{src=\"https://codesandbox.io/embed/nuxt-content-l164h?hidenavigation=1&theme=dark\"}\n     \u003CTerminal />        :terminal{content=\"nuxi build\"}\n     \u003CVideoPlayer />         ::div\n     :video-player{src=\"https://www.youtube.com/watch?v=o9e12WbKrd8\"}\n   ::\n   html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":35,"path":36,"dir":14,"title":37,"description":38,"keywords":39,"body":43},"content:1.api:2.composables.md","/api/composables","Composables","Discover the Docus composables to use in your custom Vue components and pages.",[40,41,42],"useDocus()","useMenu()","useScrollspy()","  Composables  Discover the Docus composables to use in your custom Vue components and pages.   useDocus()    useDocus  ()\n  gives access to docus runtime config, all default values and your custom config from   app.config.ts    config  refers to the merged config of the current page.   main ,   header ,   aside ,   footer  and   titleTemplate  can be set from   _dir.yml  and any   page.md  file.  The configs in   app.config  file will be used as defaults.     \u003C  script   setup  >\n   const   {   config   }   =   useDocus  ()\n   \u003C/  script  >\n   \n   \u003C  template  >\n     \u003C  div  >\n       \u003C  h1  >{{ config.title }}\u003C/  h1  >\n       \u003C  p  >{{ config.description }}\u003C/  p  >\n     \u003C/  div  >\n   \u003C/  template  >\n    tree  refers to the current navigation tree that is displayed in the   aside  component.     \u003C  script   setup  >\n   const   {   tree   }   =   useDocus  ()\n   \u003C/  script  >\n   \n   \u003C  template  >\n     \u003C  DocsAsideTree   :links  =  \"tree\"   />\n   \u003C/  template  >\n    useMenu()   useMenu()  gives access to   $menu  plugin controlling mobile navigation globally.     const   {\n     // Is menu visible\n     visible  ,\n     // Close menu function\n     close  ,\n     // Open menu function\n     open  ,\n     // Toggle menu function\n     toggle\n   }   =   useMenu  ()\n    useScrollspy()   useScrollspy()  is used in   docs  layout to make the ToC display the currently visible headings.     const   {\n     // Headings on the page\n     visibleHeadings  ,\n     // Active headings (for the current page)\n     activeHeadings  ,\n     // Update headings (an array of DOM nodes)\n     updateHeadings\n   }   =   useScrollspy  ()\n   html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":45,"path":46,"dir":14,"title":47,"description":48,"keywords":49,"body":52},"content:1.api:3.layouts.md","/api/layouts","Layouts","Docus provides multiple built-in layouts for displaying your Markdown pages.",[50,51],"default","page","  Layouts  Docus provides multiple built-in layouts for displaying your Markdown pages.   default  The default layout for every page created in the project. This layout renders multiple section alongside the content:   Aside navigation menu (togglable with   aside: false/true )  Page bottom section (togglable with   bottom: false/true )  Table of content (togglable with   toc: false/true )     ---\n   aside  :   true\n   bottom  :   true\n   toc  :   false\n   ---\n   \n   Your awesome content\n  Current page is live sample of default layout.   page   page  layout is content focused layout. This layout does not render aside menu of table of contents.  This layout accept some configuration from content front-matter.    fluid : By setting   fluid: true  in content front-matter the content will be rendered in full width.   constrainedClass : Using this option you can modify layout container look. Like constraining layout width of changing the background.   padded : Setting   padded: true  in front-matter will add horizontal padding in the layout.     ---\n   title  :   Home\n   layout  :   page\n   fluid  :   true\n   ---\n  Check   Home page  as live sample of page layout  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":54,"path":55,"dir":56,"title":57,"description":57,"keywords":58,"body":65},"content:3.web-api:chapter2.md","/web-api/chapter2","web-api","第2章 EndPoint設計與請求形式",[59,60,61,62,63,64],"2.1 設計通過API公開的功能","2.2 API EndPoint的設計思想","2.3 HTTP方法和EndPoint","2.4 API端點的設計","2.5 搜尋與查詢參數的設計","關於登錄OAuth2.0 (2.6 ~ 2.10)","  2.1 設計通過API公開的功能  SNS在線服務功能   使用者註冊  登入  獲取自己的資訊  更新自己的資訊  取得使用者資訊  搜尋使用者  添加好友  刪除好友  取得好友列表  搜尋好友  發送消息  取得好友的訊息  編輯訊息  刪除訊息  好友動態列表  特定用的動態列表  發表動態訊息  編輯動態訊息  刪除動態訊息  2.2 API EndPoint的設計思想  EndPoint的基本設計  怎麼設計一個優秀的URI，有一個重要的原則   容易記憶，URI包含的功能一目了然  💡  容易記憶的原則如下   短小便於輸入的URI  人可以讀懂的URI  沒有大小寫混用的URI  修改方便的URI  不會曝露伺服器架構的URI  規則統一的URI   短小便於輸入的URI  💀 反例     http://api.example.com/service/api/search\n  💡 正例     http://api.example.com/search\n  ✅ 結論   將URI使用短小、簡單的方式進行表達，更易於理解和記憶。  人可以讀懂的URI  💀 反例     http://api.example.com/sv/u\n  💡 正例     http://api.example.com/products/12345\n  📦 補充  API的設計查詢時，該使用  search 還是  find 詞彙?  通常使用  search 來表示，  search 表示在某個地方尋找，而  find 則是尋找某個特定物品。  ✅ 結論   盡量少用縮寫，適當的使用完整的英文單字來表示。  沒有大小寫混用的URI  💀 反例     http://api.example.com/Users/12345\n   http://example.com/API/getUserName\n  💡 正例     http://api.example.com/users/12345\n  📦 補充  如果遇到兩種大小寫的URI進行混用時，應該如何進行處理?     http://example.com/USERS/12345\n   http://example.com/users/12345\n  在普通的Web網站下，如果採用了不論大小寫都會返回相同的結果會出現一種問題，會導致Google等搜尋引    擎會認為有多個頁面返回了相同的結果而導致網站排名進行下降。  參考下列服務，當遇到大寫字母的URI時，會自動返回404     在線服務  處理混有大寫字母的URL    Foursqare  出錯404   Github  出錯404   Tumblr  出錯404  ✅ 結論   盡量不要使用大小寫字母混用會造成API難以理解，一般標準的做法是，統一使用小寫的URI。  修改方便的URI  修改方便在英語文語意為  Hackable 。修改方便的URI指的是能將某個URI非常容易修改為另外一個URI。    通常應用在獲取某種商品。  💀 反例  按照資料庫的資料表進行結構區分，例如: 1 ~ 300000儲存到alpha資表表內。     # ID的範圍 1 ~ 300000\n   http://api.example.com/v1/items/alpha/:id\n   \n   # ID的範圍 400001 ~ 500000\n   http://api.example.com/v1/items/beta/:id\n   \n   # ID的範圍 500001 ~ 700000\n   http://api.example.com/v1/items/gamma/:id\n   \n   # ID的範圍 700001 ~\n   http://api.example.com/v1/items/delta/:id\n  💡 正例     http://api.example.com/v1/items/123456\n  ✅ 結論   盡量讓URI的延展性佳(這邊指的是/items/{id})，可以藉由輸入不同的編號，來修改URI，而不是必須    要去猜測。  不會曝露伺服器架構的URI  💀 反例     http://api.example.com/cgi-bin/get_user.php?user  =100\n  💡 正例     http://api.example.com/user/100\n  ✅ 結論   不要將無意義的資訊暴露出來。例如:    cgi-bin ，可以猜測你可能是使用CGI的方式運行。   get_user.php ，可以猜測你可能是使用php進行撰寫。  規則統一的URI  💀 反例     # 獲取好友資訊\n   http://api.example.com/friends?id  =100\n   \n   # 發送好友資訊\n   http://api.example.com/friend/100/message\n  💡 正例     # 獲取好友資訊\n   http://api.example.com/friends/100\n   \n   # 發送好友資訊\n   http://api.example.com/friends/100/message\n  ✅ 結論   統一URI的設計，讓使用者易於理解。  2.3 HTTP方法和EndPoint     方法名稱  說明    GET  獲取資源   POST  新增資源   PUT  更新已有資源   DELETE  刪除資源   PATCH  更新部分資源   HEAD  獲取資源的Metadata資訊   Metedata為描述資料的資料，舉例：描述HTML5這份文件的資料。   \nMetedata不會呈現在畫面上，只會給瀏覽器和搜尋引擎查看。    https://ithelp.ithome.com.tw/articles/10237545     2.4 API端點的設計     目的  EndPoint  方法  其他相同    使用者註冊   http://api.example.com/v1/users       http://api.example.com/v1/auth/sign       http://api.example.com/v1/auth/register  POST  其他相同   登入   http://api.example.com/v1/auth/login  POST    獲取自己的資訊   http://api.example.com/v1/users/me       http://api.example.com/v1/auth/me  GET    更新自己的資訊   http://api.example.com/v1/users/me       http://api.example.com/v1/auth/me  PUT    取得使用者資訊   http://api.example.com/v1/users/:id       http://api.example.com/v1/users/{id}  GET  搜尋使用者   取得使用者列表   http://api.example.com/v1/users  GET    取得好友列表   http://api.example.com/v1/users/:id/friends  GET    添加好友   http://api.example.com/v1/users/:id/friends  POST    刪除好友   http://api.example.com/v1/users/:id/friends/:id  DELETE    搜尋好友   http://api.example.com/v1/users/:id/friends/:id  GET    發送消息   http://api.example.com/v1/friends/:id/message  POST    取得好友的訊息   http://api.example.com/v1/friends/:id  GET    編輯訊息   http://api.example.com/v1/friends/:id  PUT    刪除訊息   http://api.example.com/v1/friends/:id  DELETE    好友動態列表   http://api.example.com/v1/users/:id/friends/updates  GET    取得特定使用者的動態訊息   http://api.example.com/v1/users/:id/updates  GET    發表動態訊息   http://api.example.com/v1/updates  POST    編輯動態訊息   http://api.example.com/v1/updates/:id  PUT    刪除動態訊息   http://api.example.com/v1/updates/:id  DELETE     :id 為佔位符號  2.4.1 訪問資源的EndPoint設計的注意事項   使用名詞的複數形式    URI 表示資源的集合   HTTP 方法表示一般動詞  注意所用的單字  \n例如:   search 和  find 兩者中，該選用哪種比較好?   API一般設計採用  search  可以從👇網站查看各種API範例\n  ProgrammableWeb  不使用空格以及需要編碼的字串  \n當URI裡存在無法直接使用的字串時，則需要使用到百分號編碼（英語：Percent-encoding），又稱：URL編碼（  URL encoding ）。\n例如：   %E3%81%82 。  4️. 使用連接符來連接多個單字，基本上連接字串的方式總共有三種寫法。   S  pinal-Case寫法  一般稱為脊柱形命名法。   http://api.example.com/v1/users/12345/profile-image\n  Snake Case  寫法  一般稱為蛇型命名法。   http://api.example.com/v1/users/12345/profile_image\n  Camel Case寫法  一般稱為駝峰命名法。   http://api.example.com/v1/users/12345/profileImage\n     \n  💡 這三種寫法中，網路上最推薦Spinal-Case的方法，其中一個原因是因為Google推薦使用。  另外最好在URI中使用多個單字，例如不要使用  popular_users ，而是使用  users/popular 用路徑那樣子來劃分。  2.5 搜尋與查詢參數的設計  2.5.1 獲取資料量和獲取位置的查詢參數  當資料量很龐大的時候，例如 👇 使用者資料列表API，如果今天是FB等級的使用者，那可能有好幾億，這樣一次把所有數值吐回來是不可能達成的，因此可以採用分頁(Pagination)來處理。   http://api.example.com/v1/users\n   分頁的使用，一般可以透過SQL中  limit 和  offset 數值來產生。   各大服務查詢的方式\n   資料量 使用  limit 、  count 、  per_page  資料位置 使用  page 、  offset 、  cursor     一般來說   per_page  和  page 會一起出現，而  limit 和  offset 會成對出現。   分頁的舉例\n1頁可以容納50條紀錄，當要取第三頁(從101開始)的資料時，該怎麼撰寫呢?   per_page=50&page=3\n\nlimit=50&offset=100\n   💡 一般  page 從1開始(1-based)計數，而  offset 則從0開始(0-based)計數。  2.5.2 使用相對位置存在的問題  當使用  offset 或  limit 來取得指定的資料位置時，其實都是要從頭開始數第幾條，每次都要從第1條資料開始計數，因此效能較差。   從頭開始計數\n   當資料更新的頻率比較高的時候，會導致當前獲取資料出現一定的偏差。\n   2.5.3 使用絕對位置來取得資料  可以透過指\"定某個ID之前\"或\"某個日期之前\"等條件，來解決相對應位置取得資料的問題。  例如：Twiiter的API中的  max_id 、YouTube中的  publishedBefore 。  2.5.4 使用參數來過濾  以下例子使用Linkedin的People Search API舉例。   http://api.linkedin.com/v1/people-search?first-name=Clair\n\nhttp://api.linkedin.com/v1/people-search?last-name=Clair\n\nhttp://api.linkedin.com/v1/people-search?school-name=Shermer&20High%20School\n  2.5.5 查詢參數和路徑的使用區別  到底該把參數附加在查詢參數裡面? 還是放在路徑裡呢? 可以依據下列兩點來解釋   是否可以表示唯一資源所需的資訊   http://api.example.com/v1/users/10\n   是否可以省略  分頁的額外補充   請求\n    perPage  每個頁面的大小(每個頁面的項目)   page  目前頁面的編號   http://api.example.com/v1/users?page=3&perPage=50\n   回應\n    currentPage  目前頁面的編號   pageSize  每個頁面的大小(每個頁面的項目)   totalPages  頁面總數量   totalItems   項目的總數量   items  目前頁面上的項目  關於登錄OAuth2.0 (2.6 ~ 2.10)  OAuth在API設計上是蠻重要的一環，你一定很常遇到在使用某個網頁時，他會想要你Google或是Facebook的資料，此時頁面會導向一個小視窗要你輸入Google或Facebook的帳號密碼，輸入完畢後接著就會導回原本的網頁。接著網頁就可以獲取你Google與FB的相關資訊了。這種B網頁要向你索取第三方網頁的認證工作，就是OAuth會替你處理掉。  2.6.   陽春認證  上述描述的認證工作，最簡易的認證機制如下圖，使用者在客戶端透過基本的帳號與密碼向後端伺服器驗證身份。伺服器會經過一連串的驗證流程，驗證成功後透過如 Session / Cookie 機制，在客戶端保存用戶登入的狀態資訊。    此陽春認證大致會有幾個問題   第三方程式必須儲存 Resource Owner 的帳號密碼，通常是明文儲存。  Server 必須支援密碼認證，即使密碼有天生的資訊安全上的弱點。  第三方程式會得到幾乎完整的權限，可以存取 Protected Resources ，而 Resource Owner 沒辦法限制第三方程式可以拿取 Resource 的時效，以及可以存取的範圍 (subset)。  任何第三方程式被破解 (compromized)，就會導致使用該密碼的所有資料被破解。  2.7 OAuth的基本認證機制  那麼OAuth在第三方認證這流程上，中間到底發生什麼事情，我們可以看下述圖意流程     Step1：User點下允許訪位Facebook個人資訊認證  Step2：第三方網頁請求認可  Step3：User輸入帳命並告知Facebook可以把Token轉交給第三方網頁  Step4：將Token轉交給第三方網頁  Step5：第三方網頁帶取Token向Facebook調用索取資訊API  Step6：Facebook Response請求給第三方網頁  上述OAuth常見的基本流程，使用OAuth方便的是，User無須再次對請求輸入帳號密碼，認證過程中會通過Facebook提供的頁面(一般常見為帳號密碼輸入或是認證許可按鈕如下圖)。    如果OAuth訪問成功就可從Facebook獲取access token，通過此token，第三方網頁就可訪問Facebook用戶允許的相關訊息(public profile mail 介紹...)。  2.8 OAuth 2.0 的角色定義   Resource Owner：可以授權別人去存取 Protected Resource 。如果這個角色是人類的話，則就是指使用者 (end-user)。  Resource Server：存放 Protected Resource 的伺服器，可以根據 Access Token 來接受 Protected Resource 的請求。  Client：代表 Resource Owner 去存取 Protected Resource 的應用程式。 “Client” 一詞並不指任何特定的實作方式（可以在 Server 上面跑、在一般電腦上跑、或是在其他的設備）。  Authorization Server：在認證過 Resource Owner 並且 Resource Owner 許可之後，核發 Access Token 的伺服器。  2.9 OAuth的認證流程形式(Grant Type)  上述簡單描述OAuth基本流程，但實際的認證流程會有四種形式，推薦此篇  認識 OAuth 2.0：一次了解各角色、各類型流程的差異 。對於四種形式我覺得此篇作者整理得很淺白易懂。這邊我也會直接擷取他對於四種形式的描述來解說。     Type  常見應用    Authorization Code  有透過Server處理   Implicit  Clinet端處理   Resource Owner Password Credentials    Client Credentials  M2M(Machine to Machine)  2.10   Authorization Code  流程示意  常見類型，通常應用在SSR伺服器渲染的設計上，大部分的邏輯處理程式碼以極機密都會保存在Server。    詳細流程  (1) Authorization Request  【Client】GET -> 【Authorization Endpoint】  第一步是 Client 產生一個 URL 連到 Authorization Endpoint ，要 Resource Owner 打開（點擊）這個 URL ，從而產生「向 Authorization Endpoint 發送 GET request」的操作。  把參數包在 URI 的 query components 裡面。     參數名  填什麼/意義    response_type  code   client_id  自己的 Client ID   state  內部狀態   redirect_uri  申請結果下來之後要轉址去哪裡   scope  申請的存取範圍   GET /authorize?response_type=code&client_id=s6BhdRkqt3&state=xyz\n    &redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n   (4) Authorization Response  【Authorization Endpoint】 302 Response ->  GET 【Client: Redirection Endpoint】  Resource Owner 若同意授權，這個「同意授權」的 request 會往 Authorization Endpoint 發送，接著會收到 302 的轉址 response ，裡面帶有「前往 Client 的 Redirection Endpoint 的 URL」的轉址 (Location header)，從而產生「向 Redirection URI 發送 GET Request」的操作。     參數名  填什麼/意義    code  Authorization Code   state  原內部狀態   HTTP/1.1 302 Found\nLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA\n          &state=xyz\n   state 如果 (1) 的時候有附上，則 Resopnse 裡面必須有，完全一致的原值。如果原本就沒有，就不需要回傳。  Authorization Code：   必須是短時效的，建議最長 10 分鐘。  Client 只能使用一次，如果重複使用，Authorization Server 必須拒絕，並且建議撤銷之前透過這個 Grant 核發過的 Tokens  要綁定 Code ↔ Client ID ↔ Redirection URI 的關係  長度由 Authorization Server 定義，應寫在文件中， Client 不可以瞎猜。   (5) Access Token Request  【Client】POST -> 【Token Endpoint】     參數名  填什麼/意義    grant_type  Authorization Code   code  在 (4) 拿到的 Authorization Code   redirect_uri  如果 (A) 有提供，則必須提供一模一樣的。   client_id  自己的 Client ID  Authorization Server 的處理程序   要求 Client 認證自己（如果是 Confidential Client 或有拿到 Client Credentials）  如果 Client 有出示認證資料，就認證它  確定 Authorization Code 是發給 Client 的\n   Confidential: 用 Client 的認證過程來證明  Public: 用 Client ID 來證明  驗證 Authorization Code 正確  如果 (1) 有給 Redirection URI 的話，確定這次給的 Redirection URI 與 (1) 時的一模一樣。   POST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=authorization_code&code=SplxlOBeZQQYbYS6WxSbIA\n&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb\n  (5) Access Token Response  【Client】 \u003C- 【Token Endpoint】  若 Access Token Request 合法且有經過授權，則核發 Access Token，同時可以核發 Refresh Token （非必備）。如果 Client 認證失敗，或 Request 不合法，則依照   RFC 6749 Section 5.2  的規定回覆錯誤。   HTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n  \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n  \"token_type\":\"example\",\n  \"expires_in\":3600,\n  \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n  \"example_parameter\":\"example_value\"\n}\n   Implicit  流程示意  通常應用在SPA設計，整個應用程式都在前端運行，依需求向後端 API 取得資料。由於整個應用程式都在前端運行，所以會缺少「後端伺服器透過 Authorization Code Grant 交換 Access Token 」的步驟。取而代之的是請 Authorization Server 直接核發 Access Token。  這邊要注意最終應用程式就能拿著 Access Token 向 Resource Server 取得資料。特別留意：不像 Authorization Code Flow，這邊是由前端獲得與管理 Access Token，並帶著 Access Token 發出請求前往取得資源，因此在安全性上「相對脆弱」。    詳細流程  (1) Authorization Request  【Client】GET ->【Authorization Endpoint】  第一步是 Client 產生一個 URL 連到 Authorization Endpoint ，要 Resource Owner 打開（點擊）這個 URL ，從而產生「向 Authorization Endpoint 發送 GET request」的操作。  把參數包在 URI 的 query component 裡面。     參數名  填什麼/意義    response_type  code   client_id  自己的 Client ID   state  內部狀態   redirect_uri  申請結果下來之後要轉址去哪裡   scope  申請的存取範圍  Authorization Server 的處理程序  因為 Implicit Grant Flow 是直接在 Authorization Endpoint 發 Access Token ，所以資料驗證和授權都在這一步處理。所以這個 Request 進來的時候， Authorization Server 要做這些事：  驗證所有必須給的參數都有給且合法  Redirection URI 與預先在 Authorization Server 設定的相符。\n如果沒問題，就詢問 Resource Owner 是否授權，即 (B) 步驟  (4) Authorization Response  【Client】 \u003C- 302【Authorization Endpoint】  Resource Owner 若同意授權，這個「同意授權」的 request 會往 Authorization Endpoint 發送，接著會收到 302 的轉址 response ，裡面帶有「前往 Client 的 Redirection Endpoint 的 URL」的轉址 (Location header)，從而產生「向 Redirection URI 發送 GET Request」的操作。  參數要用 URL Encoding 編起來，放在 Fragment Component 裡面。  若 Access Token Request 合法且有經過授權，則核發 Access Token。如果 Client 認證失敗，或 Request 不合法，則依照 Section 5.2 的規定回覆錯誤。  特別注意 Implicit Grant Type 禁止 核發 Refresh Token。  某些 User-Agent 不支援 Fragment Redirection ，這種情況可以使用間接轉址，即是轉到一個頁面，放一個 “Continue” 的按鈕，按下去連到真正的 Redirection URI 。     參數名  填什麼/意義    access_token  即 Access Token   expires_in  建議有\t幾秒過期，如 3600 表示 10 分鐘。若要省略，最好在文件裡註明效期。   scope  Access Token 的授權範圍 (scopes)。   state  原內部狀態。  其中 scope 如果和 (1) 申請的不同則要附上，如果一樣的話就不必附上。  其中 state 如果 (1) 的時候有附上，則 Resopnse 裡面必須有，完全一致的原值。如果原本就沒有，就不需要回傳。  Access Token 的長度由 Authorization Server 定義，應寫在文件中， Client 不可以瞎猜。  Client 遇到不認識的參數必須忽略。   HTTP/1.1 302 Found\nLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA\n          &state=xyz&token_type=example&expires_in=3600\n   Resource Owner Password Credentials  流程示意  由使用者提供帳號與密碼等資訊給應用程式，由應用程式直接向 Authorization Server 交換 Access Token，因此「必須是使用者高度信賴的應用程式」才適合使用，且唯有前兩種皆不可行時，才會考慮使用當前類型的流程。  體驗上和以往的帳號密碼登入雷同。    流程細節  (2,3) Authorization Request & Response  在這個流程裡面， Authorization Grant 就是 Resource Owner 的帳號密碼，所以在 Step (A) 裡面直接向 Resource Onwer 索取，沒有經過網路來取得 Authorization。  Spec 不規定 Client 要怎麼拿到帳號密碼，但是 Client 取得 Access Token 之後，必須把 Resource Owner 的帳號密碼給銷毀掉。  (4) Access Token Request  【Client】POST -> 【Token Endpoint】     參數名  填什麼/意義    grant_type  password   username  Resource Owner 的帳號   password  Resource Owner 的密碼   scope  申請的存取範圍  Authorization Server 的處理程序  這個 Request 進來的時候， Authorization Server 要做這些事：  要求 Client 認證自己（如果是 Confidential Client 或有拿到 Client Credentials）  如果 Client 有出示認證資料，就認證它   Client Credentials  流程示意  通常是由應用程式向 Authourization Server 請求取得 Access Token 以獲取「自己」的相關資源，而非使用者的資源。  這個流程已經跳脫使用者，因此，使用者身份驗證的流程將不再需要。取而代之的，是應用程式必須向 Authorization Server 提供驗證所需的自身資訊。    流程細節  (1) Access Token Request  【Client】POST -> 【Token Endpoint】     參數名  填什麼/意義    grant_type  password   scope  申請的存取範圍   POST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=client_credentials\n  (2) Access Token Response  【Client】POST \u003C- 【Token Endpoint】  若 Access Token Request 合法且有經過授權，則核發 Access Token，但是最好不要核發 Refresh Token。如果 Client 認證失敗，或 Request 不合法，則依照的  RFC6749規定(Section5.2) 回覆錯誤。   HTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n  \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n  \"token_type\":\"example\",\n  \"expires_in\":3600,\n  \"example_parameter\":\"example_value\"\n}\n  簡易整理    d.OAuth端點範例  上述探討完四種認證流程形式，那實際使用OAuth時，端點的形式該如何設計?下述為常見的幾個有名的網站    書中筆者比較建議的方式是像  /oauth2/token 此種方式去設計，因為明確指出使用的是OAuth2.0，並且與RFC 6749給出的範例雷同。  我們稍微看一下實際medium在索取facebook認證資訊時的內容如下圖，基本上也是照這邏輯下去設計     OAuth2.0   OAuth 2.0 筆記  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":67,"path":68,"dir":56,"title":69,"description":69,"keywords":70,"body":77},"content:3.web-api:chapter5.md","/web-api/chapter5","第5章 開發方便更改設計的API",[71,72,73,74,75,76],"5.1 方便更改設計的重要性","5.2 透過版本訊息來管理API","5.3 版本變更的方針","5.4 終止提供API","5.5 編排層(中間層)","5.6小結","  5.1 方便更改設計的重要性   API必須保持公開提供串接的狀態，但是我們會需要添加新功能、廢棄某些功能  如果只是修改API內部邏輯，對外的數據格式不變，則不需要更新API設計規範  5.1.1 公開發佈的API   LSUD(Large set of unknown developers)\n   ex.FB這類的公開API  影響不特定開發者，範圍未知  API改版的影響程度大  無法保證用戶端可以搭配API改版而重新串接，此時強制變更API會導致終端用戶、串接應用，覺得這個服務不可靠  5.1.2 面向移動應用的API   SSKD(Small set of known develop)\n   只有影響特定開發者，範圍可控  API的改版影響程度小  注意不更新應用程式的刁民  5.1.3 Web服務中使用的API   注意快取的影響  5.2 透過版本訊息來管理API   更新API有會不等程度的影響，透過某些機制讓不更新用戶可以繼續使用舊的服務，更新後的用戶使用新的服務    實現的方式   不同的URI\n   舊的：  http://api.example.com/user/123  新的：  http://newapi.example.com/user/123  議題：new的命名不好，如果之後又要改版，newnewapi?  5.2.1 在URI中嵌入版本編號    http://api.example.com/v2/user/123  最常見的方式，舊版本的api短時間能可繼續使用    5.2.2 如何添加版本編號   編號規則：主版本編號、次版本編號、補丁版本編號。ex.1.0.1  如果只是修正BUG，則增加補丁版本編號ex.1.0.2  如果功能新、刪，且向下兼容，則增加次版本編號ex.1.1.1  如果本次修改無法向下兼容，則增加主版本編號ex.2.0.1  以  http://api.example.com/v1/user/123來說，只使用一個版本編號，代表為主版本編號，因此當主版本編號增加時，API才進行版本升級  同時維護多版本的API成本相當高，也容易讓用戶混淆該用哪一個，因此小更動會盡量不去升級api版本，而是盡可能地向下相容  只有發生可以放棄下向相容的重大更新時才去升級api版本，因此大部分的api的網址版本編號只有主版本編號ex./v1  5.2.3 在查詢字串加入版本訊息    http://api.example.com/user/123?v=1.5  差異：使用參數的方式代表是可以省略，如果沒有填，伺服器會直接使用默認的版本(通常是最新版本)  該選擇加在網址路徑還是參數？\n   建議加在網址路徑，因為參數的方式如果省略的話，用戶其實不知道呼叫到的是哪個版本  5.2.4 透過媒體類型來指定版本訊息   在header加入Accept:application/api.example.v2+json  好處：URL可以作為純粹的資源使用  5.2.5 該採用什麼方法   最常用的是在URL的路徑中嵌入版本訊息  5.3 版本變更的方針   盡可能向下相容  ex.原本使用gender(Int)1=男生2=女生，如果想要改為gender(String)男生、女生的方式紀錄，則建議多一個參數genderStr(String)，並把gender標示為廢棄  什麼時候該升級版本\n   權限、驗證機制調整，ex.v1沒有身份驗證機制，v2有身份驗證機制，則可以廢棄v1升級到v2  因為這類的調整會動到的地方太多，難達成向下相容，因此該升級版本  5.4 終止提供API   公告讓用戶知道該升級，舊API什麼時候結束服務，用戶可以規劃系統升級的時程  Blackout Test：暫時一段時間不提供服務，逼迫用戶提早升級  5.4.2 正式停止舊API   回傳http status 410，同時給予錯誤訊息  應用服務必須針對410的錯誤提示用戶該升級系統  5.4.3 在使用條款中寫明支援期限   在X個月後，不再支援舊版api，但不是直接關閉服務  新的API出來的時候，同時宣布至少支援X月  5.5 編排層(中間層)   ex.fb graph api，源頭端的API可以負責叫小範圍，就像是單一個積木，減少開發的複雜性  終端透過中間層去組裝多個積木來達成頁面的需求  終端可以受到API改版的影響較小，源頭端可以減少API變更的阻礙    5.6小結   最大限度減少API版本更新的頻率，注意向下兼容  在URI中嵌入API版本的主版本編號  停止提供API服務時不能立即中止，至少需要繼續公開六個月",{"id":79,"path":80,"dir":56,"title":81,"description":81,"keywords":82,"body":85},"content:3.web-api:chapter6.md","/web-api/chapter6","第6章開發牢固的WebAPI",[83,84],"6.5 同安全相關的 HTTP Header","6.6 應對大規模訪問的對策","  6.5 同安全相關的 HTTP Header     當使用者通過瀏覽器發送request到伺服器上，伺服器會回應response給瀏覽器，此時就會帶上一些header，其中有些header可以保證網站安全。    6.5.1 X-Content-Type-Options   連結    IE系列：   IE8 ━ ：無效(自帶Content Sniffing)  IE8 ✚：可用    避免Client執行不正常的 Content-Type 類型檔案。  該標頭  告訴瀏覽器不要猜測所提供內容的MIME （多用途Internet郵件擴展名）類型，而是信任\" Content-Type\"標頭。如果沒有設定：  X-Content-Type-Options 標頭，則某些較舊的瀏覽器可能會錯誤地將文件檢測為 Script 或 CSS Style，從而可能導致XSS攻擊。     推薦設定：   X-Content-Type-Options：nosniff \n\n阻止瀏覽器探知檔案的 mime type ( disable Content sniffing )，一般情況下瀏覽器會去探知資源的 Content-Type ，以判別資源類型。\n\n例如：image/png、text/css，而有些資源的 Content-Type 有可能是錯誤或缺少的，此時就會進行 Content sniffing猜測解析內容，將 X-Content-Type-Options 設成 nosniff，可阻止這種行為。\n\n沒有設成 nosniff 的風險為攻擊者可能使用錯誤的 header 隱藏攻擊的 script ，例如 \u003Cscript src=”https://example.com/attacker.txt\" >\u003C/script>，attacker.txt 實際是 js 檔，表面的 header 是 text/plain ，實際上瀏覽器會解析 scrip t的content type ，並且執行 script。\n       什麼是 content sniffing：  一般來說瀏覽器會透過 Content-Type 來判斷請求到的資源是什麼類型，像透過   \u003Cscript src=\"script.js\">  拿到的 Content-Type 一般都是   text/javascript ，因此瀏覽器看到之後就會拿來執行。但有些網站（尤其是十幾二十年前的舊網站）在開發時並沒有把 Content-Type 設好，導致某些 JS 檔的 Content-Type 是   text/plain ，也就是純文字檔。為了讓這些網站可以順利運作，  瀏覽器除了參考 Content-Type 之外，也會做 content sniffing 從檔案內容分析是什麼類型 ，如果分析出是 JS 那就會拿去執行，這樣舊網站才不會壞掉。    sniffing 這個動作看似貼心，卻也是一個弱點：  譬如說有些網站允許使用者上傳檔案，那**  攻擊者就可以惡意上傳一些有 JS 特徵的 JPG 檔（這些圖片會被瀏覽器判斷成腳本）**。 接著想辦法讓這張圖片被載入到前端來，導致裡面的惡意腳本被執行，  造成 XSS 攻擊。       6.5.2 X-XSS-Protection   連結    IE系列：   IE8 ━ ：無效  IE8 ✚：可用(可停用)\n   瀏覽器檢測到 XSS Script 攻擊，即停止執行頁面載入。  可搭配設置 Content-Security-Policy 來禁用 Corss Javascript。  現代多數瀏覽器不太需要這項保護，但對於不支援 CSP 的舊版瀏覽器的用戶提供保護。   X-XSS-Protection: 0\n    禁止XSS过滤。\n\nX-XSS-Protection: 1 \n    啟用XSS過濾（通常瀏覽器是預設的）。如果檢測到跨站腳本攻擊，瀏覽器將清除頁面（刪除不安全的部分）。\n\nX-XSS-Protection: 1; mode=block\n    啟用XSS過濾。如果檢測到攻擊，瀏覽器將不會清除頁面，而是阻止頁面載入。\n\nX-XSS-Protection: 1; report=\u003Creporting-uri> \n    啟用XSS過濾。如果檢測到跨站腳本攻擊，瀏覽器將清除頁面並使用CSP report-uri指令的功能發送違規報告。\n     推薦設定：   X-XSS-Protection: 1; mode=block\n啟用XSS過濾。如果檢測到攻擊，瀏覽器將不會清除頁面，而是阻止頁面載入。\n     6.5.3 X-Frame-Options   連結    IE系列：   IE8 ━ ：無  IE8 ✚：這個 HTTP response header 在 2009 年時首先由 IE8 實作，接著其他瀏覽器才跟上，在 2013 年時才變成了完整的   RFC7034 。   允許或禁止網頁載入   \u003Cframe>  與   \u003Ciframe> 。   副作用是其他正常的網站，也無法在 frame 中顯示被禁用 frame 的網頁。    X-Frame-Options  最前面的   X  說明了它比較像是一個過渡時期的東西，在未來新的瀏覽器當中，它的功能會被 CSP（Content Security Policy）給取代，並且把上面提到的問題解決。   X-Frame-Options: DENY\n    拒絕任何網頁把這個網頁嵌入，包含 \u003Ciframe>, \u003Cframe>, \u003Cobject>, \u003Capplet>, \u003Cembed> 這些 tag 都不行。\n\nX-Frame-Options: SAMEORIGIN\n    只有 same origin 的網頁可以。\n\nX-Frame-Options: ALLOW-FROM https://example.com/\n    只允許特定的 origin 嵌入，除此之外其他的都不行（只能放一個值不能放列表，所以如果要多個 origin，要像 CORS header 那樣在 server 動態調整輸出）。\n\nWebAPI：可以減輕在通過Frame讀取資料導致的某些漏洞而被惡意使用。(應該也不會在Fram內讀取資料，有加有保庇。)\n     推薦設定：   X-Frame-Options: SAMEORIGIN\n    只有 same origin 的網頁可以。\n   💡    補充：Clickjacking 點擊劫持攻擊  點擊劫持（Clickjacking）技術又稱為    界面偽裝攻擊（UI redress attack） \n是一種將惡意程式隱藏在看似正常的網頁中，並誘使使用者在不知情情況下點擊的手段。    攻擊原理   使用者被誘使點擊種下惡意程式的連結時，  該連結上其實覆蓋了一個隱藏的   \u003Ciframe> ，  點擊該連結時，實際上是點選了隱藏的   \u003Ciframe> ，  如果   \u003Ciframe>  內容是個 facebook 的「讚」按鈕，  用戶點到連結時，實際上是操作的是 facebook 的介面。如 Twitter、Facebook 和 Paypal 等網站上，都曾經發生過此種攻擊。    會偽裝連結使受害者點擊惡意連結   CSS z-index 屬性 ：在 CSS 當中 z-index 的數字越大，表示越上層，受害者插入   \u003Ciframe>  或其他 HTML 的時候，可以調整標籤的「透明度」、「z-index」，可以設定為透明且最上層，使受害者可以點擊。       不識廬山真面目：Clickjacking 點擊劫持攻擊 (cymetrics.io)   Day17【Web】網路攻擊：點擊劫持 Clickjacking - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天 (ithome.com.tw)     6.5.4 Content-Security-Policy   連結     內容安全策略 （  CSP ） 是一個額外的安全層，用於檢測並削弱某些特定類型的攻擊，包括跨站腳本 （  XSS  ） 和數據注入攻擊等。 \n無論是數據盜取、網站內容污染還是散發惡意軟體，這些攻擊都是主要的手段。  \n📌 CSP 建議在 server 端加 ，雖然前端可以利用 `meta http-equiv`\n給瀏覽器一些額外資訊， 但所有文件還是 prefer 在 Server 那邊加 HTTP header\n     推薦設定：   Content-Security-Policy: default-src larry.com\n  限制瀏覽器只能從 larry.com 這個網域載入圖片、CSS、字體等等各種資源\n\nWebAPI：Content-Secuity-Policy: default-src 'none'\n  告知瀏覽器不要讀取其他資源**\n    \n💡 補充：\n   簡單弄懂同源政策 (Same Origin Policy) 與跨網域 (CORS)   Content Security Policy (CSP) — 幫你網站列白名單吧   Day11-記得要戴安全帽（一）     6.5.5 Strict-Transport-Security   連結     全名是 HTTP Strict Transport Security。  強制瀏覽器只能使用安全的 HTTPS 協定跟網站進行連線，而不能使用 HTTP。  譬如說很多網站其實用 HTTP 跟 HTTPS 都連得上，但考量到安全性，當然是希望使用者都走 HTTPS。這時只要在 header 裡加上   Strict-Transport-Security: max-age=31536000; includeSubDomains ，那在往後的 31536000 秒內（其實就是一年啦XD），只要使用者的瀏覽器看到這個網域或他的子網域，就會全部改成用 HTTPS 進行連線，真的是很方便呢。    \n📌 只有在 HTTPS 有效\n     6.5.6 Public-Key-Pins   連結    已棄用     不再建議使用此功能。雖然某些瀏覽器可能仍然支援它，但它可能已經從相關的Web標準中刪除，可能正在被刪除，或者可能只是為了相容目的而保留。避免使用它，並盡可能更新現有代碼;請參閱此頁面底部的[相容性表](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Public-Key-Pins#browser_compatibility)，以指導您的決定。請注意，此功能可能隨時停止工作。   用於將特定加密公  鑰 與某個 Web 伺服器相關聯，以降低使用偽造證書進行   MITM  攻擊的風險。但是，它已從現代瀏覽器中刪除，不再支援。     推薦設定：  \n📌 Certificate Transparency\n  \n📌 Expect-CT\n     6.5.7 Set-Cookie   連結      從後端設置 ：使用後端語言設置 cookie，通過 response 的 Set-Cookie header，瀏覽器會根據 Set-Cookie 儲存 cookie    從前端 javascript 設置 ：如：document.cookie = “name=John;”。   cookie原理   連結  \n📌 Cookie（也叫HTTP cookie，web cookie）是保存在瀏覽器中的一小塊數據（不超過4K）。 HTTP協定是無狀態的，因此cookie最初被設計來幫助網站保存一些狀態資訊，或者使用者的一些操作歷史。 比如基於cookie實現的前端購物車（現在通常會用local storage來替代cookie），或者結合session來實現使用者登錄狀態，亦或者是保留使用者在網站上填寫的表單資訊方便下次輸入。\n    同源策略  cookie常常被用於存儲使用者的私有資訊，所以為了保證隱私安全，防止cookie資訊被盜取，瀏覽器施行了同源政策。 只有當各個網路訪問滿足同源策略時，才允許共用cookie資訊。 所謂的「同源」指的是：   協定相同  功能變數名稱相同  埠相同   http:// www.test.com :80/xxxxxx\n------- ------------ ---\n    |         |       |\n   協議      域名     端口**\n  只有當這三者相同時，瀏覽器才認為是符合同源策略的。 而基於cookie的網路攻擊則是通過繞過各種辦法繞過同源策略來實施攻擊，比如XSS、CSRF攻擊。   cookie帶來的安全問題    網路竊聽（中間人攻擊）      DNS緩存中毒      斷續器 - cookie盜用      斷續器 - 代理請求     Cookie flag：\n    Expires：設定一個日期，到日期時就會自動失效。\n    Max-Age：設定秒數，秒數過後自動失效，比Expires優先度高。\n    Domain：設定作用網域，設定之後會包含子網域，若無設定則默認當前網域，不包含子網域。\n    Path：設定作用路徑，設定/admin將匹配/admin/users,/admin/roles等路徑。\n    Secure：只能使用https傳到伺服器。\n    HttpOnly：只能經由伺服器存取cookie，不能經由document.cookie。\n    SameSite：Lax: default 值，在不同網域時不會發送，但在其他網域導向原本網域時會發送。\n    Strict: 只能在同網域下傳送。\n    None: 可以跨域發送，但必須有Secure flag。\n     推薦設定：   Cookie flag：\n    **Expires：設定一個日期，到日期時就會自動失效。\n    Max-Age：設定秒數，秒數過後自動失效，比Expires優先度高。\n    Domain：設定作用網域，設定之後會包含子網域，若無設定則默認當前網域，不包含子網域。\n    Path：設定作用路徑，設定/admin將匹配/admin/users,/admin/roles等路徑。\n    Secure：只能使用https傳到伺服器。\n    HttpOnly：只能經由伺服器存取cookie，不能經由document.cookie。\n    SameSite：Lax: default 值，在不同網域時不會發送，但在其他網域導向原本網域時會發送。**\n    Strict: 只能在同網域下傳送。\n    None: 可以跨域發送，但必須有Secure flag。\n  \n💡補充：\n   資安議題 — Cookie 安全. 前言 | by LSZ | 程式愛好者 | Medium   Cookie 的安全隱患 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天 (ithome.com.tw)         資安議題 — Http Security Header. 當使用者通過瀏覽器發送request到伺服器上，伺服器會回應response給瀏… | by LSZ | 程式愛好者 | Medium   前端單兵基本教練 - X-Frame-Options、CSP frame-ancestors 網站內嵌限制實測-黑暗執行緒 (darkthread.net)     6.6 應對大規模訪問的對策      不僅是Web API服務，任何在網路上公開的服務都會時不時地遇到來自外部的大規模訪問。當伺服器遇到大規模訪問時，為了處理這些訪問會耗盡資源，進而無法提供服務。這時不僅是這些大規模訪問，任何人都無法和伺服器端建立連線。  \n⚠️ **DDOS：**\n   ddos 攻擊定義，防護策略與三手法| Cloudflare | Cloudflare     Famous DDoS Attacks | Cloudflare     【Security 的老生常談】又是你嗎？DDoS ?! - (discover-thefutureofwork-tw.cloud)       6.6.1 限制使用者的訪問 *      用什麼樣的機制來識別使用者   如何確定限速的數值   以什麼單位來設置限速的數值   在什麼時候重置限速的數值       Twitter\n       對搜索推文的操作  (search  /  tweet)：每   15   分鐘   180   次\n     對直接取得消息的操作  (direct_message)：每   15   分鐘   15   次\n   \n   Zendesk\n       基本   1   分鐘內   200   次\n     不同端點，有些只允許   10   分鐘   15   次   (更新 ticket) , 或更少\n     6.6.2 限速的單位      上限值要根據所設想的API使用情境進行調整   要了解你所提供的API會在怎樣的情況被用戶使用，並以此為依據來決定如何設置訪問限制速。  \n❌ 對資料庫頻繁更新的查詢類 API ： 用戶需要頻繁地訪問API，取得最新資料。如果設定 1 小時只允許訪問 10 次這樣嚴格的限制。那麼即使使用API，也無法給應用或服務帶來更高的附加價值，API用戶數也難以增加。\n  \n📌 Etsy 服務引入\"progressive rate limit\"(累進限速)的限速方式，用戶訪問上限 24 小時 1 萬次\n  計算：\n24 小時 拆成 12 個單元，每個單元 2 小時，以過去 12 個單元累計訪問次數做為訪問上限。\n即使用戶超過上限，只需要再等待 2 小時，第一個單元的訪問次數就會重置，用戶就可以再訪問。     6.6.3 應對超出上限值的情況     可以返回HTTP協議中備好的“429 Too Many Request”狀態碼。   當用戶超出訪問上限值時，服務端該如何返回響應訊息呢？這種情況下可以返回HTTP協議中備好的“429 Too Many Request”狀態碼。429狀態碼在2012年4月釋出的RFC 6585中定義，當特定使用者在一定時間內發起的請求次數過多時，伺服器端可以返回該狀態碼錶示出錯。RFC 文件中對該狀態碼描述如下：         6.6.4 向用戶告知訪問限速的信息     用戶會一直訪問 API   用戶如果知道限速信息，就可能會針對性的編寫出自動調整訪問量的客戶端程序。           https://api.github.com/rate_limit               Web API 的設計與開發 | 七月十五九月初七 (luisedware.github.io)   html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":87,"path":88,"dir":89,"title":90,"description":7,"keywords":91,"body":97},"content:4.cicd-2.0:5.chapter5.md","/cicd-2.0/chapter5","cicd-2.0","05 持續交付的軟體系統架構",[92,93,94,95,96],"前言","5.1 ”大系統小做”原則","5.2 常見架構模式","5.3 架構改造實施模式","5.4 小結","  前言  在 2000 年，著名的電商網站 AWS 仍然是使用傳統的巨石應用開發，而不是今天大家看到的微服務架構。巨石應用每次部署的時，都需要將整個網站作為一整體並進行統一部署。在大型促銷活動時，網站的穩定性遇到了嚴峻挑戰，儘管團隊之前做了預估擴充，但在活動流量期間往往超出了團隊的預估。生產事件造成的問題，頻頻發生，經常修復一處問題卻引發另外一處問題。  公司管理層內部開始查看原因，最主要的原因是因為系統耦合度太高且複雜。但由於時間比較緊迫，工程師忙於開發自己手上的功能，沒有時間進行溝通。  後來將巨石架構改為服務導向架構   (Service-Oriented Architecture, SOA)，並提出以下要求   所有團隊都要以服務介面的方式，提供資料和各種功能  團隊之間必須通過介面來通訊  不允許其他形式的互相操作、不允許直接存取其他團隊的資料庫、不允許共享記憶體、不允許任何形式的後門。唯一許可的通訊方式，就是通過網路來呼叫服務。  具體的實現技術不做規定，HTTP、Corba、Pub/Sub 方式，自定義協定即可。  所有的服務介面，必須從一開始就是公開的設計介面。簡而言之，在設計介面的時候，就預設這個介面可以讓外部人員使用，沒有討價還價的餘地。  如果不遵循上面的規定，就會被解僱。   AWS 在 2011 年，其生產環境的部署頻率已經非常高。工作日的部署頻率高達平均每 11.6 秒一次，一小時內最高部署次數 1079 次。  5.1 ”大系統小做”原則  5.1.1 持續交付架構要求  為了提升交付速度，獲得持續交付能力，系統架構在設計時，應考量下列因素。   為測試而設計 (design for test)。每次撰寫好程式碼之後，都需要花大量的時間和精力來進行測試，這樣驗證花太多時間，就沒有辦法快速發佈。  為部署而設計 (design for deployment)。開發完成新功能後，當部署發佈時，需要花費很長時間準備，甚至要停機才能部署，就沒有辦法快速發佈。  為監控而設計 (design for monitor)。當功能上線後，無法即時監控，得等到出問題時，使用者回饋後才知道問題，這樣持續交付的優勢就大幅降低了。  為擴展而設計 (design for scale)。有兩點，一是支持團隊成員的規模擴展; 二是支持系統自身的擴展  為失敗而設計(design for failure)。快速部署一定會遇到問題的。一但部署或發佈失敗，該如何優雅且快速地處理。  5.1.2 系統拆分原則  大系統小做的方法由來已久，在 1971 年時，David Parnas 發表了一篇論文\"On the Criteria To Be Used in Decomposing Systems into Modules”(將系統分解為模組的標準)。大系統應該由很多組件(component)或服務(service)組成。通常會以 jar/war/dll/gem 等形式出現，其顆粒度要比一個類(class)大，但要比整個系統小很多。  參考  連結   組件通常在編譯建置或部署時被集合在一起，而服務由多個組件組成，且能夠獨立運行，並在運行時與整個系統進行通訊，成為整個系統的一部份。  目前軟體的發展趨勢，以持續交付的要求對系統進行拆分，有以下原則   做為系統的一部分，每個組件或服務有他自己的業務職責，可以被獨立修改，甚至可以被另外一種方案所替代。  “高內聚，低耦合”，使整個系統比較易於維護，每個組件或服務地功能盡量單一化，不要太複雜。  整個系統容易建置和測試。將系統拆分後，這些組件仍然需要組合在一起，為使用者提供服務。  使團隊之間的溝通合作更加順暢。  由於將系統進行拆分，因此產生了新問題。例如: 多個服務組成的系統來說，一個請求可能經過多次不同服務之間的相互呼叫才完成。這樣呼叫鏈過長，當有上百個上千個服務時，沒有服務發現機制是很難想像的，當你呼叫其他人的服務，並要查找問題時，就會發現 Debug 難度非常高。  因此系統拆分後，我們需要建立對應的方法   建置  測試  部署  監控機制  5.2 常見架構模式  這邊討論三種架構模式   微核架構：向使用者分發的 Client 端軟體  微服務架構：用於企業自身可控的後台 Server 端軟體  巨石應用：常見於創業公司的產品項目。  5.2.1 微核架構  微核架構(microkernel architecture)，又稱為套件架構(plugin architecture)，只軟體核心框架相對較小，而主要業務功能和邏輯都通過套件實現。   核心(core)架構：通常只包含系統運行的基礎功能，例如: 基礎的通訊模組、基本渲染功能和介面整體框架。  套件：套件之間是互相獨立的，套件之間的通訊只能通過核心框架進行，避免出現互相依賴的問題。    插件：外掛程式或擴充套件，通常跟 UI 有關係，例如: Chrome 常用的 Chrome Extension 功能。  這邊舉幾個例子   前端相關   將核心架構看作為 Chrome 瀏覽器，而套件看作為 Chrome Extension 工具。  將核心架構看作為 VSCode，而套件看作為 VSCode Plug-in。  後端相關   API Getway，API Management kong，開箱即用的 Gateway  驅動相關   印表機驅動程式  USB 驅動程式  ✅ 優點   良好的功能延伸性(extensibility)：需要什麼功能，開發一個擴充套件即可。  易發佈：套件可以獨立地加載和卸載，使他比較容易發佈。  易測試：功能之間是隔離的，互相不干擾，因此可以獨立進行測試。  可訂製性高：適應不同開發的需求。  可以逐漸式地開發：逐步增加功能。  ❌ 缺點   擴展性(scalability)差，core 通常是一個獨立單元，不容易做成分布式，但為 Client 端軟體來說，這不是一個嚴重的問題。  開發難度相對較高，因為設計 Plug-in 與 Core 的通訊，以及內部的 Plug-in 登記機制。  高度依賴框架，當框架的介面升級時，有可能影響所有 Plug-in，導致大量的改造工作。  5.2.2 微服務架構  微服務架構(Microservice Architecture)是服務導向架構(service-oriented architecture)，縮寫 SOA 升級。  每一個服務就是一個獨立的部署單元(separately deployed unit)。這些單元都是分佈式的互相解偶，通過通訊協定(REST、SOAP)來通訊。   微服務架構分種三種模式   RESTful API 模式：服務通過 API 提供，雲服務(Cloud Service)就屬於這一類型。  RESTful 應用模式：服務通過傳統網路協議或應用協議提供，背後通常是一個多功能的應用程式，常見於企業內部  集中消息模式：採用訊息代理(Message Broker)，可以實現消息柱列、負載均衡、統一日誌和異常處理。建議將 Message Broker 做成群集(Cluser)，來增加穩定度和可靠性。  ✅ 優點   擴展性好，各個服務之間低耦合  易部署，每個服務都是可部署單元  易開發，每個組件都可以進行單獨開發，單獨部署，不間斷地升級  易於單獨測試，如果修改指涉及單一服務，只需要測試該服務即可  ❌ 缺點   由於強調互相獨立和低耦合，服務可能被拆分很細。導致系統依賴大量的服務，變的凌亂和笨重，網路通訊消耗也會變很大  一次外部請求(Request)會涉及到多個內部服務之間的通訊，使得問題的除錯與診斷比較困難，需要更強大的工具支持。  為原子性 (Atomicity)操作帶來困難，例如：需要事務交易操作的場景。   ACID 為資料庫操作寫入或更新的過程  \nA：原子性 (Atomicity)  \nC：一致性 (Consistency)  \nI：事務隔離 (Isolation)  \nD：持久性 (Durability)  會遇到常見的事務交易問題 👉  參考  跨服務的組合業務場景比較難測試，需要同時部署和啟動多個微服務  公共類別庫的升級和管理比較困難。在使用一些公共的工具性質的類別庫時，需要在建置每個微服務時，都將其打包到部署包中。  正是這些缺點，因此使用微服務架構模式下，需要確保每一個服務能夠獨立部署之外，還要確保服務升級之後不會影響到下游服務。  5.2.3 巨石應用  巨石應用(monolithic application)，也稱為巨石架構，只單一結構組成的軟體應用，也有另一個稱呼為單體式應用。其用戶的介面和資料存取程式碼都綁定在同一個語言平台的同一個應用程式上。   巨石架構通常是一個完整的包，例如: 一個 Jar、Exe 或一個完整的目錄結構，只要有這個包，則所有功能皆有了。   ✅ 優點   利於開發和除錯：當前所有工具和 IDE 都很好地支援巨石應用程式開發。系統架構簡單，Debug 方便。  部署操作本身比較簡單：例如，只需要運行部署時內的 WAR 或 Exe 檔案等等。  很容易擴展：只要在負載均衡器(nginx、IIS)後面放置多個應用的副本，就可以擴展應用程式。  ❌ 缺點   對整體應用程式不太熟悉的人來說，容易產生混淆的程式碼，汙染整個應用，給老舊程式碼的學習和理解帶來困難。  很難與新技術共存。  只能將整個應用作為一個整體進行擴展。  持續部署非常困難，更新一個組件，必須重新部署整個應用程式。  微服務場景相關  (a) 圖有兩個名為 A 服務，分別為新和舊版本，這樣的方式會讓主控服務，無法認識到底該使用哪一個服務進行運作。  (b) 圖有兩個實體的測試環境，A 測試環境用來測試新的 A 服務，B 測試環境用來測試舊的 B 服務。這樣的測試方式，當如果多人都需要測試服務時，會需要大量的測試環境才能夠進行測試。   下方是沒有考慮除錯環境的微服務框架   \n💡 解決上述問題的方式，可以透過路由的機制，讓開發人員可以單獨部署和修改自己的微服務來進行測試。\n   下方是通過路由機制建立共享的微服務測試環境   5.3 架構改造實施模式  對部署頻率較低的老舊系統來說，很少會仔細考慮到易測試、易部署和易擴展這三個因素。因此我們總會遇到架構改造的需求。通常改造有三種模式：   拆遷者模式  絞殺者模式  修繕者模式  5.3.1 拆遷者模式  拆遷者模式就是根據當前的業務需求，對軟體架構重新設計，並組織單獨的團隊，重新發佈一個全新的版本，一次性的替代原有的老舊系統。   ✅ 優點   與舊版本完全沒有瓜葛，沒有歷史包袱  ❌ 缺點   業務需求遺漏。在軟體的歷史版本中，有很多不為人熟知的功能還在使用。  市場環境變化。由於新版本架構花費時間較長，無法馬上修改完成，因此當市場發生變化時，就會錯失市場機會。  人力資源消耗大。必須分出人力，一邊維護舊版本的功能或緊急需求，一邊要安排充分人力進行改造。  閉門造車。新版本上線後，無法滿足業務需求。  下面舉實際案例  ✅ 成功案例  HP 惠普印表機的韌體架構改造就是一個成功的案例。在 2008 年的時候，HP 惠普團隊已經筋疲力盡，整個團隊只有 5%在開發新特性，其餘人數皆在進行維護。經過三年的努力，HP 惠普團隊將整個韌體架構改為  微核架構模式 ，在每台印表機上都有一個最小的韌體初始化版本。當印表機連上網後，就會根據韌體的版本，從網路上下載最新的功能模組，並自動安裝。  ❌ 失敗案例  網景通訊公司，主要是在做瀏覽器以 Netscape Navigator 而聞名。由於其老舊的軟體架構，讓使用者體驗越來越差，已經很難對抗主流的瀏覽器發展，於是公司高層決定使用  拆遷者模式 對軟體進行改造。在改造期間，微軟憑藉著 IE 瀏覽器和 Windows 的成功，直接躍升為瀏覽器市場第一名，而網景通訊公司後來則一蹶不振。   網景通訊公司：網景通訊，舊稱網景通訊公司，通常簡稱為網景，是一家已倒閉的美國電腦服務公司，以其開發的同名網頁瀏覽器而聞名。當還是一家獨立公司時，其總部設在加利福尼亞州的山景城。  5.3.2 絞殺者模式  絞殺者模式是只保留原來的老舊系統不變，當需要開發新的功能時，重新開發一個服務，來實現新的功能。通過不斷的建置新的服務，逐步讓老舊的系統失效，最終取代它。    ✅ 優點   不會遺漏原有需求  可以穩定地提供價值，頻繁地交付版本，可以更好的監控其改造發展  避免  閉門造車 的問題  ❌ 缺點   架構改造的時間會大幅地變長  產生一定的跌代成本  5.3.3 修繕者模式  修繕者模式是指將老舊系統的部分功能與其餘部分隔離，以新的架構進行單獨改善。在改善的同時，需要保證與其他部分能協同工作。   ✅ 優點   系統外部無感知  不會遺漏原有需求  可以隨時停下改造工作，響應高優先權的業務需求  避免  閉門造車 的問題  ❌ 缺點   架構改造的時間會大幅地變長  會有更多額外的架構改造成本  巨石應用轉變為微服務的改造   5.3.4 資料庫的拆分方法  關聯式資料庫很可能是巨石應用中最大的耦合點。對於有狀態的服務改造，我們需要非常小心地處理資料庫資料。做資料庫拆分時，應該遵循以下步驟：   詳細瞭解資料庫結構，包括外來鍵、共享的可變資料以及事務性的邊界等等。如(a)圖  先拆分資料庫，可以參考 12.3.2 節中介紹的資料庫遷移。如 (b)圖  當寫入兩邊的資料庫都無誤時，找到程式架構中的細縫，如 (c)圖  將拆分的程式模組和資料庫組合在一起，形成微服務。如 (d)圖   💡 應該圍繞業務目標進行架構改造  \n對巨石應用進行拆分時，可以先拆分顆粒度相對較大的服務。當拆分完成後，如果達到拆分的目標，那麼就可以停下來，不應該為了架構而架構，為了技術而技術。當拆成微服務架構時，你必須考慮要建立相應的基礎設施，例如：服務管理、服務監控、自動化測試與自動化部署。  5.4 小結  本章節主要討論”  持續交付 2.0 能力 ”對軟體系統架構的要求，在軟體開發時就考慮了下列項目 👇，並且 �� 論系統架構的拆分原則   可測試性  易部署性  易監控性  易擴展性  可能的失敗處理  常見的三種軟體架構模式在不同場景的分析和比較：   微核架構模式，通常是應於 Client 端軟體  微服務架構，通常適用於大型後台 Server 端系統  巨石應用架構，通常適用於創業公司或中小型專案  討論了三種系統架構改造的方式   拆遷者模式，一次性的重寫所有程式碼。  絞殺者模式，就是不改變或少改變原有老舊系統，通過增加的新服務來不斷替代老舊的功能。  修繕者模式，就是通過跌代的方式，將原本老舊系統逐步進行改造，同時開發新的功能。  也介紹了解決絞殺者模式和修繕者模式中，可能會遇到資料庫中的資料表和資料的拆分以及拆遷問題。   為了持續交付，並且降低架構改造的風險，團隊需要根據情況，來採用絞殺者模式或修繕者模式對遺留系統的架構進行改造。",{"id":99,"path":100,"dir":89,"title":101,"description":7,"keywords":102,"body":110},"content:4.cicd-2.0:7.chapter7.md","/cicd-2.0/chapter7","07 部署流水線原則與工具設計",[92,103,104,105,106,107,108,109],"7.1 簡單的部署流水線","7.2 Pipeline 的設計與使用","7.3 Pipeline 平台的組成","7.4 基礎支撐服務雲端化","7.5 企業成品庫的管理","7.6 多種多樣的部署流水線","7.7 為開發者建置自助式工具","  前言  Deployment Pipeline 為 CI 的核心，能完整呈現軟體交付的整個過程。從程式碼完成後的提交、建置、部署與測試到正式的發布，除了可以清楚知道整個歷程外，也可即時得知提交進度。  那我們該如何根據團隊與不同產品去設計整個 Pipeline?此章的重點就在談這件事情。  \n部署Pipeline受到軟體架構、Git Flow及團隊與產品不同而有所不同設計概念。\n  7.1 簡單的部署流水線  此節以實際例子來簡易 OverView 在 Pipeline 設計上會有那些環節與實際情境。書中例子以  Curise 為範例，他就像今日我們很常聽到 Jenkis，是一個以 Java Base 開發的持續整合工具。其程式碼高達 5 萬行，而自動化單元測試及整合測試 Case 就多達 2350 個，端對端測試為 140 個，在架構也算蠻龐大的軟體系統。  但他在 2010 年就停止維護了，有興趣了解可以到他的  官方網站 。Curise 在 2010 年停止維護後更名為 GoCD，並走 Open Source 開發。並將 Source Code 放置  Github 。  7.1.1 GoCD 簡單的產品研發流程  GoCD 算典型的持續整合代理伺服器架構，其架構如下，GoCD Server 提供使用者 UI 及 Pipeline 腳本控制及指派工作，讓 Agent 去執行 Pipeline 過程中需要執行的 Command(此處簡單帶過)。另外一提，他使用的版控工具為 Mercurial 不是一般主流的 Git。   維護此產品的團隊人數約為 12 人，產品的交付其中與迭帶週期為一周。在這麼快速的迭帶週期，團隊也使用 CICD，在每個迭帶結束後，用新版本替換掉目前團隊在使用的舊版本，並在每兩個迭帶後將試用版本部署到公司內部的公用伺服器，若公司內部試用版本使用到一個品質檢測標準，一周後再將版本交給企業試用。其週期如下圖所示，   白正方形:單周 Blood 版本(團隊)  灰正方形:雙周 Alpha 版本(公司)  白圈:雙周 Beta 版本(外部企業)  大圓圈:全球發布   7.1.2 初始 Pipeline 設計  GoCD 的 Pipeline 設計是 Base on 六步提交法理論，六步如下   第一步: Clone 成功版本至本地端  第二步: 修改程式碼  第三步: 本地端 Build && Test  第四步: Pull Merge 其他人程式碼再跑一次 Build && Test  第五步: 提交  第六步: 進 Pipeline   感覺六部提交法是針對新的小碼農制定的口訣，避免小碼農 Clone 錯誤的程式碼或是沒有做好 Build Test 就提交程式碼，會 Focus 在個人建置部分。  我們來看 GoCD 的 Pipeline 設計如下圖，整個提交整合與部署分為八個 Stage 站別，有手出現的 Icon 代表人為去介入   基本上每個站別都只有一類任務類型，   1.提交建置:Build 與 單元集成測試  2.次級建置:End To End 測試(Windows && Linux)  3.將打包好的檔案部署到 UAT 環境  4.測試人員驗證完後 Tag 驗收通過，並對 Pipeline 點擊繼續  5.做自動化性能測試(此處沒說明做什麼性能測試)  6.將 Alpha 版本部署到公司內部伺服器給團隊試用  7.試用 OK 後發布 Beta 版本給外部企業試用  8.外部企業試用試用完成後正式發布  \nUAT，(User Acceptance Test),使用者接受度測試 即驗收測試，主要是用來作為客戶體驗的環境。\n  基本上這 Pipeline 設計大部分專案情境可能都會經過這些步驟，只是也許後面部署與測試順序不一定會完全相同。例如有些企業會覺得 UAT 測試完後其實就可以上 Production，但 GoCD 為了嚴謹在部署測試上又多了好幾個站別，確保 Product 能完全運行順利。  另外值得一提的，在這個設計中，GoCD 在單元集成測試的時間非常長，有五個集成測試，基本上每個集成測試要花 15min，而第二站別的次級建置端對端測試也多達 140 個測試項目，需要最長時間為 30min....  7.1.3 Pipeline 狀態解析  管線運型實際狀況如下，可看到在建置編號 12 版本，在 UAT 部署就停了下來。也許這建置版本並沒有新功能，所以可以在這階段就停止。而建置編號 13 在次級建置跳過，有可能因為 12 還沒完成。至於此處是手動按停止還是自動停止就不太清楚。  不過此節要表達的是，再多 Job 管線運行上，會根據不同狀況管線過的 Stage 狀況也會不太一樣。   7.2 Pipeline 的設計與使用  在介紹完 GoCD Pipeline 的實際使用狀況，大體上應該會曉得基本 Pipeline 會有什麼工作需要運行。那我們該如何透過設計去優雅的使用 Pipeline 呢?  7.2.1 Pipeline 的設計原則  書中提到有 5 個觀念去設計 Pipeline    一次建置，多次使用 。Pipeline 上的任務要產生部署使用的檔案，盡量在前面的站別就一次建置完成，並可直接讓後面的站別做使用。盡量不要在後面在別再做重複性建置。另外如果後續的站屬如果要使用此編制檔案，也必須此部署檔案來源是與上流站別是同一份。   與業務邏輯松耦合 。簡單來說在就是不要為了方便，將一些部署所需使用的腳本或資料放在 Pipeline Server 上，盡量與 Pipeline Server 不要有編譯耦合的設計。相反，若有相依檔案或腳本，我們必須存放在存取庫中，照樣就可以輕鬆對這些腳本設計做修正。簡單來說，對於 Pipeline，他就像是調度、執行與紀錄者，他只需要知道整個調度流程，不需要知道如何建置與部署軟件需要自己提供哪些東西。   並行化原則 。如果有五個自動化測試任務，我們也可以設計並行 Pipeline 同步跑這五個測試任務，並即時提供結果訊息，從而修正問題。若使用併行，整體等待回應的時間就能大幅收短。就像前面提到 GoCD 有五個測試集成，若使用並行化原則就能大幅縮短測試時間。   快速回應結果 。如果資源較貧乏(例如 Runner 規格特爛)，在 Stage 的設計，我們可以將依些運行較快的自動化驗證優先做執行，較慢與消耗資源較多的放在後面執行。感覺這邊得意思 花較長時間的測試，就放在越接近正式上線前做，來縮短前面開發測試時間。   重要的回應結果優先 。呼應第四點，雖然為了達到快速回應結果將一些較快的測試放在前面做，但依然要以重要優先權高的為主。  7.2.2 團隊紀律  1.立即暫停原則  Pipeline 一出問題，團隊需要有人立即去處理，而不是放任他不管。再問題修復前，禁止任何人提交新的程式碼。  2.安全審核原則  所有代碼與軟件包都需要有偷過板控及審核完畢才可使用。  7.3 Pipeline 平台的組成  這章節主要述說 Pipeline 的主要組成區塊  7.3.1 工具鏈整體架構  書中提出的圖有點難去了解，在這我拿一張以 Github 結合 Jenkis 的架構圖去輔佐解說(Jenkis 那張圖先不管架構 Solution 是否為最好)。   Pipeline 整體架構主要分成、唯一信受源(程式碼與打包物存取庫)、調度及展示(調度器)以及基礎支撐服務(測試、部署等實際執行環境..)  1.唯一信受源  在 Pipeline 過程中，團隊角色若對任何訊息產生質疑時，要做追溯都應該要能追回到存取庫裡的產出物(要部署檔案)，而在存取庫中的打包檔案都可以找到對應程式碼及他相依的類別庫檔案，或是能找到下載的 URL Source。  2.調度及展示(Pipeline)  能接受不同的服務基礎平台，且具有調度不同任務，完成整個交付流程的功能。並此能展示整個過程的歷史訊息。  3.基礎支撐服務  一間較大的公司具有相對應的建置、測試及部署的服務。規模較不大的通常前兩個通常就直接在一個 Runner Execute 直接做掉。那如果是前者，在 Pipeline 設計上就要考慮如何去與這些基礎支撐服務去連通與協作，讓整體 Pipeline 過程中達到最大的效益性。  7.3.2 平台應具有的基本能力  Pipeline 事團隊多角色的統籌協作系統，因此關注的是軟體在 Pipeline 的流動效率，包含部署與上線，過程能精準展現個環節的狀態與訊息，並能在不增加團隊負擔情況下自動收集各環節產生的數據。例如，衡量某一功能的開發週期。  此章節提到重點就下述兩點，   1.追溯能力  2.重新建置能力  針對 1 不多說，簡單來說就是對於事件能查詢他所有的歷程。對於 2，只要存取庫程式碼依舊存在，就算遇到版本出問題，依舊能再次修改重新做自動部署。又或是自動化失敗因為對應服務環境出問題，在對應環境 Recovery 後，能再次重新運行測試。  7.3.3 工具鏈建設策略  上述 7.3.1 圖中提到的平台架構，可看出他是由不同的工具與子系統組成。因此我們可以根據公司的習慣與策略去客製設計。例如 GoCD 團隊因為在自動化測試量較龐大，因此就自行開發一個自動化測試分組插建，由此插件自動將所有測試分配到不同任務哩，並將這些任務分配到多個測試環境中執行。但對更大型的公司，其環境會更加複雜，其各產品組件之間的關聯關係也會更加龐大複雜。為了發揮持續交付的威力，上述提到的各類支撐服務雲端化也成為必要選項。例如 AWS、Facebook 與 Google 都具有自己的 DevOps 平台工具鏈，甚至將其中一部分工具開放給 Open Source。  那此服務系統間個詳細的關係是什麼? 7.4 章節會述說這件事情。  7.4 基礎支撐服務雲端化  大多大公司服務端程序部署頻率都非常快，幾乎都又自己的雲化支撐服務，如下表   7.4.1 基礎支撐服務協過過程  此章節為稍微大致講解整個管線與基礎建置服務互動的過程，大分類上分三個步驟來看，   第 0 步:環境準備(yml 設定)  這部白話一點就是整體部署有哪些設定及有哪些基礎服務建設，針對 Stage 任務對應相關設定指派相對應基礎建設服務準備。  第 1 步:提交建置(建置，測試)  將 Source Code 交至相對應服務做健置與測試，建置管理服務會將代碼從程式存取庫中提出，然後在建置環境建置打包後，放入成品庫。  接著部署管理服務根據 Pipeline 定義將編譯好的成品，放到測試環境測試。如果測試需要一些比較特別的設定，則同時從部署配置讀取相關配置，成功後就開始執行 Pipeline 的測試任務。  第 2 步:次級建置(部署，測試)  當測試完成後，部署管理服務會再從成品庫中拿去成品，並從部署配置讀取 UAT 相關部署訊息，將兩者結合，部署到 UAT 環境進行端對端測試。  第 3 步:部署生產環境  當次級建置 UAT 測試完成後，部署管理服務會再次從成品庫取出成品，並讀取配置訊息，部署到正式環境。  7.4.2 建置管理服務  構成分三個區塊   任務管理  調度  執行器   每個區塊服務都有柱列緩衝，任務管理將任務交給調度器後，調度器會根據一定的調度算法選擇建置任務將其發送相對應的執行器編譯。例如 c#代碼若為 Net Framework 則指派到 Windows 環境下編譯，C++則指派到 Linux 下環境編譯。而集群管理器則是管理這些執行器的建立與狀態管理(繁忙、空閒、失去連線..)。  執行器為建置任務的代理，集群中可以有多個執行器，每個執行器會根據收到訊息對應的存取庫 URI 檢出代碼並根據要求編制建置任務。建置完成後會將指定產物(部署需用檔案)放到成品庫中。並向 Pipeline 回報執行結果。  另外可以看到圖中左邊 Request 輸入點有個人頭，代表這架構也允許工程師在本地編寫期間就可以直接使用此服務。  7.4.3 自動化管理服務  構成分三(四)個區塊   任務管理  調度  執行器  測試健康管理   針對任務管理、調度與集群管理猶如 7.4.2 所說，大致上是一樣的意思，只是編制任務變成測試任務。值得一提的是測試健康管理。當測試在不同節點或資源條件下，因為失敗重複執行太多次(書中寫 1000 次)。  此時測試健康管理器就會將不穩定的 Case 拉到不穩定池並通知團隊做處理。這邊健康管理器英文對應一時查不太到....所以如何實作也不太清楚。  7.4.4 軟件部署管理服務  雖然在 Pipeline 過程中的測試都沒問題，但也有可能到了實際正式環境會出錯。原因在於測試環境與正式環境還是會有一定的差異性。  書中舉過內很多大型企業的生產環境用的 J2EE 應用服務器都是商業軟件，但因為過於笨重，所以用語法檢查就不嚴格的 Tomcat。此時如果部署到企業的正式生產環境，就會產生有些頁面因為 Html 標籤不匹配而發生錯誤。  好，上述講一講不是下圖重點..下圖要表達的是，因為為了協調運維部門與產品部門的合作。之間的接口建議有個正式產品庫及上線單。此時運維部門就可以根據上線單，從正式產品庫拉取相對應的產品至正式(生產)環境步數。   7.4.5 基礎環境管理服務  為建置、測試、部署管理提供環境準備與監控服務。能接受這三種環境的請求為期準備相對應的環境。隨著 Docker 技術成熟，配置基礎環境慢慢以 Docker Image 形式，需要時直接啟動，並提供服務。   7.5 企業成品庫的管理  企業成品庫是部署流水線工具鏈中企業的受信源之一，也是企業信息管理中的一個重要節   \n點。只有通過安全驗證的軟體包才會被納入成品庫，並且安全驗證部門也應定期對存儲的   \n對存儲的內容作安全掃描及清理。  7.5.1 成品庫的分類    臨時軟體包庫(A)   \n用於存儲團隊開發並通過流水部屬線生成程式碼的所有軟體包。  正式軟體包庫(B)   \n用於存儲通過流水線部署且經過安全驗證，被確認能夠發布到生產環境或使用者的軟體包。  外部軟體包庫(C)   \n指該軟體包的程式碼並非由團隊管理或維護，但在開發中所使用到的其他軟體包。這些軟   \n體包通過互聯網或是第三方取得，亦將其存儲在成品庫中。   \n外部軟體包一般存儲的形式可能包含 3 種：   \n(1) 以二進制的方式保存。   \n(2) 以程式碼副本的方式保存。   \n(3) 以外部連結地址的方式保存。    臨時鏡像庫(D)、正式鏡像庫(E)、外部鏡像庫(F)   \n基本上同軟體包庫，只是以鏡像的方式作存儲。  7.5.2 成品庫的管理原則  成品庫中，每個成品都應該有標示，並且連同其來源、組成的部件以及用途等，一起保   \n存為該成品的信息。所有成品都要能夠追溯至源頭， 包括臨時成品庫中的成品。  7.6 多種多樣的部署流水線  7.6.1 多組件的部署流水線  若一個軟體產品由多個組件建置而成，每個組件都有獨自的程式碼倉庫，並且每個組件   \n由一個單獨的團隊負責開發與維護，整個產品的部署流水線的設計通常與下圖相似。   每個組件的部署流水線成功以後，都能觸發下游的產品集成部署流水線。而這個集成部   \n署流水線的打包階段，會自動從軟體包庫中獲取每個組件最近成功的軟體包，然後對其   \n進行產品打包，再觸發集成部署流水線的後續階段。  7.6.2 個人部署流水線  每名工程師創建了自己專屬的部署流水線，用於個人在未推送程式碼到團隊倉庫之前的   \n使用。個人的部署流水線並不會部署到團隊共同擁有的環境中，而是僅覆蓋個人開發環   \n節。   工程師通過部署流水線的模板功能，複製一份團隊部署的副本。並僅保留兩個階段(提   \n交建置、次級建置)的內容。令工程師能夠監聽自己程式碼倉庫的變化，並且自動化去   \n觸發。當開發人員提交程式碼到個人倉庫時，都會自動觸發個人專屬的部署流水線。  這樣做的好處有 3 個：   個人部署流水線與團隊的部署流水線共享建置及測試環境。  保證每個工程師都能利用到相同的測試資源，加快個人檢驗的速度。  個人部署流水線的測試用例與團隊的部署流水線的驗證集合相同，因為是相同的建置資源，若是發生建置失敗，則可以容易的定位到問題點。  7.6.3 部署流水線的不斷演進  截止到 2018 年 4 月，GoCD 的社區版本每月會發布一次正式版，而其團隊的複雜的部署流   \n水線設計也已演變如下圖所示：   構置 Linux 包這個部署流水線中，包含兩個階段。第一個階段是 build-no_server。多   \n個任務並行執行，構置組成 Server 所需的多個 Jar 包，也並行執行 Java 測試用例和   \nJavaScript 單元測試用例。這體現了部署流水線盡量並行化原則。第二個階段是   \nbuild-server，使用經第一個階段己初步驗證通過的多個 Jar 包組裝成 Sever 包。  Linux 驗收測試這個部署流水線中，也包含兩個階段。第一個階段是運行高優先級的功   \n能測試，第二個階段是對插件部分的自動化功能測試，這體現了部署流水線的快速反饋   \n優先原則。  而在後續的各類測試(如驗收測試、回歸測試或者功能測試)中，被測試的二進制包均來   \n自前面各部署流水線的產出物，而且確保其使用同一程式碼版本。  7.7 為開發者建置自助式工具  優秀的互聯網公司採用了一種工具平台的設計理念，即為開發工程師設計他們認為好用   \n的工具。這種方式要求創建強大的工具平台，能夠很好地支持開發工程師做產品服務。  例如 Facebook，開發人員可以通過他們內部平台看到自己的程式碼已經發佈到哪個階   \n段，有多少用戶在使用。開發工程師在不需要任何人幫助的情況下，就能夠了解他的程   \n式碼已經發佈到哪個階段了。   例如電商公司 Etsy，開發工程師可以查看到自上次生產部署以後，每次的程式碼變更   \n數量，並且非常方便地查找程式碼差異。 ",{"id":112,"path":113,"dir":89,"title":114,"description":7,"keywords":115,"body":123},"content:4.cicd-2.0:8.chapter8.md","/cicd-2.0/chapter8","08 利於集成的分支策略",[92,116,117,118,119,120,121,122],"8.1 版本控制系統的使用目的","8.2 常見分支開發模式","分支策略","8.3 分支模式的演化","8.4 分支策略","8.5 小結","Additional Reference:","  前言  我們已經討論過如何將需求拆分成多個可交付、可驗收的用戶故事，以及如何將它們安排到我們交付迭代的過程中。接下來，本章將介紹研發團隊通過原始碼倉庫，高效組織團隊多人并發協作的方法，即代碼分支策略。分支策略的選擇對持續交付的成本與效果有很大的影晌。  8.1 版本控制系統的使用目的  版本控制系統(Version Control System）主要用於存儲及追蹤目前（文件夾）和文件的修訂歷史（這里的修訂操作包括 3 類：新增、修改和刪除），從而讓你能夠回溯那些被納入其管理範圍之內的任意對象的任意一次修訂。其最本質的作用是回答\"4 個 w\"，即在什麼時間(When)、修改了什麼內容（What),是誰修改的（Who)以及為什麼要修改（Why),。其中最後一個\"W\"是通過用戶提交代碼變更時書寫提交注釋(Comments）的方式提供的。現在，版本控制系統已經成為團隊合作共同交付軟體過程中所用到的重要協作管理機制，是軟體公司的基礎設施。其目標是支持軟體配置管理活動，追綜和紀錄多個版本的并發和維護活動。根據版本控制系統的運作方式，目前市面上的主流版本管理系統被劃分為集中式版本控制系統和分佈式版本控制系統兩種類型。  8.1.1 集中式版本控制系統  集中式版本控制系統的出現，解決了多人如何進行協同修改代碼的問題。這類版本控制系統，都有一個單一的集中管理的版本控制管理服務器，保存所有文件的歷史修訂版本紀錄。團隊成員之同的代碼交換必須通過客戶端連接到這台服務器，獲取自己需要的文件。每令人如果想獲得其他人最新提交的修訂紀錄，就必須從集中式版本控制系統中獲得。此時，客戶端并沒有整個集中式倉庫保存的所有內容，而是根據用戶的指定命令，一次僅能獲取倉庫中的某一次代碼文件快照。集中式版本控制系統示意圖如圖 8-1 所示。當工程師修改了部分代碼，但尚未完成全部工作時，如果希望將這個中間成果保存成臨時版本，做個備份時，則他通常只有兩種選擇：一是複製一份到另一個本地目錄中；二是直接提交到中央倉庫。而直接提交未經過質量檢驗的半成品到中央倉庫，可能會影響原有的功能，妨礙團隊其他人工作。這種類型版本控制系統的典型代表是 Subversion,簡稱為 SVN。    集中式版本控制系統有兩點劣勢。首先，在網路環境不佳的情況下，同步大量文件時會經常失敗。2007 年底，GoCD 團隊使用 Subversion 作為版本管理工具。軟體產品研發團隊主要在北京工作，銷售人員在美國，售後支持人員在印度斑加羅爾，源代碼倉庫所用的 Subversion 服各器部署在美國芝加哥。有一次，開發人員從北京到斑加羅爾出差，找了一台新計算機，想在當地公司辦公室修改并提交代碼，但手上沒有源代碼。於是，打算將源代碼庫從版本控制庫檢出到這台新計算機上。然而源代碼庫稍大，印度辦公室的網路不穩定，前後花了數個小時，也沒能將代碼從中央服務器拉取到這台計算機上。  其次，集中式版本服務器具有單點故障風險。假如 Subversion 服務器檔機一小時，那麼在這一小時內，誰都無法提交更新，也無法從服務器獲取文件。最壞的情況是，如果服務器的硬碟發生故障，并且沒有做過備份或者備份不及時，則會有丟失大量數據的風險。那次事件以後，GoCD 團隊將源代碼倉庫從 Subversion 遷移到了 Mercurial，它是一款分佈式版本控制系統，簡你為 Hg, Facebook 也在使用它。  8.1.2 分佈式版本控制系統  分布式版本控制系統與集中式版本控制系統的區別在於多個服務器共存，每個人的節點都是一個代碼倉庫，所有的節點都是平等的。在團隊協作過程中，通常會指定某個節點作為團隊的中央服務器，如圖 8-2 所示。    分布式控制系統的特點是：提交（commit)操作都是在本地進行而無須經過服務器，因此提交速度也更快。只有當需要向其他人或遠端服務器做文件提交或同步時，才通過網路將其推送到遠端倉庫或從遠端倉庫拉取。因此，即使在沒有網路環境的情況下，你也可以非常愉快地頻繁提交更新。當有了網路環境的時候，再推送到遠端的團隊代碼倉庫。目前主流的分布式版本控制系統是 Git。  前面提到 GoCD 團隊工程師在印度遇到的情況，如果使用分布式版本管理倉庫，即使網路不穩定，也可以比較方便地完成代碼拉取操作，如圖 8-3 所示。  (1) Bob 通過斑加羅爾辦公網路克隆（clolle）一份 Sara 的代碼倉庫（sara 也在斑加多\n羅爾辦公室）。\n(2) Bob 從芝加哥的中央倉庫中拉取（pull）與本地倉庫有差異的代碼。\n(3) Bob 修改代碼文件，井提交（commit）到本地倉庫，產生一個新的文件版本。\n(4) Bob 將這個新的版本推送（push）至中央倉庫。\n(5) Sara 即可從中央倉庫拉取（pull）所有的差異代碼。    8.1.3 版本控制系統中的基本概念  版本控制系統要解決的核心問題是多人協作過程中的文件版本管理問題。目前所有的版本控制系統中都有幾個相似的概念，用於協調多人協作。在具體討論多人協作模式之前，因爲有多種版本控制系統，所以有必要對這些概念進行統一定義，以方便後續的討論。   代碼倉庫（codebase）是指一個包含一組文件所有歷史修改信息、的還輯單位，通常用於保存有關一個軟體產品或某一組件的所有文件信息紀錄。  分支（branch）是指對選定的代碼基線創建一個副本。人們可以對這個副本中的文件進行操作，而這些操作與原有代碼基線的文件操作是互不影響的。  主幹（trunk/master）是一令具有特殊意義的分支（branch)，通常在創建代碼倉庫時即由版本控制系統默認創建，每個代碼倉庫有且僅有一個這樣的分支。其特殊意文在於其於軟體的開發活動和發布方式緊密關聯，例如，在 SVN 中以\" trunk \"命名的分支和 Git 中以\" master \"命名的分支都是主幹分支，我們將在分支模式進一步討論它們的特殊意義。  版本號（revision）對應在某個分支（ branch ）上的一次提交操作，是系統產生的一個編號。通過這個編號，你可以獲取該次提交操作時的所有文件鏡像。在 SVN 中，它叫作 revision，是一令連續變化的正整數。而在 Git 中，它是一令 40 位的散列值，類似於\"734713bco47d87b··…65ae793478c50d3\"這樣一段字母與數字的組合。為了方便使用， Git 可以使用該散列值的前幾個字符來視別某次提交，只要你提供的那部分 SHA-1 不短於 4 個字符，并且沒有歧文即可。  標籤（tag）是某個分支上某個具休版本號的一個別名，以方便記憶與查找。你可以通過版本控制工具自身提供的命令來創建這個別名。  頭（head）是指某個分支上的最新一次提交對應的版本號。  合併（merge）是指將一令分支上的所有內容與某個目標分支上的所有內容進行合并，并在該目標分支上創建一個新版本號。  仲突（conflict）是指在合併操作時，兩個分支上的同一個文件在相同位置上出現不一致的內容。通常需要人工介人，確認如何修改後，方可合併目標分支。  依據上面的定義，通過下面的字串記憶方式可以唯一確定某個代碼鏡像：\n{代碼倉庫名｝:｛分支名｝:｛版本號｝或者｛代碼含庫名｝:｛分支名｝:｛標籤｝  8.2 常見分支開發模式  目前基於版本控制系統的開發模型，根據新功能開發以及版本發布所用的分支進行分析，主要有 3 種，它們分別是：\n(1）主幹開發，主幹發布（Trunk-based Development&Release);\n(2）主幹開發，分支發布（Trunk-based Development&Branch-based Release);\n(3）分支開發，主幹發布（Branch-based Development&Trunk-based Release)。\n下面我們分別介紹一下它們各自的特點。  8.2.1 主幹開發，主幹友布  顧名思義，\"主幹開發，主幹發布\"是指工程師向主幹上提交代碼（或者每個分支的生命周期很短，如數小時，或少於 1 天），并用主幹代碼進行軟體交付（如圖 8-4 所示）。也就是說，所有新功能的開發，代碼均提交到主幹（trunk）上；但需要發布新功能時，直接將主幹上的代碼部署到生產環境上。    根據交付頻率不同，可以分為低頻交付和高頻交付兩類。低頻交付模型常見於一些周期比較長的大型軟體開發項目，也是一種最古老的軟體開發模式，當時的 IT 行業是以數年或數月為一個交付周期。\n在低頻工作模式下，其主幹代碼總是長時間處於不可用狀態，只有在項目內所有功能的代碼開發完成後，才開始進行軟體聯調和集成測試工作。\n在開發期間，版本控制系統的作用僅僅是確保代碼不丟失，是純粹的代碼備份倉庫。高頻交付子類型是指代碼庫中的代碼發布頻率較高，通常每天都會發布一次，甚至多次。\n高頻交付子類型常見於具有比較完備的交付基礎設施（自動化配置構建、自動化測試、自動化運維、自動化監控與報警等）的互聯網產品團隊，通常也有快速缺陷修復能力，尤其適用於後台服各端產品形態（如 Web 網站或 SaaS 軟體的後台服各）。\n這種模式的優點在於分支方式簡單，因此分支管理工作量較少（如代碼合并成本）,但也存在弱點。例如，針對低頻交付模式，其項目後期的缺陷修復階段，并不是團隊所有人都需要做缺陷修復，會有一定的資源浪費。針對這種情況，很多團隊會釆用後續介紹的\"主幹開發，分支發布\"模式，下面會詳細介紹。\n針對高頻交付模式，由於多人向主幹上頻繁提交代碼，其代碼變動非常快。假如某個開發人員拉出一個私有開發分支，并在該開發分支上進行開發，開發完成後再合并回主幹。此時，他只有兩種工作方式。一是每天從主幹上更新代碼到他自己的分支上。此時該開發人員很可能每天需要一兩個小時將主幹上的代碼與自己分支上的代碼進行合并。二是不做每日更新，而是一段時間後（例如在分支上開發完成功能）之後，再向主幹合并。此時，很可能由於主幹上的代碼變化太大，導致自己這個分支上的代碼已經無法再合并回去了。  無法完成的\"合并任務\":  2011 年，百姓網（一今生活分類網站）的研友團隊只有 12 名工程師。他們使用高頻交付模式，每天早上 7 點做一次生產環境發布。為了對某個重要模塊迸行重大重構，其技木負責人曾經創建了一個專有分支。然而，一周以後，他不得不宣布放棄該分支的所有代碼，因為其他工程師在主幹上己經做了太多的改動，專有分支已經無法合并回主幹。  \"未開發完成的功能代碼不能帶入將要發布的版本裡\"曾被認為是一和最佳軟體質量管理實踐。然而，在這種高頻交付模式下，很難再遵守這一實踐。相反，底該允許提交未完成功能的代碼，前提是不影響用戶的正常使用和發布。為了使未開發完成的功能不影響發布質量，可以使用一些特殊技術管理手段（如開發技術或抽象分支方法等）來處理這類問題，自然，這些手段也會序生一定的管理開銷。詳細方法參見第 12 章。與此同時，高頻交付模式也要求質量保征活動能夠做到既快速又全面。  8.2.2 主幹開發，分支發布    這種開發模式是指(圖 8-5)：   開發人員將寫好的代碼提交到主幹；  當新版本的功能全部開發完成或者已經接近版本發佈時間點的時候，從主幹上拉出一個新的分支；  在這個新的分支上進行集成測試，並修復缺陷，進行版本質量打磨。當質量達標後，再對外發布該版本。  其特點如下：   主幹代碼提交活動頻繁，對保障主幹代碼質量有較大的挑戰；  分支只修復缺陷，不增加新功能；  新版本發布後，如果發現嚴重缺陷，而且必須立即修復的話，只要在該版本所屬的分支上修復後，再次發布補丁版本，然後將分支上的修改合併回主幹即可。也可以在主幹上修復缺陷，然後將針對該缺陷的修復代碼挑出來（ cherry-pick ）合井到該缺陷所在的分支上。Facebook 的移動端產品開發流程就使用後面這種方式。  通常，發布分支的生命週期不應該持續時·間過長，一段時間後應埠終止該分支上的任何操作活動，例如，圖 8-6 中 Vl.01 發佈點之後， Vl.0 分支應該結束。\n在\"主幹開發、分支發布\"模式下，從拉出發布分支開始，到分支代碼達到可交付狀態的時間週期可以作為評估主幹代碼質量的指示器，我們稱之為\"質量打磨週期（ Branch Stabilization Time ）\"。打磨週期越短，說明主幹代碼質量越好。當質量打磨週期極短時，就可以轉換到高頻的\"主幹開發，主乾髮布\"模式。當然，做到這一點並不容易，需要結合本書其他部分所描述的原則、方法與實踐，方能游刃有餘。  該模式的優勢在於：   與將要發布的新功能無關的人員可以持續工作在開發主幹上，不受版本發布的影響；  新發布的版本出現缺陷後，可以直接在其自己的版本發布分支上進行修復，簡單便捷。即使當前開發主幹上的代碼已經發生了較大的變化，該分支也不會受到影響。  其不足在於：   主幹上的代碼通常只能針對下一個新發布版本的功能開發。只要新發布版本的任何功能在主幹上還沒有開發完成，就不能創建版本發布分支，否則很有可能影響下一個發布的開發計劃，開源項目在發佈時間點以及特性功能方面的壓力小一些，因此常常採用這種分支方式；  使用這種開發模式，對發布分支的數量不加約束，並且分支週期較長，很容易出現\"分支地獄\"傾向，這種傾向常見於\"系列化產品簇＋個性化定制\"的項目，例如某硬件設備的軟件產品研發的分支模式，如圖 8-6 所示。    該硬件設備最初只有一種類型，其類別定義為 A ，型號是 x ，對應軟件的發布版本為 Ax1.0 發布以後，客戶提出了同類別不同型號的緊急需求，公司為了能夠快速響應客戶需求，從 Ax l.0 的產品分支上又拉出一個產品分支，名為 Ay 分支，其發布版本為 Ay2.0 。然後又在 Ay 的基礎上開發了一個增強版 Az，對應的分支及時間點如圖 8-6 所示。隨後在 Axl.0  上發現了一個嚴重缺陷，需要增發 A1.01 補丁版本。該缺陷在 Ay 分支和 Az 分支上也同時存在。因此就要將修復缺陷的代碼移植到主幹及 Ay 和 Az 兩個分支。\n該公司以這種管理模式支持了更多類別和型號的產品。如圖 8-6 中，公司開發了硬件產品 B，而其軟件版本是從主幹分支上拉出，並先後發布了 B1.0 和 B1.01。客戶需要在 B 類型上也具有 Ay2 和 Az3 上的部分新功能特性，於是，公司決定從 Ay2.01 和 Az3.0 的分支上移植該新功能的代碼到 B 分支上。  隨著硬件類 別和型 號的不斷衍生，研發團 隊效率越來越差。如圖 8-6 中的虛線處所示，團隊終將疲於在分支間移植代碼和測試。這與《大規模敏捷開發實踐：HP LaserJet 產品線敏捷轉型的成功經驗》一書中描述的 HP 激光打印機固件團隊在 2008 年的狀態相似。該團隊僅有 5% 的資源用於新功能的開發，而各分支間移植代碼會佔用團隊 25%的時間，如圖 8-7 所示。  8.2.3 分支開發，主幹發布     這種模式是指(圖 8-8 ) ：   團隊從主幹上拉出分支，並在分支上開發軟件新功能或修復缺陷；  當某個分支（或多個分支）上的功能開發完成後要對外發布版本時，才合入主幹；  通常在主幹上進行缺陷修復，質量達標後，再將主幹上的代碼打包發布。  這種模式的優勢在於 ：   在分支合井之前，每個分支之間的開發活動互相不受影響；  團隊可以自由選擇發布 i 哪個分支上的特性；  如果新版本出現缺陷，可以直接在主幹上進行修復或者使用 hotfix 分支修復，簡單便捷，無須考慮其他分支。  它的優勢也會導致不良後果，即為了分支之間盡量少受影響，開發人員通常會減少向\n主幹合併代碼的頻率，從而推遲了發現各分支中代碼衝突的時間，不利於及時進行代碼重\n構，如圖 8-9 所示。  該主幹上的代碼中原有一個方法簽名為 handleY(int b）。 Alice 和 Bob 各自領取一個新功能的開發任務，並創建了對應的一個分支 A 和 B ，而且，在新功能開發完成之前，兩人都沒有向主幹合併代碼。為了完成自己的新功能， Alice 對 handleY 方怯進行了修改，將其簽名變更為 handleY(int  ， boolean c）。同時， Bob 在自己的分支上也修改了 handleY(int b) 的內部實現。主幹上發生了兩次 hotfix ，兩人都將主幹的修改合入了自己的分支上。在這之後 ， Bob 又從 handleY(int b） 中抽取了一個方告， 簽名為 findX(int   a）。此時 Alice 開發完成了自己的新功能，將代碼（從 al 到 a4 ） 合入主幹。當 Bob 打算提交 代碼到主幹時，他需要將 Alice 的 4 次代碼變更與自己的 5 次變更合併在一起。由於 Alice 修改較大，這個合併很可能成了非常大的包袱。Bob 發現，Alice 不但修改了很多文件，而且對方戰 handleY（）進行了較大的重構。然而，這些還只是文本上的衝突，比較容易發現和修正。風險更大的則是語義上的衝突，即程序運行時的邏輯衝突。這類情況的發生會令團隊成員進行代碼重構的意願大大下降，從而令代碼的可維護性越來越糟糕。    不頻繁的集成導致的巨型代碼合併  如果分支過多，那麼衍生出來的問題是：當某個分支的生命週期（即從主幹拉出分支那一時刻至將其再次合入主幹這段時間週期）過長，代碼合併及驗收成本會快速增加。成本增加的數量與其生命週期中合入主幹的分支數量成正比。  若想成功使用這種模式，其關鍵點在於：   讓主幹盡可能一直保持在可發布狀態；  每個分支的生命週期應該盡可能短：  主幹代碼儘早與分支同步；  一切以主幹代碼為準，盡可能不要在各特性分支之間合併代碼。  另外，根據分支的存在周期和目的，\"分支開發，主乾髮布\"模式還可以進一步分為兩種子類型，它們分別是特性分支模式和團隊分支模式。   特性分支模式在開發過程中，允許多個開發分支同時存在，且每個分支對應一個功能特性的開發工作。當該特性開發完成後，立即合入主幹，其他尚未合入主幹的特性分支需要從主幹拉取主幹代碼，與自己分支上的代碼進行合併後，才能再合回主幹。這種模式為特性分支模式，如圖 8-1O 所示。    該模式的目的是：  讓團隊更容易在\"特性\"這個層次上並行工作，同時保持主幹的穩定可發布狀態。其優勢在於每次發布的內容調整起來比較容易。假如某個新功能或者缺陷在版本發佈時間點之前無桂完成，則不必合入主幹中，也不會影響其他功能的發佈時間點。  但這種模式也有不足：如果特性分支過多，會帶來比較多的合併成本。例如，每當某個特性分支開發完成打算合入主乾時，都需要與主幹的代碼合井，並進行質量驗證。一旦主幹代碼的質量驗證通過，其他分支此時都應該從主幹上拉取最近的通過質量驗證的新代碼。否則，如果在特性開發完成後再與主幹合井，那麼這種一次性合併會帶來較大的工作量和質量驗證工作。如圖 8-10 所示，特性 2 分支需要合併特性 1、3 和 4 的代碼。  假如有多個特性同時開發完成，怎麼辦？下面是兩種極端的做法。   所有已完成的特性分支一同向主幹合井，然後再共同設怯讓主幹代碼達到可交付狀態。這種方式通常會被特性團隊排斥。因為共同合併後，多方代碼交織在一起，出現的缺陷可能很難快速定位和快速修復。  所有已完成的特性分支排成隊列，以順序方式合入主幹。每個特性分支向主幹合人代碼後，必須使主幹上的代碼達到可交付狀態後，下一個特性分支才可以合入。這種方式通常是特性分支的常見做氈，也是特性分支的優勢所在。但所帶來的問題是，多個特性分支按排隊順序進行合井，會導致排在隊尾的特性分支等待較長的時間 。  如果想讓特性分支方式更好地工作，需要做好下面的管理。   每個特性分支的生命週期都應該很短，分支上的開發和測試工作盡量在 3 天內完成。這要求盡可能將\"特性\"拆分成小需求。關於需求拆分的方怯，參見第 6 章。  開發人員每天從主幹上拉取最新的可交付代碼，與自己的分支合井。  不要從其他特性分支上拉取代碼。    2.團隊分支模式  團隊分支可以看作是特性分支的一種特殊情況。也就是說，一組人一起在同一個分支上進行開發工作，而且該分支上通常包括一組相近及相關的特性集合的開發。由於是一組特性集合的開發，因此其分支存續時間比特性分支的存續時間長。  這種分支模式通常出現於規模較大的團隊（ 40 人以上）共同開發同一款產品，團隊被分成多個組，每組開發不同的系統組件。只有當一系列功能特性開發完成後，才對外發布新的軟件版本，很容易成為典型的瀑布開發流程，如圖 8-12 所示。    團隊分支模式在通信公司的產品研發或大型客戶端軟件產品研發中比較常見，例如第 14 章的案例中，團隊研發管理模式改進之前，就使用這種開發模式。成功應用這種模式的關鍵在於：   每個團隊儘早向主幹合入高質量的代碼，即使不馬上發布：  向主幹合入代碼後，盡快使其達到可交付狀態：  其他團隊儘早從主幹拉取可交付狀態的代碼，與自己分支上的代碼合井。  分支策略  8.3 分支模式的演化  8.3.1 三駕馬車分支模式  Chrome 瀏覽器於 2010 年使用此分支模式    開發 Branch 擁有足夠多的新功能 (或者準備 Release 時), 將該 Branch 使用   Cherry Pick  撿到 Pre-Release 分支上  Pre-Release   BugFix  Document  Deployment  Feature  Pre-Release 達到 Alpha 等級後 → 發布 Alpha 版本 (給予極少部分使用者先行體驗) → Beta 版本 (給予嘗鮮用戶進行體驗) → 收集存在的質量與 Bug 問題與修正 → Beta 版本穩定 → 合併至 Release 分支 → RC 版本 → RC 版本穩定 → 正式版本  8.3.2 GitFlow    Master  (Main) 分支是正式版本的發布分支   Release  分支用於品質打磨的預發布分支，如果 Release 的品質達標，將 Release 合併至 Main 分支與 Development 分支   Development  分支為 Feature 新功能整合的分支   Feature  分支是為了新的功能，開發人員從 Development 分支上 Checkout 出來的分支。當 Feature 開發完後，合入 Development 分支。    Gitflow 為特性分支模式與三駕馬車分支模式的組合   優點: 分支定義明確  缺點: 分支較多，具有特性分支的不足  8.3.3 GitHubFlow   名稱來自 GitHub 團隊的工作實現  對於開發者的開發紀律比較嚴格，對於品質保證的要求也較高。  Flow   從 Master (Main) 建立一個新分支, 以特性 (Feature) 或 缺陷 (Bug) 的編號 (Issue Number) 命名該分支。  在這個新分支上撰寫並提交程式碼。  功能開發完成後，並自行測試通過，建立 Pull Request (簡稱 PR)  其他開發人員對這個 PR 進行審查 (Code Review)，確保程式碼品質沒問題後，合併回 Master (Main)    如果 Feature 分支存在時間很短，則此模式可被認為是高頻率的   主線開發，主線發布  的模式。   8.4 分支策略  企業可以依照以下類型與條件，來確定適合團隊的分支方式   開發或維護的軟體產品類型  發布的頻率  團隊成員能力  基礎架構的等級\n   自動化測試  程式運行環境的管理  團隊紀律性  8.4.1 版本發布模式  版本發布的基本模式有三種:   專案制發布模式 ( Project Release Mode )  發布火車模式 ( Release Train Mode )  城際快線模式 ( Intercity Express Mode)    專案制發布模式  在軟體研發規畫中，先確認好某一版本需要的功能特性數量，只有當該次版本所需的功能全部開發完成並達到相對應的品質標準後，才能發布該版本。  發布版本的時間間隔並沒有強制的規定，而是根據新版本要求的功能集合開發完成並達到發布標準後，對所需的時候進行評估後決定。  此模式為最古老的發布模式，針對一個特定版本，確定了版本的功能數量與品質標準後，再估計版本交付的週期，等於先固定了功能數量與品質要求，因此團隊可能交付的時間點也就相對固定。  Pros:   可以確切知道每個版本包括哪些具體功能，有利於商業套裝軟體的銷售模式 (賣版本和授權，收取維護費用，當有心功能版本發行後，再向客戶收取新版本的升級費用。  符合人們的安全生產習慣，也就是不能把未完成的功能帶到即將發布的版本中。  Cons:   專案交付周期較長，參與人員眾多  如果開發週期因為某些原因導致需求變更 (如增加需求、修改原本需求實作方式或更換需求) 時，需要重新評估專案的交付時間，會連動影響那些原本能夠如期交付的需求。  需要等待所有需求全部實現完成後才能一起發布    發布火車模式  常見於大型套裝軟體。大型傳統軟體產業通常有許多產品線，各產品線之間存在非常複雜的相互依賴關係。為了能夠讓各個產品線協同發布。這些企業會為每條產品線都制定好每個版本的發布週期，也就是每個版本都像火車一樣，事先計畫好什麼時候發車。  \n💡 車是按照時間發的，能趕上火車的就一起走，趕不上車的，就等下一班車。\n    為了能夠準時發布，要求所有參與到該版本的開發團隊必須對齊該版本的每個開發階段。這種嚴格的時間一致性要求是因為如果該產品線的時間變更會引起其他產品線的時間變更，而這些更改也可能會影響到共享的集成測試環境的分配。  大多數的情況下，由於計畫和各產品集成與依賴關係，因此發布火車通常以一季為單位，但不會超過 10 個月。( *Note: 本書作者以大型企業來做舉例，但 Release Train Mode 不一定依照此週期為規範。)  當發布火車時間表時，發布管理團隊通常與負責個產品開發的團隊進行提前溝通，討論要發布那些內容，有時甚至需要幾個月的時間，將其結論發布在企業版本表中。    圖 8-17 為 LiberOffice 的發布火車時間表。提前制定出時間，目的就是讓各種業務與技術部門有足夠多的時間進行計畫，以便評估出各種依賴與影響。  制定發布計畫是一個 ˊ 非常正式與結構化的過程，需要有各種格式化數據以確保參加的團隊能夠對正式發布的可行性做出判斷。數據包含發布的詳細資訊( 相對標籤、名稱、部屬日期、風險級別、發布類型-企業,計畫或投資組合)、整個生命週期的各個階段及預定日期(如圖 8-18 )、每個階段要完成的活動與任務、里程碑時間、品質要求、以及管理發布火車的主要負責人。    Pros:   對於企業來說，可以通過並行多台車的方式，將突發需求排入一台發布火車  用戶可以提前體驗最新版產品提供的新特性，而不必影響原本生產線上的舊版本。體驗之後在決定要不要應用於自己的生產環境中  即便已經決定將這個新版本用於自己的生產環境中，也可以等到新版本成熟穩定之後再這麼做  Cons:  如果參與團隊的人數越多，溝同協調的成本會越高   3 城際快線模式  城際快線模式是指在發布模式三要素中，固定   時間  與   品質  兩個維度，且時間周期較短(一周，一天，甚至更少)，針對那些在 0 發布時間點已達到對應品質標準的特性進行一次發布。  跟火車發布的區別在於兩點:   發布周期較短，通常是兩周以內  負責功能開發的團隊可以自己選擇搭乘哪台城際快線，而不必在很久之前就先確定把時間確定下來。  這種模式常見於提供網際網路服務或 SaaS 服務的軟體公司。好處在於減少了團隊之間溝通協調成本。因為每個人都知道每次發布的具體時間點，所有工作任務都可以按照這個時間點提前進行協調。而且即使功能沒有及時趕上最近一次的版本發布，團隊也能知道這個功能是否可以在下一次發布的時間進行發布。Facebook 的 Web 網站於 2013 年部屬推送頻率以達到每天發布兩次，每周一次大版本。如圖 8-19 所示。    每個周日從主幹上拉一個發布分支，自動化測試驗證通過後，在公司內部人員開放(在公司內訪問，重定向到 latest.facebook.com)。運行過程中如果出現問題，可以在主幹上修復，然後分撿到 (CherryPick) 發布分支上。發布分支上代碼每天兩次更新到 latest.facebook.com，供公司員工內部開發使用。如果版本穩定，就對外發布，同樣是每天兩次。  自 2017 年開始 Facebook 的發布策略已經從一天兩次的\"主幹開發，分支發布\" 改變為平均每天發布 9~10 次的 \"主幹開發，主幹發布\"模式。  城際快線模式的優點有兩個:   每個人都非常清楚各個時間點  更加聚焦生產品質  缺點:   發布頻率較高，因此未完成功能的代碼也會一同發布出去  對於程式碼要求品質較高，需要強大的品質基礎設施保證。  使用城際快線模式，間隔多長時間發出一趟合適? 在不影響用戶體驗，不增加成本且合規的前提下，讓發布週期盡可能縮短到令你感到有些緊張的節奏，例如:每個月發布一次版本，現在可以把兩周當作一個目標。  8.4.2 分支策略與發布周期的關係   分支策略與版本發布周期有一定的相關性    分支策略與版本發布周期之间有一定的相關性，如圖 8-20 所示   軟體開發週期極長的“專案制”團隊和軟體發布頻率的極高 “城際快線模式”團隊會使用   主幹開發，主幹發布  的分支策略  次之的團隊會使用   主幹開發，分支發布  的策略  最後的區間使用   分支開發，主幹發布  的分支策略  這之間不是絕對的，其中會有很大的重疊部分，通常會受到團隊成員人數，產品架構與品質保障基礎設施等影響  8.5 小結  每個分支策略都有其優點與挑戰。它對於發布頻率以及每次發布的效率也有較大的影響。  目前的發展趨勢為: 軟體的發布的頻率越來越高，發布週期越來越短，矽谷頂級的網路公司大多採用 \"主幹開發\" 或者高頻的   GitHub Flow  分支模式。  一個企業到底選擇哪種分支策略，需要依據團隊的具體情況來決定。如果相對應的基礎設施不足 ( 如軟體架構、人員能力、和工具平台成熟度)，盲目地提高發布頻率，縮短發布週期會造成不必要的損失。   持續交付 2.0  提倡持續極盛的分支策略，選擇分支模式的原則有以下幾項:   分支越少越好，最好只有一條主幹  分支生存週期越短越好，最好在 3 天以內  在業務允許的條件，發布週期越短越好。  企業管理者應該遵循   持續交付 2.0  的思想、理念與原則。制定合理的改善目標，促進公司 IT 交付能力不斷提升，才能夠跟上時代的發展。  Additional Reference:   Git 常用的分支管理模型   DevOps 技术：主干开发   什么是 Release Train?",{"id":125,"path":126,"dir":89,"title":127,"description":7,"keywords":128,"body":135},"content:4.cicd-2.0:9.chapter9.md","/cicd-2.0/chapter9","09 持續整合",[129,130,131,132,133,134],"9.1 起源與定義","9.2 六步提交法","9.3 速度與品質權衡","9.4 在團隊中實施持續整合實作","9.5 常見執行問題","9.6 小結","  9.1 起源與定義   Chrysler Comprehensive Compensation System(C3)，是一個用戶數達 87000 名的綜合人事與工資系統  1994 年開始開發，預計 1999 年上線，1996 年 Kent Beck 被邀請來挽救這個項目，並採用新的開發方式(極限編程方法)\n   遇到的問題：要把系統的不同部分整合起來，並且讓系統運作，常常需要 1~2 週的時間  極限編程：提高整合頻率，每次合併的東西較少，減少整合需要的時間，整合過程中的問題較好排解(Debug)  方式：開發人員撰寫 shell 腳本，這個腳本定期去訪問儲存庫，只要發現有新的程式碼被提交，就將程式碼自動拉取到建構主機進行編譯  但是最後上線的版本僅能支撐 10000 人使用，2000 年系統被捨棄  9.1.1 原始定義   每日構建(daily build)、每晚構建(nightly build)\n   每天定時自動執行一次軟體構建工作，將版本控制系統最新版本的程式碼在建構環境(沒有安裝集成開發環境的乾淨機器)下進行編譯、鏈結、打包的過程  有助於確保開發人員明確了解前一天編寫的程式在整合的過程中是否發生問題，幫助開發團隊確定新的程式碼變更是否破壞原有功能  「持續集成是一種軟體開發實踐，團隊成員頻繁地將他們的工作成果集成再一起(通常每人每天至少提交一次，這樣每天就會有多次集成)；每次提交後，自動觸發一次包含自動化驗證的構建任務，以便能儘早發現集成問題」 —— Martin Fowler(2006)  9.1.2 一次集成過程   開發人員提交程式碼到儲存庫  建構主機定期輪詢程式碼儲存庫  有新的程式碼，下載到建置環境  根據建置腳本，執行建置  建置完成後上傳結果    9.2 六步提交法   開發人員 check out 最新建置成功的程式碼  修改程式碼實作需求  第一次個人建置(Build)：建置自己開發的東西(確保自己開發的東西沒問題)  第二次個人建置：從主幹中下載最新建置成功的程式碼(如果這段期間有其他人更新)，並且進行建置(自己開發的東西＋這段期間其他人的東西)\n   確保要上去主線的程式碼是沒問題的  提交程式碼  第三次建置：如果程式碼通過自動化測試、靜態程式碼檢測，則將該程式碼並回主線，如果失敗則進行修復    9.2.1 四個關鍵點   六步提交法中的三次驗證有什麼作用   三次驗證的腳本必須一樣  第一次驗證：確認開發者撰寫的內容是否正確，內容為自己  第二次驗證：確認與最新版合併後系統是否正常，內容為自己＋他人  第三次驗證：在乾淨受控的環境中執行與第二次驗證一樣的腳本，確保開發人員提交完整且無程式品質問題，內容為儲存庫最新版本\n   如果第二次驗證有過，第三次驗證沒過，代表 1.自己這次程式碼提交不完整 2.自己的建置環境跟團隊有差 3.團隊成員有提交新代碼，但是自己沒發現  個人驗證(第一次驗證、第二次驗證)一定要做兩次嗎？   第二次驗證目標是驗證自己改的程式碼跟其他人提交的程式碼合併再一起，也符合預期  如果第一次有過，第二次沒過，代表其他人提交的內容影響到這次的開發內容  信心爆棚的工程師可以跳過個人第一次驗證，直接做第二次驗證即可  如何確保在提交前執行個人建置   在代碼合併到主線時，強制進行第二次個人驗證  每次建置應該包含哪些品質檢驗內容   單元測試、程式碼靜態掃描(白箱)、程式碼規範檢查(code style)  建置驗證測試(build verification test)   建置結束產生的二進制內容是否包含正確的內容 ex.配置文件的完整性  這個建置結果是否能夠正常安裝並且啟動運行  運行後最基本的功能是否可以使用 ex.登入  針對接手舊案(大量遺留代碼的儲存庫)，使用程式碼靜態掃描可能會出現一堆錯誤，該怎麼處理？以下提供兩種解法   減少規範，關注重點：提取最重要的程式碼規範，早期只關注嚴重類型的問題，以後在逐步增加程式碼規範  執行「童子軍營地」原則：遺留代碼多，且系統已經上線一段時間，且最近不會動到那邊的程式碼，則暫時不去修(當作沒看到)，有動到那部份的程式碼，則考慮進行修復，做到每次提交時，沒有新增問題，最好問題可以逐步減少   💡 童子軍營地原則：離開營地前，確保營地和你使用之前一樣乾淨，能在乾淨一點就更好了  9.2.2 同步異步模式   主要的差異是在程式碼提交到主線時(六步提交法的第五步)，後續開發人員的行為差異  同步：開發人員需要等到建置完成後，確保通過才進行下一個開發任務  異步：提交後就可以開始下一個開發任務  Kent Beck 不建議採用異步，因為可能存在浪費，ex.當開發人員已經在做下一個任務時，被通知上一個驗證沒過，需要調整，開發人員需要回想當初做了什麼  9.2.3 自查表   可以從以下六個面向來檢查是否自己已經符合持續整合的最佳狀態  主線開發，頻繁提交：開發分之生命週期不超過三天  每次提交都是一個完整的任務  讓提交的建置都可以在 10 分鐘內完成：尤其使用同步模式(參考 9.2.2)  提交建置失敗後應禁止團隊成員提交新的程式碼，也不允許其他人 check out 該程式碼\n   當團隊成員提交代碼引起建置失敗，說明系統整體品質可能存在問題，因此整個團隊不應該繼續提交新的程式碼，而是集中火力解決這個問題  立即在十分鐘內修復已失敗的提交建置，否則該主線分支退回上一個提交點\n   因為問題被修復之前，這個分支上的內容無法上到 release，導致其他人就算提交內容，這個分支的內容還是不能用  為了讓其他人的內容可以持續提交，出問題的原開發有足夠的時間進行思考與修復，捨棄這個有問題的提交  自動化建置驗證通過後，對軟體品質有較大的信心\n   反例情境：團隊並不覺得使用持續整合有什麼用處，因為他們有很多自動化測試案例，但是隨著系統功能增加，新增的測試案例卻很少，而且現有的測試案例測試失敗後，如果該問題太難修復，就刪除這個測試案例(解決提出問題的人，就是解決問題 😀)  9.3 速度與品質權衡  9.3.1 分級建置   隨著系統功能擴展，自動化測試的數量會越來越多，超果我們可以忍受的建置時間(10 分鐘)  可以將自動化測試拆成兩個部分，將運行速度較快，重點驗證項目放入提交建置裡面，運行較慢、不常驗證失敗的測試案例，放在次級建置驗證的內容  次級構建失敗，應該立即發出通知，並且立即修復，在修復之前不得提交新程式碼  9.3.2 多人同時提交的建置   如果目前次級建置(每次可能需要執行 30 分鐘以上)進行中，新提交的程式碼就不執行次級建置，只做主要構建  直到次級建置完成後，新提交的程式碼(合併到儲存庫)，才會觸發下一次的次級建置，中間的次級建置全部被省略\n   1.節省建置資源 2.同時進行如果前者壞了，後者執行的內容全沒意義    9.3.3 雲端建置的威力   編譯過程主要分為預編譯、編譯、鏈結  可以透過雲端叢集的概念同步執行，減少整體建置時間的為「編譯」，各機器完成編譯後，再交由一台主機做整合的鏈結    9.4 在團隊中實施持續整合實作  9.4.1 實作五步法   建置腳本化，搭建持續整合框架\n   選擇一款持續整合工作，目前比較夯的是 Jenkins  在該持續整合工具上建立一個建置任務，可以從你的儲存庫拉取程式碼  寫一個腳本文件，可以自動完成系統的編譯、建置、打包  修改持續整合工作上的任務(第二步)，讓他可以調用第三步的腳本  向儲存庫提交一次程式碼，驗證持續整合工作可以發現新代碼並拉取正確的程式碼版本，運行指定的腳本  添加已有的自動化驗證集合\n   增加自動化測試案例  加入程式碼規範掃描\n   SonarQube、Android Lite、CCCC、cppcheck、Clang、Pclint  選擇利於持續整合的分支策略\n   如果分支過多，則不利於團隊持續整合的效果  建立六步提交法  持續優化\n   初期整個機制運作正常，但隨著系統功能增加，整個過程出現了問題  ex.測試案例本身的程式碼品質不良，導致隨機的測試失敗  優化編譯打包的時間  調整程式碼分支策略  自動化測試案例的分級(ex.哪些應該放在次級構建)  優化程式碼規範掃描(ex.調整規則)  生成數據報告，方便團隊了解目前的程式碼品質狀態  工程師改變習慣，並提升技能\n   要求工程師主動提早整合，非推遲整合(不要一大包才提 PR，一個 PR 不要包含多個任務)  學習持續整合的工具如何使用    9.4.2 分支策略與部署流水線   主線開發，主線發布：開發團隊只要架設一個持續整合服務，關注主線的程式碼變更即可  主線開發，分支發布：當新增分支時，需要加增這個分支的部署流水線  分支開發，主線發布：(只有一個儲存庫，但是有多個系統)每個分支都需要有部署流水線，當有人併入主線觸發主線部署流水線，當分支不需要時，同時可以砍掉其部署流水線  多建置集成：系統來自於多個儲存庫，個別建置完觸發產品部署流水線        9.5 常見執行問題   團隊原有工作習慣，例如\n   開發人員在自己的開發任務完成之前不希望與別人的程式碼進行整合  測試人員希望在整批的開發完成後再進行集中測試  對於程式碼靜態掃描問題視而不見，1.團隊對於掃描規範沒有大家都認同 2.問題太多沒時間修  自動化測試案例不夠，導致採用人工測試，必須開發完才有辦法整批測試，無法在每次提交時就進行測試  技術研發管理缺乏導致，例如\n   開發、測試和維運環境沒有分離或分離不徹底，多人共用測試環境  各類測試環境的準備工作很複雜  9.6 小結   主線開發，高頻提交代碼  每次提交都是完整有意義的任務  提交建置階段在十分鐘內完成  提交建置失敗後，立即修復，其他人不得在修復前提交代碼  應該在十分鐘內修復失敗，否則放棄這次的提交  自動化建置成功後，團隊對於系統品質比較有信心",{"id":137,"path":138,"dir":89,"title":139,"description":139,"keywords":140,"body":147},"content:4.cicd-2.0:10.chapter10.md","/cicd-2.0/chapter10","Chapter 10 自動化測試策略與方法",[92,141,142,143,144,145,146],"10.1 自動化測試的自身定位","10.2 突破傳統自動化測試的困境","10.3 自動化測試的實施策略","10.4 用戶驗收自動化測試要點","10.5 其他質量檢查方法","10.6 小結","  前言  想發揮持續整合的真正作用，一個至關重要的部分就是自動化測試策略。  本章主要討論軟體進入生產環境之前的   「自動化測試管理」  ，包含：   自動化測試的定位：\n   包含哪些測試，怎麼分類？  哪些可以被自動化？  本章節主要探討哪些測試？  傳統自動化測試的困境：\n   過去常見的一種自動化測試策略模式，它哪些問題？  作為良好自動化測試的一個反例  如何實踐良好的自動化測試\n   自動化測試的分層  測試案例的管理、從何開始做自動化測試…  10.1 自動化測試的自身定位  測試領域的4類活動   「問題認知」：對業務問題本身的理解與認識 (了解測試的目標是什麼)  「分析」：分析、設計測試流程或實作測試程式碼 (以最低的測試成本，達到驗證的目標)  「執行」：執行測試，得到測試結果數據  「決策」：根據測試結果進行下一步行動判斷   其中的「執行」存在大量重複性勞動，自動化測試能夠降低此成本  回歸測試：重複執行以前的全部或部分相同的測試工作\n   確保過去開發的功能服務都有正常運作  產品生命週期越長，回歸測試案例庫就越大，回歸測試的工作負擔越重  Brian Marick 測試4象限  \n有很多不同的測試，如何分類？哪些測試可以被自動化？\n     四個面向\n   面向業務專家：能與業務專家無障礙溝通 (ex: PM、使用者)  面向技術人員：易與技術人員達成共識 (ex: 開發工程師)  支持編程：目標是為了幫助研發團隊檢查功能需求是否開發完成 (ex: 功能性和UI是否一致)  評判項目：目標是為了找出產品是否有缺限 (ex: 產品是否滿足客戶的實際需求)  四個象限\n   第一象限：(手動) 用戶演示demo、可用性測試、探索性測試  第二象限：  (自動化)  功能驗收測試 => 以用戶的角度  第三象限：  (自動化)  系統集成測試、組件測試、單元測試 => 系統角度，技術實現的驗證  第四象限：(自動化/手動) 非功能驗收測試(性能測試、容量測試、可靠性測試…)  本章主要討論第二、第三象限的自動化測試  10.1.1 自動化測試的優勢  \n相較於手動測試，自動化測試有哪些優勢  \n(機械自動化 v.s. 人的手動執行)\n  「減少失誤率，提高準確性」:   機械不受情緒、經驗的影響，每次執行都重覆相同的動作並紀錄詳細的結果  「節省時間和執行成本」   在長生命週期、發佈頻率高的產品中，時間成本的節省相當明顯  「提升測試覆蓋度」:   自動化測試可以增加測試的深度和範圍，以提高軟件質量  ex: 內存使用、內部程序狀態…  「做手動無法完成的測試」:   手動測試難做到如摸擬成千上萬個虛擬用戶同時間與軟體進行互動 (mock)  「為開發人員提高質量反饋速度」:   讓開發人員可以方便的執行，快速發現問題  「提高團隊士氣」:   讓團隊可以將時間花在更具挑戰性和更有價值的活動中  ex: 探索性測試  10.1.2 自動化測試所需的投入  \n事物都具有兩面性，自動化測試帶來收益的同時，也會產生成本\n     成本  說明    工具投入成本  測試工具、測試框架的研究與培訓   測試案例維護成本  功能調整的同時，需維護相對應的測試案例   專業技能人員的成本  測試編程、設計規劃的經驗、培訓   設備資源的投入  自動化測試無法完全替代手動測試  保留手動測試所需的測試環境，也要為自動化測試的執行準備相應的測試環境  手動測試與自動化測試的不同  \n自動化測試有很多優勢，但手動測試依舊不可完全被取代\n  \n為什麼？兩者的本質上有哪些不同？\n   自動化測試   無主觀意識，它只做腳本要求它做的事  比較沒有無主動觀察、主動認知和分析的能力，沒有創造力  擅長回答：系統是否照我們「預先設計」的方式正確運行？  ex: 用戶功能驗收測試  手動測試   有人為主觀意識的介入  具主動觀察、學習、分析、創造力  擅長回答：我們是否正在開發一個正確的，滿足用戶期望的軟體系統？  ex: 探索性測試  自動化測試與手動測試的成本收益對比示意圖    10.2 突破傳統自動化測試的困境   自動化測試常作為提測前的檢驗標準 (提交給手動測試之前，先運行自動化測試案例)  傳統自動化測試的創建流程     測試分析者 => 分析測試案例，並文檔化(撰寫測試流程的文檔)  測試執行者 => 照測試流程文件執行手動測試，發現BUG向開發人員報告  開發人員   => 修復bug  測試執行者 => 再次執行測試，直至驗證通過  測試分析者 => 從測試案例文檔中選出一些重要且變動可能性較小的測試案例  自動化測試開發者 => 對挑選出來的測試案例編寫自動化腳本，並歸入自動化回歸測試庫  10.2.1 傳統自動化測試的特點  1. 測試案例執行成本過高   處理流程較長、要準備的測試案例較多，需花費較多時間、精力  多為黑盒自動化測試案例，摸擬真實用戶的介面操作來驅動的系統集成測試  2. 自動化測試執行頻率低   通常是在軟件開發完後(提測階段)、或系統回歸測試(重覆以前全部或部份的測試工作)用  3. 質量反饋滯後   大部份的測試案例是回歸測試案例，無法對當前正在開發的新功能進行測試  為了能安全執行，經常會通過 sleep 指令讓流程暫停，再繼續下一流程，因此很耗時  4. 測試環境準備成本高   完善的測試數據集  整套的運行環境  測試環境的搭建手動操作較多，甚至需要多人的參與  5. 測試結果可性度低   受機械硬體配置、網路狀況、案例處理時間長度等影響，可能會產生隨機失敗  若界面需求的改動沒有即時通知測試團隊對測試進行修改，也會造成測試失敗  這些失敗都會造成團隊可能會更傾向於忽略這些自動化測試案例的存在  6. 人員依賴性強   編寫自動化測試案例很大程度依賴少數測試開發專職人員  適合傳統自動化測試的團隊   適合用于發佈版本週期較長，使用傳統瀑布開發方法的團隊  現代軟件版本迭代速度越來越快，這種自動化測試案例的投資回報率越來越低  名詞解釋：   黑箱測試(ex: 功能驗收測試)\n   把測試軟件當成黑箱，不在乎內部的實作，只在乎輸入輸出結果是否正確  根據用戶說明書、需求文檔，去進行操作、輸入測試  優點：站在用戶的立場進行測試  缺點：無法對程序內部特定的內容進行測試  白箱測試(ex: 單元測試)\n   把軟體當成透明的盒子，在乎程式內部的運行邏輯，對其結構進行測試  優點：對程式內部的問題進行覆蓋(盡量作到能夠覆蓋到每一行原碼中)  缺點：無法檢驗程式外部的特徵，也無法站在用戶的角度進行測試  10.2.2 自動化測試的分層   本章聚焦的測試類型為\n   「用戶驗收測試」(用戶角度) 第二象限  「系統集成測試」(系統角度) 第三象限  傳統自動化測試方式產生的測試案例類型通常偏上層測試\n   形成測試捲筒冰淇淋 (頭重腳輕) => 不利於持續整合\n   被測範圍較大：執行時間成本、準備成本都很高  測試捲筒冰淇淋    「快、捷、時、信」  \n良好的自動化測試實踐，應該要「快、捷、時、信」\n     項目  說明    快速  測試案例的執行速度要快  (持續整合的要求是，最好在十分鐘以內，不要超過15分鐘)   便捷  每名工程師都可方便執行測試，不會影響到他人   及時  一但功能發生變化，就能馬上告知本次代碼變更對軟體質量的影響   (若沒有一直開發新測試案例對新功能即時驗證，會導至反饋速度的降低)   可信  不存在隨機失敗的現象。  持續整合實踐要求一但自動化測試案例失敗，必須立即修復  隨機失敗會大大增加工程師的無效投入，並降低工程師對持續整合的信心  \n透過傳統自動化測試的方式，能達到快、捷、時、信嗎？(困難)  \n快 => 降低時間成本  \n信 => 提高穩定性\n   開發上層測試案例成本較高，穩定性差\n   被測對象範圍較大，測資準備工作量大，執行時間久  有外部依賴，不穩定性也高  降低成本：\n   減少上層測試案例數量  增加下層測試案例數量  形成穩定的正三角形    10.2.3 不同類型的測試金字塔  \n軟體架構發展的趨勢朝「服務化」和「微服務化」發展   \n掀起大規模分散式應用服務浪潮\n   服務化：軟體服務由「單體應用架構」拆分成「服務導向的架構(SOA)」\n   服務之間透過RPC等方式進行溝通(RPC：Remote Procedure Call, 遠端過程呼叫)  微服務化：服務導向架構 => 微服務架構/微核架構\n   後台服務化模組被拆分成很多的微服務 (微服務架構)  客戶端軟體向元件化或微核架構發展   (微核架構)    1. 微核架構的測試金字塔     端到端自動化測試\n    「摸擬介面操作」  來驅動的自動化測試  API自動化測試\n   UI層之下，   「透過API介面」  來驅動下層業務邏輯的自動化測試  元件或外掛間服務的介面自動化測試\n    「兩個或兩個以上元件(外掛)間」  的功能正確性  元件測試\n   對   「單個元件或框架」  本身進行品質驗證  自動化單元測試\n   最細粒度的自動化測試  2. 微服務架構的測試金字塔     單元測試：   測試目標：驗證   「業務邏輯單元」  的正確性，不在乎上層程式要實作什麼功能  什麼是單元？\n   軟體中最小可測業務邏輯單元 (一個函式、一個Class)  對外部依賴(如檔案系統、網路等)比較少  測試運行時不需系統處於執行狀態  測試運行速度快  業務元件或服務測試   測試目標：驗證   「單個元件或服務」  的行為是否符合設計預期  什麼是元件？\n   由多個最小業務邏輯單元組成  可能與本系統「內部」的其它元件互動，也可能負責與「外部」整合點進行互動  ex: GoCD 中的類別 MaterialService，就是負責與Git或Subversion打交道的一個元件  測試通常不需要系統處於執行狀態，但可能涉及外部依賴(檔案系統、網路、資料庫等)  執行進度可能比單元測試稍慢  契約測試，又稱消費者驅動的契約測試(consumer driven contracts test)   測試目標：  「兩個服務之間」  的契約\n   測試消費者介面與服務者介面之間的正確性  驗證服務者提供的資料是否為消費者所需要的  契約：指軟體系統中各個服務間互動的資料標準格式    業務工作流測試   測試目標：驗證   「多個被測服務」  之間是否可以正常工作，達成某一業務請求  啟動執行兩個以上的微服務，進行業務流程上的測試  端到端測試   對   「整個軟體服務」  的流程進行測試\n   模擬用戶在可視化介面上執行各種操作  若軟體服務對外提供非可視介面的服務(如API呼叫)，這類測試也歸屬端到端測試  從用戶的角度驗證整個功能的準確性和可用性  不關注某一細小功能的實作  10.3 自動化測試的實施策略   考慮自動化測試案例的成本，為了更好的投資報酬率，需要更聰明地啟動自動化測試實踐  10.3.1 增加自動化測試案例的著手點  1. 針對代碼熱區補充自動化測試案例   程式碼熱區\n    程式碼變動頻率相對較高  的檔案或函數   經常出問題  的功能元件  若非程式碼熱區，說明執行穩定，編寫自動化測試的投報率較低  2. 跟隨新功能開發的進度   給目前的功能開發提供即時的品質回饋  若只是在補充原有功能的自動化測試案例，無法即時發揮保護網的作用  多數自動化測試案例由開發工程師自行負責編寫\n   若同一功能由一人開發，一人編寫測試，就會產生溝通成本\n   (傳統自動化測試的缺點)  3. 從測試金字塔的中間層向上下兩端擴展   上層開發成本高，下層單元測試覆蓋率小，中間投報率最好  ex: 採用微服務架構的服務端軟體 => 從契約層開始著手  ex: 手機端APP(微核架構) => 從元件級或API級的測試開始入手  4. 自動化測試案例的質量比數量重要   在能達到「驗證品質目的」的前提下，自動化測試的案例越少越好 (降低成本)   「在實作成本最低的測試層級上，進行相應業務邏輯的測試」   不要在不同層級的測試(如單元測試層和元件測試層)中，針對相同的邏輯編寫測試案例  數量夠就好，絕不寫不必要的測試程式碼  10.3.2 提高自動化測試的執行次數   測試執行次數越多 => 成本越低、獲益越高  如何提高執行次數？  1. 共享自動化測試案例 (測試可以被反覆利用，甚至自動化)   反例：\n   測試只保存在自己的電腦中  測試只能在自己的環境中執行  測試案例無法針對不同環境(如測試環境、預生產環境)進行適配  正例：\n   將自動化測試案例放到團隊的程式碼倉庫中  整合到持續部署流水線中自動執行  2. 開發人員是自動化測試的第一用戶   每個開發人員，隨時都能非常方便地執行自動化測試案例\n   將自動化測試作為開發人員日常開發中的一張品質保護網  而非測試人員用來驗收開發人員工作成果的工具  10.3.3 良好自動化測試的特徵  1. 案例之間必須相互獨立   案例間若存在順序依賴\n   就只能線性執行  執行時間拉長，回饋效率降低  搜尋失敗原因難度提高  2. 測試案例的運行結果必須穩定   不穩定的測試案例只會提供錯誤的品質訊號，浪費團隊的時間  3. 測試案例的運行速度必須快   將一個測試案例分解成多個獨立的測試案例，每個案例僅測原測試案例的一部份\n   => 平行執行  「等待」改為「輪詢」，以很小的時間間隔不斷查詢是否到達下一步執行的狀態\n   => polling 取代 sleep  4. 測試環境應該統一 (最大化測試案例共享的獲益)   反例：測試只能在某測試環境上執行，甚至只能在某開發人員的開發機器上執行  想辦法讓大家的測試環境統一或是讓測試能適配不同的環境  10.3.4 共享自動化測試的維護職責   自動化測試也是軟體程式碼，應花費時間心力使其易於維護，避免程式碼腐爛  自動化測試應盡可能與生產程式碼同步變化\n   沒有同步變化，執行就會失敗  當執行自動化測試失敗後，就應該馬上進行修改  (可能是功能出錯，也可能是測試需要修改)  「破窗效應」：\n   犯罪學理論：\n   環境中的不良現象如果被放任存在，會誘使人們仿效，甚至變本加厲  一個廢棄的房子出現了一個破窗沒人理，久了就會越多，甚至出現塗鴉  越來越多測試失敗卻沒有受到關注，久了就對自動化測試的結果視而不見  10.3.5 程式碼測試覆蓋率   有人認為它是非常有用的指標\n   應該要求達到一定比例的測試覆蓋度  有人認為它是有用的工具，但它\n   只能告訴你「哪些程式碼缺乏測試案例覆蓋」  卻無法證明「被覆蓋的程式碼就一定是真正經過良好驗證的程式碼」  提供一種錯誤的安全感  Google公司並沒有規定測試覆蓋率的統一標準，只有一個建議性標準：\n   單元測試覆蓋率達到85%  Facebook於2004年剛上線時也沒寫自動化測試\n   業務發展快速、工程師數量大幅增加  交付品質變差、開發人員常常處於救火狀態  2008年始，Facebook正式引入自動化測試實踐  Facebook 也無統一規定要寫多少自動化測試  Facebook 公司中，自動化測試案例的大多數由開發工程師自己負責      10.4 用戶驗收自動化測試要點   用戶驗收自動化測試處於自動化測試金字塔的最高層，成本最高  開發更多用戶驗收測試前，必須精心準備，以便以較低的成本持續維護比較健康的測試案例集  10.4.1 先搭建分層框架   先選擇適合專案的測試框架，做一定的調整  產生腳本程式後，進行測試腳本程式的分層重構  1. 測試案例的描述層   test case 描述  2. 測試案例的實現層   實作 test case  3. 測試案例的接口層(介面層)   把 test case 中 可以重用的東西提取出來  10.4.2 測試案例應保持低位(案例數應保持少量，低成本)   測試案例數量不應太多  focus在驗證軟體服務的核心工作流程  實作細節可交由下層的自動化測試案例來覆蓋  ex: 驗證系統登入行為時\n   驗證目標主要在驗證整個登錄流程是否得到正確執行  而不是驗證輸入資訊是否非法  後者可透過更低層次的自動化測試案例來覆蓋  10.4.3 為自動化測試案例預留API   少用模擬圖形介面操作的程式碼\n   介面操作反應慢  可能會有不容易定位，或執行不穩定的情況  盡量呼叫位於介面下層的API來驅動業務流程的執行  10.4.5 測試數據的準備   通過一些規則，編寫程序自動生成數據(當規則複雜時，較難編寫程序)  通過錄制手工測試時產生的數據  將生產環境的非敏感數據克隆一份，或截取一個片段  進行生產環境數據的自動化錄制，並保存備份  10.5 其他質量檢查方法  10.5.1 差異批注測試方法   一種半自動測試方法\n   當做預定義的數據集輸入系統后，收集運行后的輸出結果，對其中需要驗證的數據進行提取，並將提取結果放入文本檔中，通過對比前後兩次測試的結果，用人工批注的方式進行半自動測試。 需要特別注意動態信息(日期時間)的處理，常見的工具包括TextTest和ApprovalTests等。    10.5.2 代碼規範檢查與代碼動靜態檢測    代碼風格規範檢查：  是指通過工具 ，依據團隊定義的一些代碼編寫規範，針對源代碼進行檢查，如發現破壞規範的代碼，就加以指正。   工具常用的有 Checkstyle、PMD、SonarQube 等。  增強代碼的可讀性和易維護性。  Google 工程師在做代碼評審時，對代碼可讀性要求就非常嚴格。   代碼動靜態檢測：  通過一些工具對產品原始程式碼進行自動化掃描，發現代碼中存在的問題或潛在風險。    靜態掃描：  寫好源代碼後，無須經過編譯器編譯，而直接使用一些掃描工具對進行掃描，找出代碼中存在的一些語義缺陷、安全漏洞的解決方案。   常用的工具包括：lint，Coverity，ColcWork等。   動態分析：  通過在真實或虛擬處理機器上執行目標程序進行分析，比如，在可能的漏洞處插入專門編製的故障發生函數，迫使目標軟體產生異常，然後通過監控程式來檢查是否發生了邊界溢出或者其他異常現象。   常用工具包括：Valgrind，Purify等。  \n  當代碼庫的規模較大時，這種質量掃描工作可能會花費較長時間。\n    應該在提交構建之前，提供增量掃描的方式。  將完整代碼庫的掃描放到後期執行。  單獨執行。  正如我們可能將提交構建與次級構建分開一樣，這也是為了在反饋時間與反饋質量之間取得平衡。\n  10.5.3 AI在測試領域的應用   在代碼分析、缺陷定位等方面Al工具很多，其他UI、安全性測試也有一些： Appdiff、DiffBlue、BugDojo、微軟AI安全風險檢測工具、Facebook Sapienz等。雖然這些智能測試工具還在探索中，但已經有一些喜人的成果出現。   例如 2018 月， Facebook的工程網站 code.facebook.com 上，Ke Mao 和 Mark Harman 撰寫了一篇文章，名為《Sapien z: Intelligent automated so ware testing at scale》，講述了 Sapienz 對 Facebook 自身安卓應用進行智能自動化軟件測試的結果，稱：「除能夠加速測試過程以外， Sapienz測試結果的假陽性率極低…… Sapienz的結果報告中，需要修復的比例占75%。」    将人工智能（AI）应用于软件测试中    將AI應用於軟件測試中   查找和修復錯誤，利用AI進行更快速的測試  利用AI提高DevOps工作效率  將AI與機器學習相結合    使用AI進行軟件測試   從單元測試和靜態分析開始  向金字塔上移至API和UI級別    华为大咖分享：AI在软件测试领域应用探索    10.6 小結   自動化測試案例運行次數越多，平均成本越低，收益越大  自動化測試案例間應該盡可能獨立，互不影響  在質量有保障的前提下，自動化測試的案例越少越好  遺留代碼的自動化測試編寫應從代碼熱區開始  自動化測試案例從測試金字塔的中間層開始補充，投入產出比最高",{"id":149,"path":150,"dir":89,"title":151,"description":151,"keywords":152,"body":159},"content:4.cicd-2.0:11.chapter11.md","/cicd-2.0/chapter11","Chapter 11 軟件配置管理",[153,154,155,156,157,158],"11.4 環境基礎設施管理","11.5 軟體配置項的管理","11.6 不可變基礎設施與應用","11.7 資料的版本管理","11.8 需求與原始碼的版本關聯","11.9 小結","  11.4 環境基礎設施管理  11.4.1 環境準備的4種狀態   蠻荒法\n   以 \"人腦 + 手工” 代表  剛起步的專案，整體不複雜，用戶與客戶數量不多\n   開發人員自己就可以搞定所有的軟體部屬相關問題  所有環境準備相關的知識都在開發人員腦中，團隊核心與英雄  規範法\n   以 \"文檔\" + \"私有腳本\" 代表的 規範化狀態  隨著軟體服務的成功，用戶跟客戶數量變多，更多需求滿天飛過來，伺服器的數量也因此增長不少，環境維護工作變得多了起來\n   要求正式上線的部屬文件，通常會總結出一個環境部屬的準備說明書，由維運的人來執行\n   例如 文檔可能有11個步驟，但每個步驟中又有許多子步驟。  很多團隊是找不到這樣的環境說明文件，即使找到，可能也是無法使用過時的文件  要有規範化的上線部屬流程，此階段需要有個SOP文件，詳細紀錄每次的操作  利用私有化腳本，提升效率。每次的升級腳本都會重複之前一些動作   現在仍然有非常多的企業處於圖中此種狀態\n    流程通過 \"人\" 來維護，經常有遺漏  文檔通過 \"EMAIL\"追蹤，查找不方便  審查工作量大，由於手工工作量大，常有人繞過過程  自動化腳本不規範統一，而且經常出錯，導致部屬過程中斷  以辦公自動化為代表的 \"標準化狀態\"\n   隨著軟體服務的越來越成功，公司也不斷的壯大，維運人員越來越多，生產部屬事件也多了起來  無紙化的型態出現，原先使用office寫文件，轉為線上系統填寫\n   流程平台統一化，軟體開發與維運皆在同一平台上  部分內容標準統一  可以部份重用，減少工作量  審核工作變得容易，所有紀錄皆保留平台上  但仍然有些許問題\n   系統操作變得複雜，有些仍需人工餐與  兩次上線部屬差異比對仍然困難，雖然開發人員可以複製上一份資料，但每個皆為獨立副本，很難進行比對查找  以受控式自動化腳本為代表的 \"自動化狀態\"\n   此階段的自動化維運腳本有兩種型態\n   操作過程式為主\n   符合原有的思考習慣，將原本的手工操作步驟轉為腳本語言即可  靈活，想做甚麼操作，幾乎手工操作都可以辦到，不受任何約束  狀態聲明式為主\n   可以明確知道，無論何種情況或誰來執行這個腳本，皆可以得到相同結果  如果將此腳本放置 git倉庫，可通過diff功能，比對差異  學習成本高，此DSL(Domain=Specific Language，領域專屬語言)用來描述環境部屬的專有操作與狀態  腳本數量較多時，文件管理也存在相同儲存結構問題  此時可使用一些工作來做為輔助\n    工具運行模式可分兩種\n   拉模式\n   目標伺服器安裝 agent，保持與伺服器的連線與接受指令  推模式\n   不須安裝客戶端 agent，只需由伺服器遠端連線進行操作即可  11.4.2 領域專屬語言的應用     以上說明的這些工具都定義了各自工具領域，此種語言可以描述出環境部屬狀態的文件。  以 Puppet管理 apache2 服務為例來說明\n   Ansible 語法範例\n   11.4.3 環境基礎設施即代碼   現在，已將環境基礎設施一系列準備工作以腳本描述出來，也能通過自動化方式來執行。\n   好處\n1. 無論哪個環境出問題，皆能快速構建出全新的環境\n1. 只要有權限，任何人皆可完成任務\n1. 任何對環境修改都可以被記錄與審核\n1. 對不同環境來說，將腳本對比即可知道差異，不需再登入至伺服器  為了更進一步的優化，版本管理應該要有\n1. 操作系統名稱的版本號、補丁號與系統配置訊息\n1. 依賴軟體包的所有版本號與設置的內容\n1. 需與應用程式連線的版本號與設定檔內容  11.5 軟體配置項的管理  11.5.1 二進制與配置項的分離   一個應用程式通常程式碼與可執行檔是分開的，一旦編譯完成，此編譯執行檔就不會更改  編譯建置過程中，可能會有依賴其他套件包，通常套件包與編譯完成的執行檔是為分開的，但這兩項為必須，因而可視為不可分割的一環\n   二進制執行檔部屬時需與套件包的各版本完全相同  11.5.2 配置信息的版本管理   編譯執行檔時根據內容不同會設置各種設定檔\n   環境配置項(environment configuration)\n   網域、ip、api port、web port ...等  應用配置項(application configuration)\n   初始資料(帳密、通用資料...等)  VM資源設置  DB連線資料  Log紀錄相關設定  商務配置項(bussiness configuration)\n   預設值設定檔  某些商業邏輯計算設定\n    使用資料夾來區分不同開發環境的設定檔\n   11.5.3 配置項的儲存組織方式   儲存配置方法很多，最簡單的為使用純文字來記錄  可針對不同環境寫不同設置  編譯時將根據不同環境自動載入配置檔\n   11.5.4 配置飄移與治理   隨著生產環境發展，某些設定檔會偏移原先預期的設定，通常是由臨時修改測試所引起的  一段時間必須做校正回歸，否則將常出現不穩定狀態，甚至當機  好的配置可以解決飄移問題，也可避免人為操作上的遺漏  11.6 不可變基礎設施與應用  11.6.1 實現不可變基礎設施   物理主機鏡象技術 與 虛擬機鏡象技術\n   這兩種技術都可以提供環境準備效率  將上線的服務一模一樣分為兩份，同時部屬至不同地方  虛擬機除了可鏡象分離腳本外也可動態分配系統資源  Docker容器技術\n   容器化特性可使部屬軟體部分大幅降低難度與成本  11.6.2 雲原生應用   雲端服務PAAS，可讓部屬人員使用 git push 即可完成部屬動作，只需等待建置完成後的結果  PAAS先驅 Heroku 提出了 雲原生應用12要素\n   一套基本代碼多環境部屬  顯示聲明依賴關係  在環境中儲存配置  把後端服務當作附加資源  嚴格分離建置、發佈與運行  應用程式本身應該是一個或多個無狀態進程，進程之間沒有資料共享  通過端口綁定提供服務  通過進程模型進行擴展  快速啟動與優雅終止  盡可能讓開發環境、預生產環境與生產環境等價  日誌作為事件流  將管理/管理任務作為一次性進程運行  11.6.3 優勢與挑戰   優勢\n   簡化維運工作  部屬流程自行產生文件  持續部屬不停機，故障更少  減少錯誤與威脅  多類環境基礎設施的一致性  杜絕了\"配置飄移\"  被測試的即是被使用的  相對代價的挑戰\n   為不可變基礎設施建立一套自動化，初期成本較高  生產環境突發狀況，修復時間可能稍長  對大規模軟體服務來說，大檔案鏡象發佈至多台伺服器會消耗大量的網路資源，時間也會消耗不少  有狀態儲存軟體服務不容易被直接替換  11.7 資料的版本管理  每個軟體都需要處理資料，對資料進行版本管理是一件比較困難的事情，但是我們可以通過對其中一部分內容進行版本管理，來提高產品之間的合作效率。例如: 加快測試環境的建立，提高自動化測試使用案例的執行可靠性。  11.7.1 資料庫結構變更  當你使用關聯式資料庫系統，當軟體部署頻率變高，同時參與軟體開發的人員變多時，就應該對資料庫進行版本管理。除審計(Audit)管理和問題訂位外，對資料庫的版本管理在開發和自動化測試中也是非常有效地。  下圖為通過Flyway或Liquibase這類工具進行資料庫的升級或降級操作。搭配CI/CD工具的在執行Pipeline時，進行資料庫的管理。\n   當我們把資料庫結構的變動腳本放到原始碼倉庫後，在執行自動化測試時，可以很方便地得到一個乾淨的初始化資料庫版本。當發布給客戶的歷史版本出現Bug時，為了訂位問題，我們可以很快的對資料庫進行清空然後重建到特定的資料庫版本。  11.7.2 Binary文件  對於二進制文件的版本管理，就不能使用原始碼版本控制系統了。此時可以通過類似FTP、遠端檔案系統進行管理。   💡 這邊推薦MINIO系統服務來管理，他支援二進制的檔案版本管理，非常方便，參考  MINIO Versioning  當某公司內有一個  大檔案儲存系統 時，你可以將大尺寸檔案上傳到系統中時，它會返回一個URI，將URI放到一個文字檔案內容中，然後將文件檔內容納入到Git版本控制。這樣就將資料與產品原始碼版本進行統一的版本管理了。此時URL就是一個引用，而  大檔案儲存系統 就相當於一個儲存資料並進行版本管理的共享倉庫，這種方式對於測試資料管理是非常方便的。  另外一種狀況，當應用程式的啟動或運行需要仰賴一組資料檔案時，例如:   資料庫連線字串 ，我們可以先將資料庫連線字串進行演算法加密，當作一份二進制文件，然後將解密的演算法腳本加入到Git資料庫版本控管中，在程式執行時，將二進制文件進行載入後，在執行解密的演算法後，再進行資料庫的連線。  資料庫版本補充  請參考  Appendix 01 Database Version Control  11.8 需求與原始碼的版本關聯  由11-1圖中，程式碼、軟體包、環境都進行管理了，但我們想要對程式碼與需求項目進行關聯時，應該如何處理呢?  我們可以將需求內容進行文件化，並與對應的軟體包版本進行關聯，如果需求顆粒度要更細的管理，也可以將管理平台中的每個需求項目ID(或缺陷管理系統的缺陷ID)與程式碼進行關聯。例如: 再每次向程式碼倉庫提交程式碼時，將需求項目的ID，做為提交註解的一部分，並將這種關聯訊息進行展開出來。下圖是Mingle工具中的關聯參考   Mingle的SaaS從2019/7/31號開始已經停止服務。參考  官網 。你可以使用其他替代工具，例如: jira、Asana 、TFS等等。    11.9 小結  良好的軟體管理是打造持續交付Pipeline、加速驗證壞環節的基礎。  本章節主要有三個核心管理。   對一切進行版本管理  共享唯一來源  標準化與自動化  可以透過下面5個問題來驗證檢查你是否對一切都做了版本管理。下列5個問題是否都有放入到版本控制系統中呢?   產品原始碼和測試程式碼  軟體應用的配置訊息  各類環境的系統配置  自動化的建置和部署腳本  軟體包是否進行版本管理  另外可以利用下列兩個問題來檢查軟體管理是否做得足夠好。   可以透過原始碼倉庫的專案，一鍵式地建構出完整軟體包嗎?  在沒有他人的幫助下，任何團隊成員都可以一鍵式自動化搭建出一套應用軟體系統，用於體驗產品新功能嗎?",{"id":161,"path":162,"dir":89,"title":163,"description":163,"keywords":164,"body":170},"content:4.cicd-2.0:12.chapter12.md","/cicd-2.0/chapter12","Chapter 12 低風險發佈",[92,165,166,167,168,169],"12.1 高頻發佈是一種趨勢","12.2 降低發佈風險的方法","12.3 高頻發佈支撐技術","12.4 影響發佈頻率的因素","12.5 小結","  前言     前幾章主要討論快速驗證環中「建置階段」的工作  本章主要討論如何「高頻」「低風險」地進行軟體部署和發佈，儘早讓軟體在生產環境中執行\n   「高頻」的好處與可能帶來的成本與風險  「降低風險」的各種方式：藍綠部署、開關技術…  12.1 高頻發佈是一種趨勢   2007年以前，「敏捷軟體開發」的認同度不高，一些傳統IT企業表示：「我們不需要那麼快速地交咐軟體」  2009，Flickr 的 John Allspaw 和 Paul Hammond 在 Velocity 2009 年的大會上分享了題目為《Flickr 每天部署10次以上：開發與維運的高效率合作》  2011年5月，亞馬遜公司的月度統計顯示，平均每11就觸發一次軟體部署操作，當月最高部署頻率達到每小時1079次之多。平均1萬台伺服器會同時收到部署請求，而最高一次是3萬台伺服器同時執行一個部署操作  2017年，Facebook每天對其網站推送多次部署。    高頻發佈的好處   有更多機會與真實用戶互動，快速決定或調整自己產品前進的方向  每次變更規模較小，降低部署風險  單次部署成本降低  出現問題易定位、易修復、能快速修正  仍使用低頻發佈模式，強行執行高頻發佈的話，會帶來較高的迭代成本   設某團隊以手動模式每個月發佈一次，現改為每週發佈一次  假設「仍舊採用原有手動模式部署」，那每個月的工作量就是原來的四倍  12.2 降低發佈風險的方法   高頻帶來好處的同時，也存在各種風險(ex: 工作量提高、錯誤處理…)  藍綠部署   💡 準備兩套完全一致的執行環境，交互作為生產環境與預生產環境，目的為減少釋出過程中服務停止的時間   準備兩套完全一致的執行環境\n   一套環境 For 正式生產環境  另一套 For 新版本的預生產環境  對新版本環境進行驗收測試，直至確認無問題  將存取流量引流到新版本所在的環境，作為正式生產環境，同時保持舊版本所在環境不變  直至確定新版本沒有問題後，再將舊版本所執行的環境作為下一個新版本的預生產環境，部署未來的新版本     很多藍綠部署方案會使用相同的資料庫服務(因為資料庫複製的成本較高)\n   同一個資料庫儲存格式需對新舊兩個軟體版本做相容性處理  當切換發生在用戶的一次業務操作過程中且涉及事務處理時，如何處理資料的一致性問題\n   切換發生時尚未返回結果的舊有請求，舊版本環境允許其存取完成  之後不再接收新的請求即可    滾動部署     從服務群集中選擇一個或多個服務單元，停止服務後執行版本更新  相較於藍綠部署，不需要準備兩套一模一樣的服務執行環境，伺服器成本相當於少了一半  當新版本出現問題時，這種方式無法像藍綠部署那樣透過前面的流量負載平衡器切回舊環境\n   要對其中已部署新版本的伺服器進行還原  或快速修正後發部第三個版本V3，此時服器群集中可能會同時有V1~V3三個版本存在  金絲雀區佈   💡 讓一小部份用戶先行使用新版本，以便提前發現軟體存在的問題  17世紀，礦工帶一隻金絲雀下井。若井下存在有害氣體，在人體還沒察覺到前，金絲雀就會因無法抵抗瓦斯氣體而死亡  灰度發佈   💡 將發佈分成不同的階段，每個階段的用戶數量逐級增加     2012 Facebook 發佈一次首頁大改版\n   用戶數達總用戶的1%，網站的瀏覽量、頁面打開率等都有所下降  用戶超過10%後，各項關鍵業務仍舊表現不佳  於是Facebook 最終放棄這次首頁大改版，恢復了原有的版本  兩種實作方式\n   開關隔離方式：設置開關針對不同步圍的用戶開放新功能  滾動部署：將軟體的新版本部署到生產環境中的一部分節點上  暗部署   為演算法設一個開關\n   當開關打開時，會有流量進入此演算法，但用戶並不知道他用的是舊演算法還是新演算法  若此演算法的性能不夠好，可以馬上關閉這個開關  流量克隆\n   對每個請求都克隆一份，發送給新演算法  但新演算法並不向用戶回饋結果，而是開發人員自己收集資料  12.3 高頻發佈支撐技術  第8章提到，當一個軟體團隊的發佈頻率高於一週一次時，採「主線開發，主線發佈」更為經濟  但當某個功能無法在兩次發佈之間完成開發，怎麼辦？  拆分功能   分解為更小的在一個開發週期內能夠完成的功能集  先後再前   先實作伺服端功能，再實作用戶介面    功能開關技術   透過開關來隱藏未開發完成的功能   開關提供兩種用途\n   隔離：將未完成功能的程式隔離在執行路徑之外  快速止血：一但生產環境出了問題，直接找到對應功能的開關將其關閉  需考慮系統中所有開關的數量和組合測試的問題\n   開關越多，維護成本越高  開關存在時間越長，維護成本越高  應盡可能少用開關技術\n   if else 語句會帶來程式的複雜性，造成程式碼設計混亂  模組職責不清時，更容易出錯  但如果在「分支」和「開關」間選擇，盡可能選擇開關技術\n   建立分支會帶來後期的分支合入及多次測試成本  應對開關設置項目進行統一管理  定期檢查和清理不必要的開關項目  常見工具\n   C/C++: gflag，Google公司貢獻的開源工具  Java社群可用：Togglz or Flip  Grails: grails-feature-toggle  .Net: FeatureToggle  資料移轉技術   因為資料庫更新可能需要較長的時間，停機更新的方式可能不合適，所以處理資料庫的版更時可以選擇：   小幅改動的話：\n   只增不刪：欄位盡可能只增不刪  大幅資料結構的改變，則資料移轉SOP如下\n   為資料庫結構增加一個新版本  修改應用程式，同時向兩個版本的結構中寫入資料  編寫腳本程式，以後台服務的方式將原來的歷史資料，回填到新版本的結構中  修改應用程式，從新舊兩個版本中讀取資料，並進行比較，確保一致  當確認無誤後，修改應用程式，只向新版本結構寫入資料，可以將原來的舊版本資料保留一段時間，以防止未預期的問題出現  抽象分支方法  大型架構變動會需要較長的時間，傳統做法如下圖，以真實分支，大規摹覆寫的方式進行架構調整    這種方式在調整後第一次發佈時出現問題的概率較大，需要一定的品質打磨週期   💡 「抽象分支方法」是在不建立真實分支的情況下，透過設計手段，將大的重構專案分解成很多個小的程式碼變更步驟，逐步完成大的程式碼架構調整。     好處：\n   重構的同時也能交付業務功能需求  可以逐步驗證架構調整的方向和正確性  如果遇到緊急的情況，很容易暫停，且不浪費之前的工作量  能強化團隊的合作性  可以使軟體架構更模組化，變得更容易維護  成本\n   整個修改的時間週期可能會拉長  整體工作量比一次性完成的情況要大  案例\n   iBatis 和 Hibernate 是兩種物件關係映射框架 (Object Relational Mapping，ORM)  GoCD團隊曾使用抽象分支方法成功將IBatis 替換成Hibernate，並有兩個對外發佈的版本同時包含了這兩個ORM框架  在使用抽象分支方法前，也曾嘗試使用從主線上建立分支進行框架替換，但失敗了\n   團隊大多數人在主維上開發功能，分支上做框架替換，每天將主線程式碼同步到分支上  原預計三週可以完成的任務，六週也沒有能夠完成    如果使用建立分支的方式，通常必須停止大部分的新功能開發，否則很難成功  升級替代還原   我們總會遇到部署或發佈後出現一些問題，需要馬上修復  此時若有使用開關技術，便重新設置一下開關即可  但若沒有使用開關技術，怎麼辦呢？ ⇒ 升級替代還原  Facebook的處理方法：   盡可能以程式碼升級方式替代binary還原\n   典型的還原操作：將與待修復的問題相關的某次提交，以及與之相關的任何提交一同從程式碼倉庫中直接剔除，然後再次提交，等待下一次發佈即可  Facebook之所以可以以升級方式替代還原，得益於：\n   其工程師的程式碼提交遵循「小步、獨立、頻繁」的原則  發佈頻率高  Facebook工程師平均每天提交程式碼0.75次，平均每人每天提交約100行程式碼的修改  12.4 影響發佈頻率的因素   高頻發佈並非適合所有類型的軟體\n   需隨硬體發佈的嵌入式軟體開發來說，其對外發佈的成本非常高  一但軟體出現問題而導致退貨率上升，其損失可能相當高  決定軟體的發佈頻率時，需綜合考慮以下影響因素\n   增量發佈帶來的獲益和可行性  每次發佈或部署的操作執行成本有多高  出現問題的概率與由這些問題帶來的成本有多少  維護同一軟體的眾多不同版本帶來的成本  高頻發佈模式對工程師的技能要求  支撐這種高頻發佈所需要的基礎工具設施與流程完善性  組織對這種高頻發佈的態度與文化取向  其中 5、6、7對前面四項的結果會產生直接影響  可能會因這三項原因使高頻發佈的成本高居不下，獲益相對較少  此時企業領導就需做出更多努力，在後面三項上投入更多的精力  推遲發佈動機的漸進壞強環     大家習慣推遲風險  兩次發佈之間的間隔越長  累積的程式碼變更越多  所需品質驗證時間就越長，部署成本、發佈風險就越高  12.5 小結  本章討論了   如何在快速部署發佈的情況下，透過多種技術手段降底風險\n   資料庫遷移技術  各種部署策略\n   藍綠部署  金絲雀(灰度)發佈  抽象分支部署  暗部署  應對高頻部署的其它技巧\n   拆分功能、先後再前  開關技術  資料移轉技術  抽象分支方法  升級替代還原  在某些業務場景下，我們的確無法直接高頻地對外發佈軟體  但我們若能使用本章介紹的方法持續向預生產環境進行發佈與部署，就可以儘早獲得軟體的相關品質回饋，進而減少正式發佈後的風險。  如果我們能將每次發佈的平均成本降低到足夠低，那麼將會直接改變團隊的產品研發流程",{"id":172,"path":173,"dir":89,"title":174,"description":174,"keywords":175,"body":182},"content:4.cicd-2.0:13.chapter13.md","/cicd-2.0/chapter13","Chapter 13 監測與決策",[92,176,177,178,179,180,181],"13.1 生產監測範圍","13.2 數據監控體系","13.3 問題處理體系","13.4 生產環境測試","13.5 向東，還是向西","13.6 小結","  前言   在有效率的開發高品質的軟體，並以低風險方式佈署和發布後，我們要開始觀測交付到用戶手中的軟體或應用程式的使用情形。  了解用戶的使用偏好和軟體執行的狀況，並以蒐集到的量化數據做為回饋，確保我們可以持續開發並改進軟體，為使用者繼續服務。  從用戶需求開始進行軟體開發，到低風險佈署/軟體發布，接著監控營運狀況並蒐集數據，我們完成了軟體開發流程的封閉環－讓我們驗證開發的功能是否有達到預期的目標。    13.1 生產監測範圍   為了了解用戶與軟體之間的互動，企業會根據相關的數據做為研發與改善的指標。  一個軟體對用戶的服務橫跨我們管理的後台伺服器和用戶裝置上，因此這兩個裝置上的服務和運行狀態都需要監測。  13.1.1 後臺服務的監測   基礎監測：針對系統基礎設施，包括網路與伺服器節點的監測。內容包含網路連線狀態、流量、CPU負載、內部和外部儲存空間等使用狀況。  應用監測：針對應用程式的運行健康，如流程是否存在、是否有正常提供服務、是否有缺陷、是否有正常的與伺服器連線、是否出現time out、是否友直回例外或警告、是否能應付突增的服務請求量等。  業務監測：針對業務指標，如用戶造訪量、功能使用需求等。  13.1.2 用戶裝置上的監測   監測用戶裝置上的軟體運作狀態和設備運行狀態需要取得使用者授權，並將蒐集的數據定期發送到後台伺服器上來分析。在離線狀態下，程式得先在本地端暫存數據，待連線後再一併上傳。  監測的項目與在後台的一樣：   基礎監測：針對用戶設備的硬體環境，以及與伺服器的連線狀態。  應用監測：同後台監測的內容。  服務監測：本地端的服務功能使用情形。  最後，也要根據市場評價來修正軟體服務的缺失，提供更優質的體驗。  13.2 數據監控體系  對監測數據的獲取過程、處理流程全面管理，包括數據來源、數據格式、採集週期、數據處理方法等。  13.2.1 收集與處理    每個步驟的職責如下：   採集上傳：在本地端蒐集事先定義的事件數據並上傳。  數據整理：過濾整理上傳數據。  實時分析：分析當前數據。  離線分析：對大量數據進行規則提取或模型化。  結果輸出：呈現實時和離線分析結果，供決策參考。  問題決策：根據輸出結果，透過人為或自動方式判定情況，並儲存判定結果，以利日後參考。  數據儲存：保存離線狀態的原始和分析後數據。  自動修復與執行系統之間的管道。修復指令需要被傳給執行系統，並由它將指令分配到對應的節點，進行相關操作。  13.2.2 數據標準化  要得到監測的數據，我們得先規劃軟體內如何觸動「事件」，並持續追蹤。持續交付價值環中強調的「探索」和「驗證」依靠用戶回饋來執行。為了提升驗證的即時性，在開發一個功能前，除了訂定功能開發目標外，還需要：   定義功能指標，以及如何處理功能指標－如何以指標量化該功能，且找出使否有與其他功能指標有關連；以及  數據事件的定義－要在程式碼內合適的位置安插監聽事件，定義輸入與輸出的格式，並確認數據是否與其他事件有關係。  若在開發實沒有定義數據指標的體系，當遇到產品開發瓶頸時，就無法察覺用戶行為。指標包括：   偏好關注基礎事件和應用事件的數據分析，而忽略了業務方面的數據。  在沒有重視業務數據監測的情況下，當打算蒐集數據時，得額外花費時間取得資料。  因此，在高度不確定的功能環境開發下，業務數據蒐集的重要性遠高於功能實現的重要性。  為了利於統計分析，一開始就必須先定義數據日誌格式與蒐集規範。訂定標準可以使數據蒐集和處理更方便，減少無用的數據或錯誤的分類，進而提升分析處理的效率和準確性。  數據紀錄的紀錄內容包含基礎訊息和擴展訊息。前者描述基本的應用情況，即 Who（哪一個用戶或服務）、When（何時發生）、Where（哪裡發生）、和 What（做了什麼）。擴展訊息是為了讓數據有更好的擴展性，以應對不同監測統計需求。  13.2.3 監測數據系統和能力衡量  監測用數據的可靠度可以用三個面向來衡量：   正確性：即收集到的數據與事實的一致性；  全面性：即收集到的數據是否足以用來下達決策；  及時性：即從數據產生到下達決策所需處理時間夠短。  團隊運作初期較常遇到數據結果與實際情況不符的情況，需要花比較多的時間。可以以下列兩種方式來驗確證數據品質：   可在運作初期尋找專家經驗來建立數據系統。  可使用來自系統外部（不同團隊）或內部（不同面相）的數據相互印證。  及時性是「  敏捷 」的重點。在更新某些功能後，都希望能儘早知道它對業務相關數據的影響。除了以上三個基本行量為度以外，監測系統還應具備  抽象能力 ，即根據實際數據量的需要，工程師可以即時配置每種數據採樣的密度。  13.3 問題處理體系  判別問題的方式有兩種：人工判別或是機器自動判別。面對大量的數據，不可能全依靠人工處理。通常先由電腦根據各種規則判斷，盡可能找出疑似的問題。無法自動處理時，就發布警告給指定的工程師。  13.3.1 海量的警告與智能化管理  面對大量的警告訊息，會希望減少警告，但另一方面又擔心出了是沒有警告，只好再加入更多的警報。事實上，大部分的警告訊息會被忽略，主要是因為：   自己不是該警告的負責人，  這只是一個預警，不用馬上處理。  警告當然有它們的正確性和真實性，但同時也要提高這些訊息的另外兩個面向：即時性和可操作性。針對後者，處理者應該可以對警告做出有用的操作，否則該訊息應被當成垃圾訊息屏蔽，避免降低工作效率；一但真正的警告被海量的垃圾訊息淹沒，就很容易釀成災難。這個問題可以靠四個方面來減緩：   讓監控點離問題發生地更近。  透過動態閥值設定合理的警告。  定期回顧警告配置，並清理多餘的警告。  用AI動態解除警告。  這些方法可以將警告數量控制在一定的範圍內，但無法完全消除。常見的警告可能已有對應的方法；真正要花時間的是那些以往沒有出現過的異常警告，因為它們很可能是「生產問題」。  13.3.2 問題處理是一個學習過程    問題處理是一個複雜的團隊活動。可提高效率的做法：   儘可能將人工步驟自動化  建立工單系統  回顧處理流程  13.4 生產環境測試   生產環境是獨一無二，我們永遠無法1保證發現生產環境中可能出現的所有問題。  隨著軟體快速發佈訴求的提升，非生產環境的測試場景越來越顯得不充分。  如何在不影響生產的前提下，在生產環境中進行測試？  13.4.1 測試活動扁平化趨勢   傳統的混布式軟體開發方法中，測試執行和決策活動通常集中在軟體研發周期的中部。  隨著現代軟體交付頻率的不斷加快，這種情況出現了變化。很多團隊的測試活動開始向左右兩側移動，如圖13-7所示。\n   測試左移(測試前移)，是指測試人員更早且積極地參與到軟體專案前期各階段活動中，在開發功能之前就定義相關的測試案例。  測試執行任務也在向左移動，表現為 : 在越來越多的軟體團隊中，測試角色開始擁抱「增量測試」，即在軟體整合測試之前，就開始針對單個已開發完成的功能集進行品質驗證，提前發現品質風險。儘管這種「增量測試」無法發現全部品質問題，但可以減少整合測試階段的時間壓力，如圖13-8所示\n   測試左右移動   「測試右移」是指將一部份品質驗證工作放在軟體發布之後，也就是讓子彈飛一回兒。  主要因為網際網路軟體產品的測試，與原先企業內部應用的軟體測試有顯著不同，即無法窮舉性。  企業內部軟體的使用者有限，環境相對可控, 但網際網路產品的情況有所不同，每個人的電腦或手機上都安裝著不同的軟體，硬體與作業系統也有很多種組合，因此無法以窮舉方式進行所有相關場景測試。因此大家也越來越依賴於生產環境上的品質驗證  測試右移現象多見於軟體產品中的示範性功能(software for show)，即軟體功能更多地傾向於內容展示，例如搜尋軟體、拍照軟體、商品展示。即便這類功能出現一些問題，但只要即時發現即時修復，就不會對用戶造成本質性損失或嚴重影嚮。  對事務性軟體(software for transaction)以及問題修復成本較高的軟體(firmware)來說，一但生產環境出現問題，會帶來比較大的損失。因此軟體團隊不會冒險將功能驗證的活動右移，而是有強列的動機將測試活動盡可能左移，同時加強右測的監測能力。  13.4.2 生產環境中的測試   QA部份應將生產環境中的測試列入日常工作中，稱為「生產巡檢」。  對生產環境中的後台服務進行定期功能驗證，以確保該後台服務備舊對外正常提供服務，且處理的結果是正確的。  通常的做法是：建立一個覆蓋應用程式主要功能的日常健康檢查清單，對生產環境進行例行測試和檢查軟體服務的品質。這種測試方法與監測不同，它們是由軟體團隊自行安排的品質驗證工作，並且定期執行，因為這是一些例行驗證，所以應該被自動化執行．。這類測試中最典型的就是介面測試。  很多團隊開始將一些自動化介面測試的案例放在生產環境鞏，周期性執行，以代替手動檢查。  這類生產環境上的品質保障工作應遵循以下原則\n   建立自用的測試資料，確保不污染真實用戶的資料  使用的測試資料盡可能真實  不要隨便修改真實用戶的資料  建立測試專用的用戶存取憑證，登錄生產環境  13.4.3 混沌工程   混沌工程(chaos engineering)是指在生產環境中注入「問題」，進而發現生產環境系統性弱點，並進行系統性改進的方法或手段。  其目標是不斷提升生產環境面對任可變更的可靠性。這與疫苗注射類似，向系統注入一些小劑量的「病毒」使身體康立對它的抵抗力，進而使身體獲得免疫性。  此部份最有名的例子為Netfilx的  Simon Army \n![13-8-1-Simian Army.png](images/cicd-2.0/13/13-8-1-Simian Army.png)  Netflix在AWS上，開發了一系列生產環境測試工具，稱為Simon Army，用於模擬AWS如區(zone)或大區(region)出現問題，以及模擬人為製造呼叫延遲，用來模擬服務降級，看依賴這些服務的模組是否能正確做出反應。  這種問題注入(Failing Injection)式的主動檢測，可使軟體工程師在架構設計上就需考慮一些常見的失敗問題。  13.5 向東，還是向西     快速驗證環中，我們將精練後的試驗方案變為可執行的軟體，部署到生產環境，並且收集了執行結果和用戶回饋。現在是要決定下一步「向東，還是向西」以完成第一個業務閉迴圈  透過分析總結，可幫助我們從收集到的數據中來判定前進目標  若收集的結果不合預期，只要與團隊共同分析，看是針對現行方案進行微調，還是從備案中選擇新的試驗方案，繼續驅動這個快速驗證環  13.6 小結  生產環境的監測範圍包含三個層次 :   基礎監測  應用監測  業務監測  每個層次的特點，監測資料的採集方式有所不同，但其處理流程基本一致，包括:\n資料收集、上報、整理、分析、展現與決策這幾個環節  而對監測系統能力的衡量有3個維度 :   資料的準確性  全面性  即時性   告警處理是研發人員和維運人員的常規工作，但告警過多反而會造成工作中的困擾，降底工作產出。因此我們應該不斷對告警點的設置及臨異值計算方式進行最佳化，進而盡可能提升有效告警率。一但告警成立，就需要啟動問題處理流程。這個流程的最後兩個環節 「根因分析」和「根源解決」是學習型組織的重要特徵  隨著發佈頻率的提高，測試場景的複雜性提高，越來越多團隊開始找尋方法在生產環境上進行軟體測試，這被稱為測試活動右移。這種只適用於軟體出錯後的成本和影嚮相對較少。而那些較交易性軟體或回收成本較高的軟體來說，測試左移的趨勢也較明顯。  測試右移主要有兩種類型 :   將測試案例在生產環境上自動執行  混沌工程(Chaos engineering)   Netfilx開發了一系列破壞性測試工具(Simian Army)可以促使工程師在軟體設計與開發之時，就提前考慮各種失敗的可能性，這被稱為「為失敗而設計」進而提高生產環境的軟體服務穩定性，為用戶提供更好的服務體驗。  當收集到真實的資料回饋，就可印證在價值探索環中所提出的假設或目標，並透過主動關聯分析，最終確定是繼續進行更多的試驗，還是重新再選擇一條新的路",{"id":184,"path":185,"dir":89,"title":186,"description":186,"keywords":187,"body":192},"content:4.cicd-2.0:16.chapter16.md","/cicd-2.0/chapter16","Chapter 16 研發推動的DevOps",[188,189,190,191],"16.1 改進的關鍵點","16.2 第一階段：敏捷101","16.3 第二階段：DevOps轉型","16.4 小結","  過分強調並專注於docker、Jenkins、測試框架、Mock框架或持續集成服務器等工具，有悖於敏捷宣言 -- 和流程與工具相比，個體與交互更為重要。  案例背景：   B公司部門組成：\n   B公司某業務線下的一個後台服務業務團隊，這個團隊負責網頁搜索產品的後台服務。該服務是一個相對獨立的子系統，接受其他服務的請求，也將自己服務的處理結果提供給其他服務使用。   由一個程序模組組成，  總體代碼量約為10萬行，  全部由C++語言編寫，  每個模組都是一個單獨的程序服務（可以認為是微服務），  運行在近300台服務器上。從前端的資料流獲取開始，再到資料流的解析、分類入庫。    工作模式   分支開發、集中聯調階段，測試人員參與較少  程式碼管理：分支開發、主幹發布    16.1 改進的關鍵點  16.1.1 改進方法論   目標驅動  從簡單問題開始  持續改善  16.1.2 定義改進目標   工作過程中的痛點   部門負責人的期望  團隊管理者交付的壓力  項目負責人的煩惱  制訂合理的階段性改進目標   短期目標\n   項目近預期時間交付  創建新的軟體開發協作方式  建立必要的基礎設施，以支持之後的持續交付  中期目標\n   縮短發布週期，可以快速上線  不降低生產環境的品質  降低測試人力總投入  改進目標對應兩個實施階段   第一階段，敏捷101  第二階段，DevOps轉型  16.2 第一階段：敏捷101   簡介   也稱為Water-Scrum-fall模式，指瀑布開發框架模式下，對各階段內部進行迭代時間盒的劃分  迭代週期通常為1~4週。開發階段內的每個迭代週期內，都會發生需求分析、程式開發、測試活動。並且每個開發迭代結束時做演示驗收  進入開發階段後，仍舊有需求收集、分析和計劃的階段，並且在結束後也會再安排1~2個作為系統測試迭代  最後安排系統試營運階段，然後再正式上線  特點：   瀑布開發模式中的幾大階段沒有變化，只對各階段內部活動進行適當調整  此模式常應用在對於持續交付理解不深、研發基礎設施不完備，但希望進行改善的團隊    16.2.1 做個靠譜的計劃   需求拆分，開發負責人根據下列3個要求作拆分，並交給測試人員進行評審和補充後，再次相互討論並達成意見一致\n   每個需求實現少於三天  拆分要遵循  INVEST原則   獨立的（Independent）  可協商的（Negotiable）  有價值的（Valuable）  可估算的（Estimatable）  較小的（Small)  可測試的（Testable）  拆分過程中的權衡  相對估算，使用排序法對需求估算，排序法有2主張(1  2)與4前提(3 6)\n   將較多的需求放一起，結合上下文做比較 (降低因人員能力差異帶來的偏查)  在需求的數量較多時，項目整體規模評估會相對準確  每個需求至少有兩個人較了解，且是可以完成的  不需要評估測試活動的工作量 (開發環節才是系統的瓶頸，若測試環節就會成為瓶頸甚至可認為開發資源已投入過多)  所有需求都拆解，並且規模不會相差太多  需求的個數相對較多  初始計劃\n   理想情況下，每週工作時間是多少  理想情況下，每週能完成多少需求  實際每週最有可能開發完成多少需求  如何處理整個項目開發過程中的線上需求變更\n   例如是在發布主幹上拉一條項目開發分支，所有人以這個分支進行開發。對於臨時的緊急需求，在線上發布版本分支上單獨拉分支，快速修復線上問題或開發緊急需求，再快速合併上線\n   系統測試的時間在哪裡？  其他類型的測試怎麼辦？  計劃時還需要考慮依賴因素\n   例如考慮業務或技術上，是否與其他團隊有依賴的關係？  項目計劃在整體上要加一個緩衝時間  16.2.2 開發階段啟航   迭代週期的選擇     水位當作開發的時間範圍，岩石當作日常問題  若以傳統模式開發，此時問題難以暴露出來  若以迭代模式開發，因為交付時間變短，相當於水位變低，問題就能提早凸顯出來。但是水位的高低的選擇，則需要團隊視情況而決定  團隊協作流程   每個迭代的工作約定  對於單個需求的開發流程約定   批量開發，批量提測：指開發人員等到全部或大部分功能開發完成後，再一起聯合驗證  單例開發，即時提測：指每當開發人員開發完一個需求之後，就即刻交給測試人員進行驗證    16.2.3 對過程品質的約束   如何能自覺遵守CI定律？  編譯時間過長   開發人員寫完程式碼，提交前在自己機器上運行命令腳本，將SVN當前版本耗與patch一起提交給服務端，空閒時就會自動編譯。若出錯就會得到反饋，若沒問題開發人員則可提交程式碼    開發人員無法運行自動化測試   迭代開發中，自動化測試的第一個用戶是開發人員，來檢查新增修改的程式碼是否正常  自動化測試的策略。根據自動化測試金字塔理論及團隊狀況做出測試約定   單元測試  模組自動化測試  服務接口自動化測試  子系統級自動化測試  大環自動化測試    自動化測試所需運行環境不足怎麼辦  如何確定一個需求可以提測   測試人員在開發人員的機器上體驗過該需求  所有自動化測試都通過。  如何作性能與壓力測試   對開發人員的工作要求\n   在迭代開發的工作模式下，所有需求是依據PARID五因素綜合優先級排入迭代計劃當中，這會要求開發人員盡量能夠多了解和修改不同的模組功能  團隊的自我主動改進\n   每個迭代舉行回顧會議，對工作過程中成員的協作方式、工作活動的約定、團隊面臨的問題及可能的解決方案進行討論  不能修改最初估算的大小\n   新增需求：以前未評估過，所以需要快速討論、估算，以便加入開發計劃當中  已估需求：單個需求估算本就不精確，原先的估算是基於整體的總量評估，因此不太會因為個別需求重新評估而偏差太多  16.2.4 階段性改進點   業務目標合理  項目計劃透明  流程\"自定義，自遵守\"，團隊確保高品質交付  定期主動回顧，而非事件驅動的回顧  通過細粒度需求組織開發流程  持續集成六步提交法  適當是用自動化測試，提高品質反饋效率    16.3 第二階段：DevOps轉型   透過敏捷101的方式，對於時程預估、開發團隊的合作、測試流程都有一定的成長，團隊開始朝向小批量生產的方式開發，並且開始有比較頻繁的成果發佈(ex.兩週一次)  從過去的分支開發、合併主線內容到分支、集中測試，改為主線開發、分支發布的城際快線開發模式\n   在wiki上可以知道每個發布的時間點，以及對應的發布列表  客戶可以隨時提交需求  需求列表中，不但有客戶要求，還包含自我優化需求排程  16.3.1 與維運人員的衝突   因為頻繁的發布，引發維運人員的憂慮\n   過去測試時間那麼長，上線的系統還是會出現各種問題，現在測試的時間縮短後(測試左移，導致最後上線前測試時間縮短)，那上線一定會更容易出問題  我會被累死，部署到多台主機，以前三個月加班一次，現在變成兩週就要加班一次  透過讓維運人員參與團隊日常的運作，增加透明度\n   開發負責人為維運人員詳細講解目前使用的研發流程模式，讓他了解目前對於程式碼品質的保障方式  邀請維運人員參與開發團隊活動，參加日常工作的討論ex.參與站立會議、參與團隊衝刺週期後的回顧會議  將維運人員加入開發團隊的工作溝通群中，以便隨時了解運作狀況，這維運人員不再視為開發團隊是一個看不到內部的「黑盒」  針對維運需求進行架構調整，讓維運人員的工作更有效率(過去對於維運的需求都以有空再來處理而忽悠過去，現在變成一個合作夥伴，一起讓讓部署過程可以更自動化)  16.3.2 高頻部署發布中的具體障礙   由於歷史共業，各模組的部署方式不一致，導致不利於統一維運  部分模組在部署時，維運人員需要手動創建某個目錄，備份程式運行時產生的臨時數據  同樣的模組在不同機器上的部署位置都有差別  同樣的模組在不同機器上對外的接口策略也不同  程式碼是用絕對路徑而非相對路徑  部署操作文件是由開發在部署前編寫(代表每次可能都不一樣，導致無法透過自動化反覆執行)，維運人員根據文件說明操作  開發環境的部署方式跟正式環境的部署方式不同  測試代碼存在QA的儲存庫，而不是跟著專案跑，導致只有QA才有辦法執行測試  開發環境、測試環境共用，導致髒資料議題  自動化測試覆蓋率不足，導致測試人員仍然需要執行很多手工回歸測試(每次上版都要手動測試全系統)  16.3.3 整體解決方案的設計   自動化測試策略的調整：\n   把測試從QA擴展到全開發，對於開發人員進行單元測試框架的培訓  減少不同層次間的重複測試，認知「通過低層次的測試來驗證很難在高層次驗證的測試」，找到最適合測試的階層，不是所有的測試都是交給QA執行整合測試     自動化測試的便捷性\n   透過配置文件的方式讓不同的開發可以共用一個測試環境(ex.只要換不同的配置文件，系統就可以上到某一台測試主機，要換到另一台主機，只要更換配置文件不需要修改程式碼就可以遷移過去)  測試代碼同源\n   把測試代碼放到專案裡面，而不是QA的儲存庫，這樣任何人都可以去執行測試  配置管理優化\n   代碼庫結構\n   程式資料夾有統一的結構，模組相關的就在該模組資料夾下(ex.該模組的測試，是放在該模組的test資料夾內，而不是整個系統的測試全部放一起)，該模組的config就放在該模組下  ex.單元測試就放在「模組a/test/unittest/測試案例1」  會有output的資料夾，提供維運人員部署使用  產出物的標準化與版本管理\n   持續整合產出的成品，透過建構號(build_id)作為成品的唯一識別  取代手工自行編譯  軟件包管理\n   只有經過一系列的自動化測試，並經過測試人員手工驗證後，才在臨時構建成品庫中標記為「符合品質標準」，當要獲取某個版本部署時，只能從臨時構建成品庫中選擇那些符合品質標準的版本放入產品發布庫    16.3.4 DevOps階段的團隊改變   完整的跨功能團隊，維運積極參與團隊的日常工作迭代會議  所有內容都做版本控制，包括原始碼、測試程式、各類環境的配置、相關的打包及安裝腳本，以及一些數據  所有環境標準化管理，可以一鍵式準備好測試環境  建立完整的部署流水線，可以一鍵式發佈到多種部署環境    16.4 小結   所有改進都是一種一連串的連續流程，從明確目標、診斷問題、解決方案、持續運營優化  過程中抱持著持續學習的心態  ",{"id":194,"path":195,"dir":89,"title":196,"description":196,"keywords":197,"body":204},"content:4.cicd-2.0:appendix00.md","/cicd-2.0/appendix00","Appendix 00 使用Gitlab做CI/CD",[92,198,199,200,201,202,203],"簡易開發流程","Runner Server設定","CI撰寫","CD撰寫","參考專案","Docker版本(Speak，後續待寫)","  前言  此章節不屬於持續交付2.0書中內容，額外挪出的一個教學章節。  CI/CD目前在大部分會做頻繁整合與部屬的團隊都已在使用，因此在開發中在目前的趨勢中有一定的必要性。CI為持續整合，他的用意本質在於當既有程式碼或產品有任何異動時，可以在短時間內完成整合，並確保用作如預期。而CD為持續交付，注意英文中的D為Delivery而不是Deployment。用意在讓任何一個異動可以保有品質的盡快交給客戶，並能為此帶來對應的價值，此章節會手把手教學如何使用Gitlab來達到CI/CD自動化。並透過CI/CD將.Net Core專案部屬到部屬機上。  \nCI/CD精神在於做到快速整合並保有高品質且能交付客戶使用，重點在於精神大於自動化工具，因此每個專案與產品狀況團隊也會具有不同的計畫與交付流程。\n  簡易開發流程  不使用CI/CD  一般簡易開發整合流程為   Step1. 開發  Step2. 建置  Step3. 測試  Step4. 部屬  如下圖所示，在沒有自動化整合平台下，基本上所有流程都須透過手動去完成。  \n     使用CI/CD  如下圖所示，我們只需要寫好Script File，交付到Gitlab，並在Gitlab Server上做好設定，Server就會根據Script腳本所寫的指令(命令)，交付Runner Server作執行。在使用此自動化整合架構下，我們可透過Gitlab與Runner Server完成上述的步驟開發、建置、測試與整合，甚至是程式碼分析。  一般CI會做建置測試與程式碼分析，而CD則是做部屬、整合測試與交付。在不同的應用場合下，設置會根據不同環境應用建立專屬CI與CD Runner服務。但此章節不會講到太複雜的情境，會以簡易的開發、建置、測試與部屬四個步驟帶過。  \n     \n一般可做自動化整合的Git Server，都會需要一個代理伺服器(Runner Server)來幫忙執行Script。因此我們會需要一台機器做專門的Runner Server來服務Git Server。\n  Runner Server設定  Runner Server須根據開發應用選擇不同的作業環境，例如若你的專案已.Net Framework為主。你想做自動化整合，你的Runner機台則就須選用Windows OS。若日可做跨平台的.Net Core，你則可以選擇Linux OS環境去架設Runner Server。  因Runner Server會根據Script指令做建置與測試甚至是部屬，所以需安裝可執行相對應的CLI指令及SDK。如上述提到的.Net Core，若Runner Server要編譯.Net Core專案，則就需安裝相對應的SDK。若CD需透過SSH連至部屬機操作，則Runner Server則需具備SSH連線能力。簡單的說，開發環境可做的事情，大部分在Runner上也要都具有相同功能。  Gitlab Runner分類  Gitlab Runner設置有三種模式，如下   Share Runner : 所有Group或專案可使用，不需自行架設Runner，免費版本兩千分鐘使用限制。  Specific(Project) Runner : 特定需求使用，需自行架設Runner。\n   Group Runner : 同Group的Project可使用，需自行架設Runner。    安裝Runner設定  上述提到Runner設置有三種，此文章我們會以Group Runner設置為主，請先至以下路徑  YourGroup → Setting → CI/CD → Runner (點選Expand)  展開後，請點選New group runner view的Take me there就會進入到Runners 設定頁面如下圖，    你可以點選右上角的Register a group runner，並根據你要設置的平台，在Show runner installation and registration instructions 選項有詳細設置方式，如下圖    Windows設置[  官網說明 ]   Step1 :   下載Windows Gitlab Runner檔案  Step2 : 安裝與啟動   # 切換到下載目錄\ncd D:\\SystemService\\gitlab-runner\n\n# 安裝服務\ngitlab-runner-windows-amd64.exe install\n\n# 進行服務啟動\ngitlab-runner-windows-amd64.exe start\n  安裝和啟動服務成功後，可以透過工具管理員查看狀態   Step3 : 註冊  至YourGroup → Setting → CI/CD → Runner (點選Expand) → Take me there → Register group runner →Show runner installation and registration instructions  點選Windows Tab 此時就會跑出建議指令流程，    請輸入Register指令   ./gitlab-runner.exe register --url https://gitlab.com/ --registration-token your token\n   Step4 : 設置Register參數\n   a. Gitlab URL : 若是Group Runner，可以輸入Group Gitlab的URL(Ex:  https://gitlab.com/groupxxxx )  b. Registration Token : Your Token (Group Token or Specific Project Token)  c. Description : 關於此Runner的描述  d. Tags : 寫CI.yml時，工作會根據Tag名稱指向符合此名稱的Runner，所以這參數設定很重要，一般可以根據你的環境去命名例如Windows-xxxx或者是Linux-xxxx  e. Maintenance note : 維護說明，可填寫維護時須注意事項  f. Executor : 執行器種類，若要走較一般的CI就是選shell，執行器就可根據不同作業系統做對應的CLI執行器設定(例如Windows設定PowerShell，Linux設定bash。  參考 )  Step5 : 完成  此時我們在點選  YourGroup → Setting → CI/CD → Runner (點選Expand) → Take me there  你就可以看到註冊好的Runner顯示在設定頁面上了    Linux設置[  官網說明 ]   Step 1 : 安裝與啟動  至Gitlab說明文件直接照步驟操刀  至YourGroup → Setting → CI/CD → Runner (點選Expand) → Take me there → Register group runner →Show runner installation and registration instructions     Step 2 : 註冊 (可直接參照上述 Windows設置註冊)  Shell設置  上述設置好Ruuner後，接著需調整Runner設定檔的執行器，請開啟Runner資料夾下的toml檔，並照下圖設置  \n     詳細對應Shell設定可至此查詢[  連結請點我 ]  安裝編譯環境設定  因為Runner為代替本機電腦做建置、測試與部屬。所以需在上面安裝相對應環境，專案上我們會使用dotnet core為範例。所以電腦需安裝對應需有的SDK，若使用Docker則需安裝Docker環境。    Net Core SDK安裝參考   Dokcer安裝參考  好用請給讚，謝謝  CI撰寫  建置與測試  Hello CI/CD  請到此下載Sample Code   https://gitlab.com/test8214/emptyproject  下載下來後將此專案上到你的Group Project，若你的Runner已設好，我們可以直接從Gitlab頁面點選 Set up CI/C，如下圖  \n     接著點選Configure pipeline，此時Gitlab會幫你生成yml Sample Code，此Sample Code已幫你寫好的基本build, test與deploy Stages。請將最上層註解刪除，並加上default區段，runner tag   # default表示所有job都會參考以及使用\ndefault:\n  # 使用Gitlab Runner有相關的標籤\n  tags:\n    - Windows(根據你的Runner Tag去填寫)\n  此時若Runner設置無誤，就可以看到Gitlab開始跑CI/CD，如下圖  \n     根據此腳本，我們可以得知CI.yml的基本語法由stages及對應的job name中的script。若要新增Job則只需在stages新增，例如我們在test站點後新增build-release，請修改stage區塊如下   stages:          # List of stages for jobs, and their order of execution\n  - build\n  - test\n  - build-release # 新增build-release\n  - deploy\n  並將以下Script放置lint-test-job下   lint-test-job:   # This job also runs in the test stage.\n  stage: test    # It can run at the same time as unit-test-job (in parallel).\n  script:\n    - echo \"Linting code... This will take about 10 seconds.\"\n    - sleep 10\n    - echo \"No lint issues found.\"\n\n#新增build-release job\nbuild-release-job:\n  stage: build-release\n  script:\n    - echo \"Build release app package...\"\n    - echo \"Build complete.\"\n  接著做commit，我們即可看到Pipeline由三個站點變成四個站點  \n     build 與 test  build-job  一般在CI/CD Sample，很常會看到這個站點，用意在測試建置專案是否能編譯過。在dotnet core專案，我們在CLI模式下可以用dotnet build去建置專案，此時我們可以嘗試將build-job站點script加入dotnet build指令(建議先註解調build job以外的job Script站別)，如下   build-job:       # This job runs in the build stage, which runs first.\n  stage: build\n  script:\n    - echo \"Compiling the code...\"\n    - dotnet build SampleWebAPI\\src\\SampleWebAPI -c debug\n  更新yml file後，檢查一下Pipeline能否編輯的過。編譯過可看到訊息如下  \n     unit-test-job  接著我們嘗試加入Test Job，請刪除lint-test-job只保留unit-test-job並將dotnet test加入script，如下   unit-test-job:   # This job runs in the test stage.\n  stage: test    # It only starts when the job in the build stage completes successfully.\n  script:\n    - echo \"Running unit tests... This will take about 60 seconds.\"\n    - dotnet test SampleWebAPI\\test\\SampleWebAPI.Test\n  更新yml file後，檢查一下Pipeline能否編輯的過。編譯過可看到訊息如下  \n     使用變數  上述編譯與測試有使用到dotnet build與test，基本上我們可以將我們的src與test路徑寫成變數，這樣在使用上可以重複利用減少重複的程式碼   variables:\n  AppFolderPath: SampleWebAPI\\\\src\\\\SampleWebAPI\n  TestFolderPath: SampleWebAPI\\\\test\\\\SampleWebAPI.Test\n  接著將原本的Build與Test Jib Script換掉   build-job:       # This job runs in the build stage, which runs first.\n  stage: build\n  script:\n    - echo \"Compiling the code...\"\n    - dotnet build ${AppFolderPath} -c debug\n\nunit-test-job:   # This job runs in the test stage.\n  stage: test    # It only starts when the job in the build stage completes successfully.\n  script:\n    - echo \"Running unit tests... This will take about 60 seconds.\"\n    - dotnet test ${TestFolderPath}\n  \n因為我們使用dot net core，如果我們有寫測試Code，我們可以直接省略測試建置這個站點(build-job)。只需要做Test即可(unit-test-job)。下dot net test時，因為要跑測試，他會順便建置App專案。\n  CD撰寫  接著我們要做簡易的Release建置與部屬，因為Windows權限設置較麻煩，這部分Demo我們使用Linux Runner去實現(Windows系統若要快速啟用Linux Runner，可以使用WSL2)。請啟用Linux Runner並在Runner上設置好.net core需要編譯的SDK安裝，另外則是SSH安裝。  Runner設置好後，我們將上述提到的default區塊使用到的tags設定，由Windows改成Linux(在此可根據你的Linux設置)。接著將上述寫好的腳本將斜線改成反斜線，參考Script如下   # default表示所有job都會參考以及使用\ndefault:\n  # 使用Gitlab Runner有相關的標籤\n  tags:\n    - Linux\n\nvariables:\n  AppFolderPath: SampleWebAPI//src//SampleWebAPI\n  TestFolderPath: SampleWebAPI//test//SampleWebAPI.Test\n\nstages:          # List of stages for jobs, and their order of execution\n  - test\n\nunit-test-job:   # This job runs in the test stage.\n  stage: test    # It only starts when the job in the build stage completes successfully.\n  script:\n    - echo \"Running unit tests... This will take about 60 seconds.\"\n    - dotnet test ${TestFolderPath}\n\n  若已確定你的Pipeline無誤，接著就可以往下走測試Release建置與部屬  建置與部屬  在建置部屬之前，請先準備好你的部屬Server，目前此章節用的部屬Server為Ubuntu 20.04 Linux，並已安裝好   .Net Core 3.1 SDK  SSH  Docker  pm2  unzip  SSH設定  為了簡易Demo，連線部分我們直接使用ssh與部屬Server溝通，為了免登入密碼，故須設置ssh私鑰與公鑰。請至你的Linux Runner資料夾底下會有一個.ssh file。若你是照Gitlab上的步驟設置，沒意外你的Runner路徑會在home底下   # 切換sudo\nsudo -i\n\n# 切換到ssh目錄下\ncd /home/gitlab-runner/.ssh\n\n#產生金鑰匙(方便測試可全按Enter)\nssh-keygen\n\n#更改私鑰權限為600\nchmod 600 id_rsa\n\n# 接著將你的公鑰傳至你的部屬機上\nscp id_dsa.pub user@abc.xxx.xxx.xxx:/root/.ssh/id_dsa.pub\n  接著連過去部屬機   # 連線部屬機\nssh root@abc.xxx.xxx.xxx\n\n# 輸入密碼\n\n# 至SSH File底下將Key複製一分到authorized_keys檔案底下\ncat id_rsa.pub > authorized_keys\n\n# 確定authorized_keys權限為600\nchmod 600 authorized_keys\n\n# 登出\nexit\n\n# 再次登入確定是否免密碼\nssh root@abc.xxx.xxx.xxx\n\n  比較笨的方式，你也可以手動複製將你自己Runner下的私鑰手動複製到部屬機的authorized_keys檔案  Project SSH Key變數  確定好Runner與部屬機之間已可免密碼連線後，我們需要在將Runner的私鑰複製一份至專案的CI/CD設定下  請至你Group  YourPorject Repo/Settings/CICD 下  此時你會看到Variables，請新增一SSH_PRIVATE_KEY變數如下    \n須注意!因為是Group Runner，所以一開始我只將SSH PK設置在Group Setting的CICD設置變數下。結果Project上tags觸發Pipeline在部屬時找不到SSH PK。所以Project Repo若要上tags，須將SSH PK設置在Project Repo Setting的CICD變數設定下。\n  build-release-job與deploy  部屬機等環境設置好後，接下來就開始寫Release與deploy。先簡單帶artifacts版本，然後連至部屬主機將artifacts載下來後，解壓縮直接透過pm2將web api服務啟起來。  build-release-job  為了減少測試時間。我們可以先嘗試使用dotnet publish指令，自己先試看看有無問題，無問題通常可以直接將指令複製到script上。  建置release stage，參考script如下   default:\n  tags:\n    - Linux\n\nvariables:\n  AppFolderPath: SampleWebAPI//src//SampleWebAPI\n  TestFolderPath: SampleWebAPI//test//SampleWebAPI.Test\n\nstages:          \n  - test\n  # 建置release stage\n  - release\n\nunit-test-job:  \n  stage: test\n  script:\n    - echo \"Running unit tests... This will take about 60 seconds.\"\n    - dotnet test ${TestFolderPath}\n\n# 建置release stage\nbuild-release-job:\n  stage: release\n  script:\n    - echo \"Build release...\"\n    - dotnet publish ${AppFolderPath} -c release\n  建置artifacts  接著我們希望在release job完成後同步產生artifacts。參考script如下   build-release-job:\n  stage: release\n  script:\n    - echo \"Build release...\"\n    - dotnet publish ${AppFolderPath} -c release\n  artifacts:\n    # on_success always on_failure\n    when: always \n    # 30 mins, 1 weeks...\n    expire_in: 30 mins\n    paths:\n      - ./SampleWebAPI/src/SampleWebAPI/bin/release/netcoreapp3.1\n  我們將artifacts寫至build-release-job下，這邊會有幾個設定   when : upload articacts時機 (  參考點我 )  expire : articats 存活時間 (  參考點我 )  paths: 要包裝檔案的路徑  此時我們在跑一次Pipeline，就可以看到build-release-job下有個可下載的介面(如下圖)，代表你的artifactst產生成功。    artifacts url測試(  參考點我 )  接著我們可以透過url下載artifacts，Sample如下   https://gitlab.com/test8214/testproject/-/jobs/artifacts/main/download?job=build-release-job  可修改的部分   test8214 : 你的Group Url  testproject : Project Repository Name  main:表示主線  release-job:表示你的stage job  \n artifacts Project URL請根據你實際的 Project URL設定調整，誤直接照抄\n  所以此url的意思為要從testproject下main主線最後一個成功Pipeline的build-release-job下載artifacts。  另外，比較好的方法是用CI_JOB_TOKEN去打Job Artifacts API拿取Artifacts，參考如\n連結  https://docs.gitlab.com/ee/api/job_artifacts.html  因為url方式是拿取最後一個Pipeline的build-release-job產物，代表他會拿取前一個成功的Pipline產物不是當下運行Pipeline的build-release-job產物。  因為這樣，所以這個Demo就不會將build-release-job上only tags。讓deploy可以正確拿取目前運行Pipeline編譯好的程式碼如下。    \n較好的Pepeline設計是將release設置在tag觸發時，也就是做CD時機點。後續再找時間修正artifacts下載方式\n  deploy  在build-release-job做完後，接著我們要做deploy stage，一開始我們須建立ssh連線，腳本指令如下   deploy-job:\n  stage: deploy\n  script:\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -     \n    - mkdir -p ~/.ssh     \n    - chmod 700 ~/.ssh \n    -> \n      ssh -o StrictHostKeyChecking=no -v user@125.229.14.65 -p 40122\n  這部分會稍微難了解一點，整體來說，主要目的在於建立一個具有PK權限的連線，讓Gitlab Runner可以在不同已允許權限的部屬主機連線(也許不只一台)。  細節部分，ssh-agent有點像是管理ssh key的工具。  第一行eval通常是印出來的意思，有點類似 echo，不過他可以直接把指令顯示出來，所以此處為顯示ssh-agent的狀態。  第二行是把 gitlab的環境變數讀取出來，之後 tr -d  '\\r' 主要是把換行給取代掉，windows內建是CRLF 相當於 /r/n，而這邊的 /r 就是Carriage-Return，所謂的迴車字元。  第三行創建 -/.ssh 是在目前使用者目錄底下創建 .ssh，用來記錄等一下你的ssh連線資訊，通常ssh連線後，會記錄在一個叫做 known_host的檔案。  寫好連線deploy-job後，我們可以嘗試讓他跑看看能否連線部屬主機成功，   default:\n  tags:\n    - Linux\n\nvariables:\n  AppFolderPath: SampleWebAPI//src//SampleWebAPI\n  TestFolderPath: SampleWebAPI//test//SampleWebAPI.Test\n\nstages:          \n  - test\n  - release\n  # 部屬\n  - deploy\n\nunit-test-job:  \n  stage: test\n  script:\n    - echo \"Running unit tests... This will take about 60 seconds.\"\n    - dotnet test ${TestFolderPath}\n\n\nbuild-release-job:\n  stage: release\n  script:\n    - echo \"Build release...\"\n    - dotnet publish ${AppFolderPath} -c release\n  artifacts:\n    # on_success always on_failure\n    when: always \n    # 30 mins, 1 weeks...\n    expire_in: 30 mins\n    paths:\n      - ./SampleWebAPI/src/SampleWebAPI/bin/release/netcoreapp3.1\n# 部屬      \ndeploy-job:\n  stage: deploy\n  script:\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -     \n    - mkdir -p ~/.ssh     \n    - chmod 700 ~/.ssh \n    -> \n      ssh -o StrictHostKeyChecking=no -v user@125.229.14.65 -p 40122\n  若連線成功，deploy stage則會運行通過(打勾勾)，接著就可以開始寫連至部屬Server的指令了。這邊可以看到有一個->的符號，代表此符號區段下的指令是在SSH目標主機上執行。  接著連過去後，我們加入要執行的Script指令   # 部屬      \ndeploy-job:\n  stage: deploy\n  script:\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -     \n    - mkdir -p ~/.ssh     \n    - chmod 700 ~/.ssh \n    - >\n      ssh -o StrictHostKeyChecking=no -v user@125.229.14.65 -p 40122\n      \"mkdir -p ~/sampleapi &&\n       wget -O ~/sampleapi/release-build.zip https://gitlab.com/test8214/testproject/-/jobs/artifacts/main/download?job=build-release-job &&\n       sudo unzip -o ~/sampleapi/release-build.zip -d ~/sampleapi &&\n       pm2 start 'dotnet ~/sampleapi/SampleWebAPI/src/SampleWebAPI/bin/release/netcoreapp3.1/SampleWebAPI.dll --urls http://0.0.0.0:5000' --name 'code-sense-api-service' &&\n       pm2 delete code-sense-api-service &&\n       pm2 start 'dotnet ~/sampleapi/SampleWebAPI/src/SampleWebAPI/bin/release/netcoreapp3.1/SampleWebAPI.dll --urls http://0.0.0.0:5000' --name 'code-sense-api-service'\n      \"\n  指令內容大致是連至目標主機後，   在user下建置sampleapi資料夾  下載artifacts  解壓鎖  使用pm2將Service Run起來  \n artifacts Project URL請根據你實際的 Project URL設定調整，誤直接照抄\n    deploy完後此時就可以透過API，得到資料   http://x.x.x.x:你的對外Port/weatherforecast  \ndeploy可以看到pm2 start兩次，因為在第一次加入時沒有對應service name可以刪除會出錯。使用> /dev/null 測試沒用。只能先用此法暫解。章節目的還是在於如何建立一起一條簡易的CI/CD Pipeline為注。正式複雜的場合可以參考Docker版本\n  only tags  接著我們要在deploy上tags觸發事件(上標籤)，只需要在原本的script下，多一個tags屬性   # 部屬      \ndeploy-job:\n  stage: deploy\n  script:\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -     \n    - mkdir -p ~/.ssh     \n    - chmod 700 ~/.ssh \n    - >\n      ssh -o StrictHostKeyChecking=no -v user@125.229.14.65 -p 40122\n      \"mkdir -p ~/sampleapi &&\n       wget -O ~/sampleapi/release-build.zip https://gitlab.com/test8214/testproject/-/jobs/artifacts/main/download?job=build-release-job &&\n       sudo unzip -o ~/sampleapi/release-build.zip -d ~/sampleapi &&\n       pm2 start 'dotnet ~/sampleapi/SampleWebAPI/src/SampleWebAPI/bin/release/netcoreapp3.1/SampleWebAPI.dll --urls http://0.0.0.0:5000' --name 'code-sense-api-service' &&\n       pm2 delete code-sense-api-service &&\n       pm2 start 'dotnet ~/sampleapi/SampleWebAPI/src/SampleWebAPI/bin/release/netcoreapp3.1/SampleWebAPI.dll --urls http://0.0.0.0:5000' --name 'code-sense-api-service'\n      \"\n  # 上tags觸發事件\n  only:\n    - tags\n  上完tags後，deploy事件則只會在你上tag時觸發。接著就可以在tag頁面看到此次的release tag是否有通過Pipeline Job。    \n一般CD做release build與deploy都會上only tags，此範例因為artifacts還不確定是不是已正確方式拿取，所以只在deploy上only tags。\n  參考專案  Repository:  https://gitlab.com/test8214/testproject  Docker版本(Speak，後續待寫)  Repository:  https://gitlab.com/test8214/demoproject  ",{"id":206,"path":207,"dir":89,"title":208,"description":208,"keywords":209,"body":214},"content:4.cicd-2.0:appendix01.md","/cicd-2.0/appendix01","Appendix 01 Database Version Control",[92,210,211,212,213],"常用的資料庫版本更新方式，有下列兩種","Database Version Control Tools","Liquibase快速入門","參考","  前言  此章節主要是補充CI/CD 2.0的11.7章節的內容。  常用的資料庫版本更新方式，有下列兩種    State-based tools   通過比較兩個資料庫中的結構模型而產生的腳本(script)，使用此腳本進行資料庫升級。   Migration-based tools  創建遷移用的腳本，替資料庫從一個版本遷移到下一個版本。  State-based tools (基於狀態的版本控制)  \n     在  state based 模式底下，我們僅需要維護資料庫的目標狀態，每個  表(Table) 、  Stored Procedure 、  View 、  Trigger 將保存為單獨的SQL文件，這些SQL文件就是資料庫真實的樣貌。而升級資料庫所需的腳本會由工具自動生成，從而大大減輕維護成本。   可以想像成MySQL中的mysqldump所建立的DDL表結構語法。  在  IaC(Infrastructure-as-Code) 領域中，Kubernetes、HashiCorp Terraform等流行軟體皆採用這種方式。    💡 目前最流行的做法是推薦此方式，但此方法會有缺點，由於Script是系統產生的，因此還是得自行注意細節。\n  Migration-based tools (基於遷移的版本控制)  \n     基於遷移的方法是將所有的遷移腳本儲存在Repository中。每一個腳本都包含了一系列的DDL語句，例如: CREATE/ALTER/DROP TABLE。最終的資料庫中的資料表結構是由這些腳本按照順序的執行來完成的。  相比  state based 模式，該模式增加了成本的  維護 和  複雜性 ，但它能讓我們更直接地控制  遷移過程 ，從而能夠處理如資料庫遷移這樣上下文相關的場景。  Database Version Control Tools  本圖片的來源資料，是參考  網址  \n     Liquibase快速入門  安裝CLI  Liquibase版本，我們將採用4.15.0版本進行演示，記得必須要安裝Java 8以上(官方建議Java 11)。  Win10   前往  官網載點 或  Github Release 依照對應所需的版本進行安裝，我們使用zip檔進行安裝 \n   \n     \n   下載後進行解壓縮放到指定的路徑底下，將liquibase放置在  D:\\tool\\liquibase-4.15.0 路徑 \n   \n     \n   設定系統環境變數，添加  D:\\tool\\liquibase-4.15.0 路徑  測試指令，重新開啟Terminal，並輸入指令liquibase -v \n   \n     \n   Docker     # 下載image liquibase 4.15.0\n   docker   pull   liquibase/liquibase:4.15.0\n   \n   # 查看liquibase版本，測試是否安裝成工\n   docker   run   --rm   liquibase/liquibase:4.15.0   -v\n  初始化liquibase     # 初始化專案\n   liquibase   init   project\n   \n   # 查看初始化後的結果\n   ls\n   ## example-changelog.sql  liquibase.properties\n  安裝Package Manager  Liquibase提供預設Driver在  internal\\lib 底下，但某些適合的資料庫Driver還是沒有提供，因此我們可以使用  Liquibase Package Manager 來幫助我們快速的搜尋套件來完成。   更多的Liquibase Driver，參考  網址  安裝   前往  Github Release 進行下載，點選對應的OS進行下載，這邊採用Win10進行舉例。  下載完成後解壓縮，設定環境變數 → 系統變數 → Path → 編輯環境變數 → 加上  D:\\tool\\lpm-0.1.7-windows  → 重啟終端機(Terminal)  常用指令     # 查看目前可以使用的lib\n   lpm   update\n   \n   # 查看套件版本\n   lpm   -v\n   \n   # 搜尋套件mongodb名稱\n   lpm   search   mongodb\n   \n   # 將mongodb加入到套件中\n   lpm   add   -g   mongodb\n   lpm   add   -g   liquibase-mongodb\n   \n   # 查看目前加入的套件\n   lpm   list\n  💡 指令  lpm add 的參數  -g 說明     使用global會將套件安裝到lib資料夾中，此資料夾為liquibase預設的lib資料夾  沒使用global則會安裝到liquibase_libs底下，必須再額外執行  JAVA_OPTS 來設定Java環境  執行方式  一般liquibase的執行有兩種方式，分別為   完全的CLI指令，不需要透過  liquibase.properties 設定  使用CLI指令搭配  liquibase.properties 設定檔  常用命令     \n   # 初始化liquibase\n   liquibase   init   project\n   \n   # 產生changelog並把log等級debug寫入到error.log\n   liquibase   --log-level=debug   --logFile=error.log   generateChangeLog\n   \n   # liquibase更新資料庫\n   liquibase   update\n   \n   # liquibase更新資料庫，並且指定某個shopping_cart\n   liquibase   --labels=  \"feature/shopping_cart\"   update\n   \n   # liquibase更新資料庫，指定dev環境上版本\n   liquibase   --log-level=debug   --contexts=  \"dev\"   update\n   \n   # 替目前最後一筆DATABASECHANGELOG，進行tag上版本\n   liquibase   tag   version_1.3\n   \n   # 將所有指定的資料庫中的所有資料表丟棄 (包含非liquibase創建)\n   liquibase   drop-all\n   \n   # 往回退回一個changeset版本\n   liquibase   rollbackCount   1\n   \n   # 退回到version_1.3的tag版本\n   liquibase   rollback   version_1.3\n   \n   # 查看changeset的列表\n   liquibase   status   --verbose\n   \n   # 驗證dbchangelog.xml的格式是否正確\n   liquibase   validate\n  從現有資料庫產生ChangeLog     # 從現有資料庫產生ChangeLog\n   liquibase   --driver=com.microsoft.sqlserver.jdbc.SQLServerDriver   \\\n     --classpath=D:/tool/liquibase-4.15.0/internal/lib/mssql-jdbc.jar   \\\n     --url=jdbc:sqlserver://127.0.0.1:1433  ;database  =  Test_Liquibase_Demo  ;trustServerCertificate  =  true  ;   \\\n     --changeLogFile  =  dbchangelog-test.xml   \\\n     --username  =  test   \\\n     --password  =  12345678   \\\n     generateChangeLog\n   \n   # 查看產生的結果\n   ls\n   ##dbchangelog-test.xml\n  Migration-based  傳統的Migration方式，藉由Script版本來進行控制。  前置作業  請先在SQL Serer中建立  Test_Liquibase_Demo 資料庫。  新增資料   修改  liquibase.properties     classpath=D:/tool/liquibase-4.15.0/internal/lib/mssql-jdbc.jar\n   driver=com.microsoft.sqlserver.jdbc.SQLServerDriver\n   url=jdbc:sqlserver://127.0.0.1:1433;database=Test_Liquibase_Demo;trustServerCertificate=true;\n   username=test\n   password=12345678\n   changeLogFile=dbchangelog.xml\n   liquibase.hub.mode=off\n  初始化ChangeLog(產生dbchangelog.xml)     # 初始化，將錯誤訊息，塞入到error.log中\n   liquibase   --log-level=debug   --logFile=error.log   generateChangeLog\n  新增  DbChangeLog_V1.0.sql   --liquibase formatted sql\n--changeset changemyminds:00001 labels:first-time\n--comment Create Users table\nCREATE TABLE Users (\n    -- 使用者編號\n    ID INTEGER NOT NULL IDENTITY NOT FOR REPLICATION,\n    -- 使用者姓名\n    Username NVARCHAR (50) NOT NULL,\n    -- 使用者密碼\n    Password NVARCHAR (50) NOT NULL,\n    -- 使用者狀態\n    Status INTEGER NOT NULL,\n);\n--rollback DELETE FROM Users;\n\n--changeset changemyminds:00002 labels:first-time\n--comment Insert default users\nINSERT INTO\n    Users (Username, Password, Status)\nVALUES\n    ('Darren', '11111111', 1),\n    ('spyua', '11111111', 1),\n    ('Jimpo', '11111111', 1),\n    ('frank', '11111111', 1);\n--rollback DELETE FROM Users WHERE Username='Darren' OR Username='spyua OR Username='Jimpo OR Username='frank'    \n  新增  DbChangeLog_V1.1.sql   --liquibase formatted sql\n--changeset changemyminds:00003 labels:feature/shopping_cart\n--comment Create table SHOES\nCREATE TABLE SHOES(\n [ID] [bigint] IDENTITY(1, 1) NOT NULL PRIMARY KEY,\n Brand VARCHAR(50),\n Size bigint, \n);\n--rollback DROP TABLE SHOES\n\n--changeset changemyminds:00004 labels:feature/shopping_cart\n--comment Insert shoes record\nINSERT INTO SHOES(Brand, Size) VALUES('Addias', 100);\nINSERT INTO SHOES(Brand, Size) VALUES('NewBlance', 400);\n--rollback DELETE FROM SHOES WHERE Brand='Addias' OR Brand='NewBlance'\n  修改  dbchangelog.xml   \u003C?xml version=\"1.1\" encoding=\"UTF-8\" standalone=\"no\"?>\n\u003CdatabaseChangeLog xmlns=\"http://www.liquibase.org/xml/ns/dbchangelog\" xmlns:ext=\"http://www.liquibase.org/xml/ns/dbchangelog-ext\"     xmlns:pro=\"http://www.liquibase.org/xml/ns/pro\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.    liquibase.org/xml/ns/dbchangelog-ext http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-ext.xsd http://www.liquibase.org/xml/ns/pro     http://www.liquibase.org/xml/ns/pro/liquibase-pro-latest.xsd http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/    dbchangelog/dbchangelog-latest.xsd\">\n    \u003Cinclude file=\"DbChangeLog_V1.0.sql\" />\n    \u003Cinclude file=\"DbChangeLog_V1.1.sql\" />\n    \u003C!-- 新增Tag版本 -->\n    \u003CchangeSet id=\"tag_1.2\" author=\"changemyminds\">\n        \u003CtagDatabase tag=\"version_1.2\" />\n    \u003C/changeSet>\n\n\u003C/databaseChangeLog>\n  常見操作     \n   # 執行first-time標籤，進行migration\n   liquibase   --log-level=debug   --labels=  \"first-time\"   update\n   \n   # 執行全部的migration\n   liquibase   --log-level=debug   update\n   \n   # 執行rollback\n   liquibase   rollbackCount   1\n   \n   # 將所有指定的資料庫中的所有資料表丟棄 (包含非liquibase創建)\n   liquibase   drop-all\n  State-based  某些情況下我們想要比較Database的版本，例如: 測試機的  Schema 和正式機的  Schema 中的差異，然後自動產生正式機可以使用SQL Script來讓我進行操作。  我們需要利用  diff 、  diffChangeLog 、  updateSQL 、  futureRollbackSQL 來完成。   使用  State-based 方式，由於產生的腳本(script)是由  Liquibase 進行產生的，因此可能會有差異，建議還是要檢查，若沒有安全感的話，建議還是使用  Migration-based 比較可以自己掌控。  前置作業  請先在SQL Serer中建立  Test_Liquibase_Demo_Prod 資料庫。  執行操作   新增  liquibase.properties     # 連線的驅動driver\n   classpath=D:/tool/liquibase-4.15.0/internal/lib/mssql-jdbc.jar\n   driver=com.microsoft.sqlserver.jdbc.SQLServerDriver\n   \n   # 產生的檔案\n   changeLogFile=dbchangelog.xml\n   \n   # 關閉hub\n   liquibase.hub.mode=off\n   \n   # 正式機資料庫\n   url=jdbc:sqlserver://127.0.0.1:1433;databaseName=Test_Liquibase_Demo_Prod;trustServerCertificate=true;\n   username=test\n   password=12345678\n     \n   # 參考的測試機資料庫\n   referenceUrl=jdbc:sqlserver://127.0.0.1:1433;databaseName=Test_Liquibase_Demo;trustServerCertificate=true;\n   referenceUsername=test\n   referencePassword=12345678\n  執行指令     \n   # 對資料庫進行兩者差異的比較，並將結果寫入到檔案中\n   liquibase   diff   --outputFile=diff_between_DEV_PROD.log\n   \n   # 對資料庫進行兩者差異的比較，並且產生changelog\n   liquibase   diffChangeLog\n   \n   # 創建差異的SQL\n   liquibase   updateSQL   >   update.sql\n   \n   # 也可以產生rollback的sql\n   liquibase   futureRollbackSQL   >   rollback.sql\n  更新正式機資料庫     liquibase   update\n  參考    liquibase   version-control-tools  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":216,"path":217,"dir":218,"title":219,"description":219,"keywords":220,"body":225},"content:5.ddia:appendix00.md","/ddia/appendix00","ddia","Appendix 00 Redis快速入門",[92,221,222,223,224,213],"安裝","常用的資料結構","其他常用功能","常見的三大問題","  前言  此章節不屬於  資料密集型應用系統設計 書中內容，額外挪出的一個教學章節。  這邊主要是補充快取(Cache) Redis資料庫的使用方式以及操作。  安裝  版本號選擇   奇數： 2.7、2.9、3.1，為  不穩定版本  偶數： 2.6、2.8、3.0，為  穩定版本  Linux安裝  原始碼安裝     # 下載檔案\n   curl   -LO   \"https://download.redis.io/releases/redis-6.2.7.tar.gz\"   \n   \n   # 解壓縮\n   tar   -xvf   redis-6.2.7.tar.gz\n   \n   # 移除安裝檔\n   rm   redis-6.2.7.tar.gz\n   \n   # 前往解壓縮目錄\n   cd   redis-6.2.7\n   \n   # 編譯專案 (類似編譯了class)\n   make\n   \n   # 將binary檔安裝到某個目錄底下\n   make   install   PREFIX=/root/redis-6.2.7/redis\n   \n   # 查看make的安裝目錄\n   $   ls   /root/redis-6.2.7/redis/bin/\n   redis-benchmark    redis-check-aof    redis-check-rdb    redis-cli    redis-sentinel    redis-server\n  💡 如果執行make指令報錯誤，則需要執行下列指令，進行安裝   Ubuntun     # 請先確認gcc是否安裝\n   gcc   -v\n   \n   # 更新apt套件\n   sudo   apt-get   update\n   \n   # 安裝apt套件\n   sudo   apt   -y   install   gcc   automake   autoconf   libtool   make\n  CentOS     \n   # 請先確認gcc是否安裝\n   gcc   -v\n   \n   # 更新yum套件\n   sudo   yum   update\n   \n   # 安裝yum套件\n   sudo   yum   -y   install   gcc   automake   autoconf   libtool   make\n  安裝目錄底下的檔案介紹     可執行的檔案  功能用途    redis-server  啟動redis伺服器   redis-cli  redis客戶端(client)操作   redis-benchmark  性能測試工具，可以在本機電腦運行，看看本機效能如何 (服務啟動起來後執行)   redis-check-aof  AOF持久化文件檢測和修復工具   redis-check-rdb  RDB持久化文件檢測和修復工具   redis-sentinel  啟動哨兵模式 (Redis Cluster使用)  其他安裝   apt安裝     # lsb: Linux Standard Base縮寫，用來顯示LSB和特定版本的相關訊息\n   # 某些最小環境的情況下需要安裝，例如在Docker Container內部\n   sudo   apt   install   lsb-release\n   \n   # 將repository加入到apt index中，後續進行更新和安裝\n   curl   -fsSL   https://packages.redis.io/gpg   |   sudo   gpg   --dearmor   -o   /usr/share/keyrings/redis-archive-keyring.gpg\n   echo   \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(  lsb_release   -cs  ) main\"   |   sudo   tee   /etc/apt/sources.list.d/redis.list\n   \n   # 更新apt-get\n   sudo   apt-get   update\n   \n   # 安裝redis\n   sudo   apt-get   install   redis\n   snap安裝     # 查詢redis名稱\n   snap   find   redis\n   \n   # 查看redis的資訊\n   snap   info   redis\n  Windows實體安裝  Redis主要支援在Linux環境底下，因此在Windows環境底下支援性很差。\n目前有兩個非官方的使用載點可以參考。    網友版本 - 5.0.14.1 ，目前還有在維護   微軟版本 - 3.0.504 ，目前已經不在維護。  Docker安裝   Redis Server     docker   run   --name   redis   -d   -p   6379  :6379   redis:6.2.4-alpine\n  Redis CLI     # 這邊的IP 192.168.23.192，替換為主機的IP\n   docker   run   -it   --rm   redis   redis-cli   -h   192.168  .23.192   -p   6379\n  更多Docker使用方式參考  Redis Official  常用操作工具    RedisInsight  redis-cli  官方推薦  RedisInsight 一款Web base的工具，個人習慣使用  redis-cli 和  RedisInsight 一起使用。  由於大家一起使用RedisInsight，為了方便查看client端是誰，這邊我們設定Redis Client的使用者名稱     # 設定client的名稱，將darren替換成你自己的名子\n   CLIENT   SETNAME   darren\n   \n   # 查看目前有哪些連線的client\n   CLIENT   LIST\n  常用的資料結構  Strings    String 是  Redis 最基本的類型，可以理解成與  Memcached 一模一樣的類型，一個  Key 對應一個  Value   String 類型是二進制(Binary)安全的。意味著  Redis 的  String 可以包含資料。比如jpg圖片或者序列化的物件   String 類型是  Redis 最基本的資料類型，一個Redis中Value最多可以是512M  原子性\n   所謂原子性操作，是指不會被其他執行緒的呼叫機制打斷的操作，這種操作一但開始，就一直運行到結束，中間不會有任何的context switch (切換到另外一個執行緒)\n   在  單執行緒 中，能夠在單條指令中完成的操作都可以認為是”原子操作”，因為中斷只能發生於指令之間  在  多執行緒 中，不能被其它執行緒打斷的操作，就叫”原子操作”  常用指令  set / get / append / strlen / setnx     # 增加key: k1, value: v1\n   >   set k1 v1\n   \n   # 更新key: k1, value: v11\n   >   set k1 v11\n   \n   # 取得value數值\n   >   get k1\n   \"v11\"\n   \n   # 從尾部後相加，回傳目前value整體的長度\n   >   append k1 __\n   (  integer  ) 5\n   \n   # 取得append後的長度\n   >   get k1\n   \"v11__\"\n   \n   # 取得k1中的value長度\n   >   strlen k1\n   (  integer  ) 5\n   \n   # 只有key不存在時，才會設置key的值\n   >   setnx k1 k0000\n   (  integer  ) 0\n  incr / decr / incrby / decrby     # 增加key: k1, value: v1\n   >   set k1 v1\n   \n   # incr只支援integer\n   >   incr k1\n   (  error  ) ERR value is not an integer or out of range\n   \n   # 替不存在的k2進行\"數字字串\"值加1\n   >   incr k2\n   (  integer  ) 1\n   \n   # 替存在的k2進行\"數字字串\"加1\n   >   incr k2\n   (  integer  ) 2\n   \n   # 替存在的k2進行\"數字字串\"減1\n   >   decr k2\n   (  integer  ) 1\n   \n   # 替存在的k2進行\"數字字串\"減1\n   >   decr k2\n   (  integer  ) 0\n   \n   # 替存在的k2進行\"數字字串\"減1\n   >   decr k2\n   (  integer  ) -1\n   \n   # 取得k2數值，記得他是\"數字字串\"\n   >   get k2\n   \"-1\"\n   \n   # 一次加上100的數值\n   >   incrby k2 100\n   (  integer  ) 99\n   \n   # 一次減上100的數值\n   >   decrby k2 100\n   (  integer  ) -1\n  setex / getset     set   k1   v1\n   \n   # 設定過期時間\n   expire   k1   1000\n   \n   # 更新數值\n   set   k1   v2\n   \n   # 查詢數值\n   >   ttl k1\n   (  integer  ) -1\n   \n   # 將k1設定為100，且數值為v2 (重新設定則時間重新計算)，下面兩種方式皆可以\n   >   setex k1 100 v2\n   >   set k1 v2 EX 100\n   \n   # 傳入新增的v3參數，把舊的v2傳回 (與Java中的HashMap的Put功能相同)\n   >   getset k1 v3\n   \"v2\"\n  使用場景   快取(Cache)資料  計數器。\n   用來統計文章瀏覽次數  某些商品的點擊數量等等  分散式共享Session  設定過期(Expire)來完成時效性的資料\n   手機驗證碼  使用者登入碼  分散式鎖  Hash   Redis hash是一個鍵值集合  Redis hash是一個string類型的  field 和  value 的映射表，hash特別適合用於  儲存物件  類似Java中的  Map\u003CString, Object> ，  C# 中的  Dictionary\u003Cstring, object>  常用指令  hset / hget / hmset     # 設定假資料\n   >   hset h1 familyName Chang\n   >   hset h1 givenName EnShuo\n   >   hset h1 age 28\n   \n   # 取得hash中的數值\n   >   hget h1 familyName\n   \"Chang\"\n   >   hget h1 givenName\n   \"EnShuo\"\n   >   hget h1 test\n   (  nil  )\n   \n   # 使用批次來進行設定\n   >   hmset h2 familyName Chang givenName EnShuo age 28\n   OK\n  hexists / hkeys / hvals / hincrby / hsetnx     # 設定假資料\n   >   hset h1 familyName Chang givenName EnShuo age 28\n   \n   # 查看h1中是否存在field\n   >   hexists h1 age\n   (  integer  ) 1\n   >   hexists h1 sex\n   (  integer  ) 0\n   \n   # 取得所有的h1的field\n   >   hkeys h1\n   1  )   \"familyName\"\n   2  )   \"givenName\"\n   3  )   \"age\"\n   \n   # 取得所有的h1中的value\n   >   hvals h1\n   1  )   \"Chang\"\n   2  )   \"EnShuo\"\n   3  )   \"28\"\n   \n   # 替age加上3\n   >   hincrby h1 age 3\n   (  integer  ) 31\n   \n   # 當age存在時，操作失敗\n   >   hsetnx h1 age 100\n   (  integer  ) 0\n   \n   # 當sex不存在時，則新增\n   >   hsetnx h1 sex man\n   (  integer  ) 1\n  使用場景   儲存使用者資訊，例如使用者名稱、密碼、電子郵件地址、手機號碼等。  儲存商品資訊，例如商品名稱、價格、庫存數量、圖片等。  儲存文章資訊，例如文章標題、作者、發布時間、內容等。  儲存設定資訊，例如資料庫連線字串、快取時間、超時時間等。  Lists   單一鍵值(Key)多個數值(Value)  是一個字串列表，按照插入順序排序。你可以添加一個元素到列表的  頭部(左邊)  或 尾部(右邊)  它的底層其實是  雙鏈接串列 ，對兩端的操作性能很高，通過索引下的操作中間的節點效能比較差  常用指令  lpush / rpush / lpop / rpop / rpoplpush     # 從key值l1左邊推送四筆資料，因此順序為v4 v3 v2 v1\n   >   lpush l1 v1 v2 v3 v4\n   (  integer  ) 4\n   \n   # 從key值l1右邊推送三筆資料，因此順序為v4 v3 v2 v1 v5 v6 v7\n   >   rpush l1 v5 v6 v7\n   (  integer  ) 7\n   \n   # 從左方取得數值\n   >   lpop l1\n   \"v4\"\n   \n   # 從右方取得數值\n   >   rpop l1\n   \"v7\"\n   \n   # 從左方key值l2推送v2、v3，因此順序為v3、v2\n   >   lpush l2 v2 v3\n   \n   # 從左方key值l3推送v1，因此順序為v1\n   >   lpush l3 v1\n   \n   # 從l2(key)右邊取值，從l3(key)左邊推入\n   # l2: v3\n   # l3: v2、v1\n   >   rpoplpush l2 l3\n   \n   # 從l3(key)取值，則取到v1\n   >   rpop l3\n   \"v1\"\n  lrange / lindex / llen     # 從key值l1左邊推送四筆資料，因此順序為v4 v3 v2 v1\n   >   lpush l1 v1 v2 v3 v4\n   (  integer  ) 4\n   \n   # 取得0(索引)的第0個位置\n   >   lrange l1 0 0\n   1  )   \"v4\"\n   \n   # 取得1(索引)的第一位\n   >   lrange l1 1 2\n   1  )   \"v3\"\n   2  )   \"v2\"\n   \n   # 用反轉(負號)的方式獲取全部，從左到右一次全部取出\n   >   lrange l1 0 -1\n   1  )   \"v4\"\n   2  )   \"v3\"\n   3  )   \"v2\"\n   4  )   \"v1\"\n   \n   # 測試取值\n   >   lindex l1 0\n   \"v4\"\n   >   lindex l1 -1\n   \"v1\"\n   >   lindex l1 -10\n   (  nil  )\n   \n   # 取得長度\n   >   llen l1\n   (  integer  ) 4\n  使用場景   實現佇列(Queue)：可以將新加入的元素插入到清單的末尾，將清單的第一個元素刪除即可實現佇列的先進先出 (FIFO) 的特性。  實現堆疊(Stack)：可以將新加入的元素插入到清單的末尾，將清單的最後一個元素刪除即可實現棧的後進先出 (LIFO) 的特性。  儲存日誌資訊：例如系統日誌、應用程式日誌等。  實現訊息佇列(Message Queue)：可以將訊息插入到清單的末尾，然後通過消費者(Consumer)不斷從清單的末尾獲取訊息來實現訊息的非同步處理。  Sets   Redis Set對外提供的功能與  list 類似也是一個列表的功能，它特殊之處在於可以排除重複的數值，當如果要儲存的一個資料列表，不希望出現重複的資料時，set是一個很好的選擇，且set提供API能判斷某個資料是否存在於集合中，而list沒有這種API。  Redis的Set是string類型的無序集合。它底層是一個Hash table，因此  新增 、  刪除 、  查詢 的時間複雜度皆為  O(1)  常用指令  sadd / smembers / sismember     # 會自動將重複的數值進行過濾\n   >   sadd s1 v1 v1 v1 v2 v3 v4 v5 v5\n   (  integer  ) 5\n   \n   # 顯示set的s1(key)的所有數值\n   >   smembers s1\n   1  )   \"v2\"\n   2  )   \"v1\"\n   3  )   \"v4\"\n   4  )   \"v3\"\n   5  )   \"v5\"\n   \n   # 判s1(key)中的v1是否存在\n   >   sismember s1 v1\n   (  integer  ) 1\n   \n   # 判s1(key)中的v9是否存在\n   >   sismember s1 v9\n   (  integer  ) 0\n  scard / srem / spop / srandmember     # 將數值進行加入\n   >   sadd s1 v1 v2 v3 v4 v5\n   (  integer  ) 5\n   \n   # 取得s1(key)的數量\n   >   scard s1\n   (  integer  ) 5\n   \n   # 刪除s1(key)中的v4\n   >   srem s1 v4\n   (  integer  ) 1\n   \n   # 隨機從s1(key)中取出，並進行刪除\n   >   spop s1 2\n   1  )   \"v3\"\n   2  )   \"v2\"\n   \n   # 隨機從s1(key)中取出，並不刪除\n   >   srandmember s1 2\n   1  )   \"v5\"\n   2  )   \"v1\"\n  sinter / sunion / sdiff     # 新增兩個set，做為測試\n   >   sadd s1 v1 v2 v3 v4\n   >   sadd s2 v3 v4 v5 v6\n   \n   # 取交集\n   >   sinter s1 s2\n   1  )   \"v3\"\n   2  )   \"v4\"\n   \n   # 取聯集\n   >   sunion s1 s2\n   1  )   \"v4\"\n   2  )   \"v6\"\n   3  )   \"v3\"\n   4  )   \"v2\"\n   5  )   \"v1\"\n   6  )   \"v5\"\n   \n   # 取s1的差集\n   >   sdiff s1 s2\n   1  )   \"v1\"\n   2  )   \"v2\"\n   \n   # 取s2的差集\n   >   sdiff s2 s1\n   1  )   \"v5\"\n   2  )   \"v6\"\n  使用情境   實現抽獎功能，例如: 在一個抽獎活動中，可以使用sets將所有的參與者的訊息加入到集合中  統計網站拜訪過的IP。將拜訪過的使用者IP進行加入到集合中，由於set可以防止重複訊息，因此最終可以顯示唯一。  追蹤聊天室的成員，並通過集合運算來管理成員的列表。  Sorted sets   Reids有序集合zset與普通的set非常相似，也是一個沒有重複元素的字串集合。不同之處在於zset的  \u003Cvalue> 都關聯一個評分(score)，這個評分(score)被用來按照從低分到最高分的方式排序。集合的  \u003Cvalue> 是唯一的，但評分(score)可以是重複的。  因為元素是有序的，所以可以根據評分(score)或者次序(postion)來獲取一個範圍的元素。存取zset的中間元素也是非常快的，因此你能夠zset做為一個沒有重複  \u003Cvalue> 的智能列表。  常用指令  zadd / zrange / zrangebyscore / zrevrangebyscore     # 增加參數\n   >   zadd z1 100 chang 200 chen 150 huang\n   (  integer  ) 3\n   \n   # 查看原本資料\n   >   zrange z1 0 -1\n   1  )   \"chang\"\n   2  )   \"huang\"\n   3  )   \"chen\"\n   \n   # 替huang的score增加51為150+51 = 201\n   >   zincrby z1 51 huang\n   \"201\"\n   \n   # 查看修改後的資料\n   >   zrange z1 0 -1 withscores\n   1  )   \"chang\"\n   2  )   \"100\"\n   3  )   \"chen\"\n   4  )   \"150\"\n   5  )   \"huang\"\n   6  )   \"201\"\n   \n   # 統計z1中的100~200分數之間有幾個\n   >   zcount z1 100 200\n   (  integer  ) 2\n   \n   # 取得該\u003Ckey>集合中的排名，由0開始計算\n   >   zrank z1 chen\n   (  integer  ) 1\n   \n   # 取不到數值時，則回傳(nil)\n   >   zrank z1 error\n   (  nil  )\n   \n   # 刪除該z1中的chen\n   >   zrem z1 chen\n   (  integer  ) 1\n  使用情境   實現一個文章的閱讀排行榜  根據時間排序的新聞列表  直播聊天室中的送禮排行榜  其他常用功能  Transactions  介紹   Reids事務是一個單獨的隔離操作，事務中的所有命令都會被序列化、按順序地執行。事務在執行的過程中，不會被其他客戶端發送來的命令請求給中斷。  Redis事務的主要作用就是串聯多個命令防止別的命令插隊  Multi / Exec / discard   從輸入  Multi 指令開始，輸入的命令都會依次進入命令柱列中，但不會執行，直到輸入  Exec 後，Redis會將之前的命令柱列中的命令依序執行  如果不想要這次的命令柱列，我們可以透過  discard 來進行放棄。  使用一個  Client A 和  Client B 來進行模擬操作     # Client A 開啟事務\n   >   Multi\n   OK\n   \n   # Client A執行操作\n   (  TX  )  >   set k1 v1\n   QUEUED\n   \n   # Client A執行操作\n   (  TX  )  >   get k1\n   QUEUED\n   \n   # Client B執行操作\n   >   set k1 v100\n   OK\n   \n   # Client A執行操作，可以發現將一連串的動作執行操作，不受Client B客戶端的操作\n   (  TX  )  >   Exec\n   1  ) OK\n   2  )   \"v1\"\n  將事務進行丟棄     # 開啟事務\n   >   Multi\n   OK\n   \n   # 設定k7數值，不小心打錯\n   (  TX  )  >   set k7\n   (  error  ) ERR wrong number of arguments   for   'set'   command\n   \n   # 將本次事務進行丟棄\n   localhost:6379(TX  )  >   discard\n   OK\n  使用watch / unwatch指令 (樂觀鎖)    watch   在執行  multi 之前，先執行  watch \u003Ckey1> \u003Ckey2> ，可以監視一個或多個  \u003Ckey> ，如果事務執行之前，這個(或這些)key的數值，被其他指令或他人改動過，那麼事務將被打斷。   unwatch   取消  WATCH 命令對所有key的監控  如果在執行  WATCH 命令之後，  EXEC 或  DISCARD 命令先被執行的話，就不需要在執行  UNWATCH 了  使用Redis中  Watch 的功能，這種方式就是  check-and-set 機制     # 初始化k1的數值為1 (Client A)\n   >   set k1 1\n   OK\n   \n   # 啟用監看key k1功能 (Client A)\n   >   WATCH k1\n   OK\n   \n   # 開啟事務交易 (Client A)\n   >   MULTI\n   OK\n   \n   # 此時有人修改k1內的數值為4 (Client B)\n   >   set k1 4\n   OK\n   \n   # 替k1的value進行+1 (Client A)\n   (  TX  )  >   incr k1\n   QUEUED\n   \n   # 替k1的value進行+1 (Client A)\n   (  TX  )  >   incr k1\n   QUEUED\n   \n   # 執行事務結果，可以發現執行是失敗的，沒有返回兩個結果 (Client A)\n   (  TX  )  >   exec\n   (  nil  )\n  三大特性   單獨的隔離操作\n   事務中所有命令都會序列化、按順序地執行。事務在執行的過程中，不會被其他客戶端發送來的命令請求打斷  沒有隔離級別的概念\n   柱列中的命令沒有提交之前都不會實際的被執行，因為事務提交前任何指令都不會被實際執行  不保證原子性\n   Redis同一個事務中，如果有一條命令執行失敗了，其後面的命令仍然會被執行且沒有回滾(Rollback)  Pub/sub  使用上的限制   Pub/Sub的內容，是不會用Key的方式去保存的，所以自然資料無法持久化，所以資料有可能會遺失。  當發送者(Pub)有發送消息時且訂閱者(Sub)連線中斷，則訂閱者將無法接收到此筆訊息  Redis Server服務停止或當機，則資料會遺失  Redis設定參數     # 32mb：緩衝區(buffer)一旦超過 32MB，Redis 直接將訂閱者(Sub)會強制踢    下線\n   # 8mb + 60：緩衝區超過 8MB，並且持續 60 秒，Redis 也會把訂閱(Sub)會    被踢下線。\n   client-output-buffer-limit   pubsub   32  mb   8  mb   60\n  使用上的限制  使用上的考量   由於Pub/Sub的內容，是不會進行保存的，所以重要的資料不建議使用此方式來傳遞  發佈者(Pub)發布消息後，並不會管訂閱者(Sub)是否有接收到消息，也沒有ACK機制，所以無法確定訂閱者(Sub)是否有接收到訊息，因此在可靠訊息的場合中不建議使用  訂閱者(Sub)會占用一個Redis Server的連線，所以要注意是否有佔用過多的連線  當發佈者(Pub)發送”大量”訊息，若訂閱者(Sub)來不及消化，資料會阻塞在通道(channel)中，阻塞時間越長，資料丟失的風險就越高，當訊息量過大時，會造成緩衝區(buffer)溢出，就會導致資流失  常用指令     # 查看全部的channel\n   >   PUBSUB CHANNELS\n   >   PUBSUB CHANNELS   *\n   \n   # 查看channel使用wild card\n   >   PUBSUB CHANNELS sss  *\n   \n   # 訂閱listen:something的頻道\n   SUBSCRIBE   listen:something\n   \n   # 發送資料給listen:something的頻道\n   PUBLISH   listen:something   hello\n   \n   # 解除訂閱listen:something的頻道\n   UNSUBSCRIBE   listen:something\n   \n   # 使用MONITOR來Debug模式查看目前送出狀態\n   MONITOR\n  使用情境   SignalR / WebSocket 在K8s底下多個Pod的廣播應用，  Redis backplane  在網頁應用程序中實現的即時聊天室。例如: 當有一個用戶在聊天室中發布了一條消息時，所有訂閱該消息的用戶都會收到通知。  常見的三大問題  Cache Penetration (快取穿透)  在高併發的情況下，查詢一個不存在的數值時會發生。例如: id為   -1  或  特別大不存在的資料時 ，會造成Cache內的資料是找不到的，既然從Cache中找不到數值，因此大量的Request皆會落到資料庫上，造成資料庫負擔。  💡 請求未命中的Cache，直接存取資料庫，這就是快取穿透。  ✅ 解決方式   在Interface層  增加驗證 ，比如使用者權限驗證、參數驗證，不合法的參數就直接Return，比如: id做基本的驗證，id ≤ 0直接  return 。   快取NULL數值 ，但是Cache NULL的時間不能太長，否則NULL資料長時間得不到更新，也不能太短，否則達不到防止Cache Penetration(快取穿透)  布隆過濾器(Bloom Filter) 類似Hash table的演算法，將所有可能的查詢生成一個bitmap，在進行資料庫查詢之前會使用這個bitmap進行過濾，如果不在其中則直接過濾，從而減輕資料庫層面的壓力。  Cache Breakdown / Hotspot Invalid (快取擊穿)  在Cache中的一個Key(比如一個促銷商品)，在某個時間點過期的時候，恰好這個時間點對這個Key有大量的高併發請求，這些請求發現Cache過期了，因此都從資料庫加載資料回Cache，如果這個時間點有高併發請求則可能會瞬間造成資料庫壓垮。  💡 熱點Key，Cache過期，直接攻擊資料庫  ✅ 解決方式   設置熱資料(Hot data)永遠  不過期  使用加互斥鎖，對Cache查詢時加鎖，如果Key不存在就加鎖，然後查DB進入到Cache中，然後解鎖，其他執行緒發現有鎖就必須等待，然後解鎖後返回資料或到資料庫查詢  Cache Avalanche (快取雪崩)  大量的Cache Key在同一時間失效，導致大量的請求都落在資料庫上，如活動系統裡面同時進行著非常多的活動，但在某個時間點所有的Cache皆過期。   設置熱資料(Hot data)永遠  不過期  Cache資料的過期時間設置為隨機，防止同一時間大量資料過期現象發生。  參考    關於 Redis Persistence - 資料持久化   Redis Pub/Sub   一分鐘學習Redis常見的三大問題  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":227,"path":228,"dir":218,"title":229,"description":229,"keywords":230,"body":236},"content:5.ddia:appendix01.md","/ddia/appendix01","Appendix 01 gRPC快速入門",[231,232,233,234,235,213],"HTTP2入門介紹","Protobuf 3介紹","gRPC Code generator","gRCP 呼叫的四種類型","gRPC工具","  HTTP2入門介紹  HTTP/2 概述  HTTP/2 是 HTTP 協議的第二個版本，它基於 Google 的 SPDY 協議，旨在提高網頁的加載速度和性能。相比於 HTTP/1.x，HTTP/2 改進了以下方面：   多路徑傳輸 (Multiplexing)：HTTP/2 允許同一個 TCP 連接上進行多個請求和響應，從而減少了 TCP 連接數量和建立連接的延遲。\n首部壓縮 (Header Compression)：HTTP/2 使用 HPACK 算法對首部進行壓縮，從而減少了首部大小，降低了帶寬消耗。\n服務端推送 (Server Push)：HTTP/2 允許服務器在響應一個請求時主動推送相關的資源到客戶端緩存中，從而提高頁面加載速度。\n  HTTP/2 原理  HTTP/2 使用二進制格式傳輸資料，將資料分為 HEADERS 和 DATA 兩部分。多個請求和響應可以在同一個 TCP 連接上進行，每個請求和響應都有自己的 ID。HTTP/2 也支持優先級 (Priority) 機制，可以對請求進行排序和分配優先級。  HTTP/2 和 HTTP/1.x 的不同之處     HTTP/2  HTTP/1.x    基於二進制格式  基於文本格式   允許多路徑傳輸  只能串行傳輸   使用首部壓縮  不支持首部壓縮   支持服務端推送  不支持服務端推送   支持優先級  不支持優先級  HTTP/2 的優缺點  優點   加載速度更快：多路徑傳輸和首部壓縮等機制可以減少延遲和帶寬消耗，從而提高加載速度。  效率更高：多路徑傳輸和優先級等機制可以更好地利用網絡資源，從而提高效率。  安全性更高：HTTP/2 強制要求使用加密，從而提高了安全性。  缺點   需要加密：HTTP/2 強制要求使用加密，這增加了網站的成本和複雜度。  需要支援 HTTP/2 的服務器和客戶端：不是所有的服務器和客戶端都支援 HTTP/2，需要更新到支援 HTTP/2 的版本。   Protobuf 3介紹  Protocol Buffers (protobuf)是Google開發的一種輕量級、高效能的資料序列化格式，用於跨平台資料交換和儲存。Protocol Buffers可以在不同的程式語言之間進行資料交換，並且比XML和JSON等常見的資料序列化格式更小、更快、更易於使用和維護。  常見的欄位以及修飾符號  singular  gRPC內部的預設的欄位類型，沒有撰寫其他修飾符號就表示預設使用  singular 為欄位的最小單位。  optional  參數值為可選的，可以把它看作為  null ，通常會生成程式碼後，會有  HasXXX 方法或屬性來判斷此數值是否存在。我們藉由optional關鍵字來簡化傳輸大小。  repeated  宣告一個空的  list  (非  null )，通常生成程式碼後，會根據對應的語言進行產生，例如: Go為  slice ，C#為  list 等等。   protobuf   message Person {\n  string name = 1;\n  repeated string phone_numbers = 2;\n}\n   java   // 創建一個人的物件\nPerson person = Person.newBuilder()\n  .setName(\"John\")\n  .addPhoneNumbers(\"1234567890\")\n  .addPhoneNumbers(\"0987654321\")\n  .build();\n\n// 獲取人的電話號碼列表\nList\u003CString> phoneNumbers = person.getPhoneNumbersList();\n  map  宣告一個空的  map  (非  null )，通常生成程式碼後，會根據對應的語言進行產生，例如: Java為  HashMap ，C#為  Dictionary 等等。   protobuf   message Student {\n  string name = 1;\n  map\u003Cstring, double> grades = 2;\n}\n   java   // 創建一個學生的物件\nStudent student = Student.newBuilder()\n  .setName(\"John\")\n  .putGrades(\"Math\", 90.0)\n  .putGrades(\"Science\", 80.0)\n  .build();\n\n// 獲取學生的成績\nMap\u003CString, Double> grades = student.getGradesMap();\n  enum  與我們一般使用的列舉差異不大，但宣告的enum編號必須是從  0 開始。   protobuf   enum UserRole {\n  ADMIN = 0;\n  EDITOR = 1;\n  VIEWER = 2;\n}\n\nmessage User {\n  string name = 1;\n  repeated UserRole roles = 2;\n}\n   java   // 創建一個 User 物件\nUser user = User.newBuilder()\n    .setName(\"John\")\n    .addRoles(UserRole.EDITOR)\n    .addRoles(UserRole.VIEWER)\n    .build();\n\n// 獲取 User 物件的屬性值\nString name = user.getName();\nList\u003CUserRole> roles = user.getRolesList();\n  oneof  跟  enum 非常相似，但主要用於互斥的屬性，且不能搭配  repeated 關鍵字。   protobuf   message Stock {\n    // Stock-specific data\n}\n\nmessage Currency {\n    // Currency-specific data\n}\n\nmessage ChangeNotification {\n  int32 id = 1;\n  oneof instrument {\n    Stock stock = 2;\n    Currency currency = 3;\n  }\n  oneof actionType {\n    int32 increase = 4;\n    int32 decrease = 5;\n  }\n}\n   java   // 創建ChangeNotification物件，並設置id、股票和增量等資訊\nChangeNotification notification = ChangeNotification.newBuilder()\n        .setId(1)\n        .setStock(Stock.newBuilder().build())\n        .setIncrease(100)\n        .build();\n\n// 創建Currency物件，並設置id、貨幣和減量等資訊\nChangeNotification currencyNotification = ChangeNotification.newBuilder()\n        .setId(2)\n        .setCurrency(Currency.newBuilder().build())\n        .setDecrease(50)\n        .build();\n  Well known types     套件名稱  用途    google.protobuf.Empty  類似於void沒有回傳值，但在ProtoBuf中仍需要撰寫   google.protobuf.Timestamp  類似於DateTime或DateTimeOffset   google.protobuf.Duration  類似於TimeSpan   google.protobuf.Any  類似於object，需要透過  Is 和  Unpack\u003C> 來進行判斷物件型別和轉型  💡 更多形別參考👉  參考  gRPC Code generator  buf  Building a better way to work with Protocol Buffers  install buf     brew   install   bufbuild/buf/buf\n  install go tool     go   install   github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway@latest\n   \n   go   install   github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2@latest\n   \n   go   install   google.golang.org/protobuf/cmd/protoc-gen-go@latest\n   \n   go   install   google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest\n   \n   go   install   github.com/envoyproxy/protoc-gen-validate@latest\n  Getting start     git   clone   https://github.com/bufbuild/buf-tour\n   cd   buf-tour/start/getting-started-with-buf-cli\n  buf使用buf.yaml文件配置，使用此命令創建您自己的文件：     cd   proto\n   buf   mod   init\n  運行此命令後，您會在當前目錄中看到一個buf.yaml包含以下內容的文件：\nbuf.yaml     version  :   v1\n   breaking  :\n     use  :\n       -   FILE\n   lint  :\n     use  :\n       -   DEFAULT\n  buf默認情況下假定當前目錄中有一個buf.yaml，或者使用默認值代替文件buf.yaml 。buf.yaml我們建議始終在文件層次結構的根目錄下放置一個文件.proto，因為這是.proto 解析導入路徑的方式。\n在我們繼續之前，讓我們驗證一切都設置正確，然後我們可以構建我們的模塊。如果沒有錯誤，我們就知道我們已經正確設置了一個 buf 模塊：     //   ~/.../buf-tour/start/getting-started-with-buf-cli/proto\n   buf   build   \n   echo   $?\n  生成代碼  使用以下命令移回目錄getting-started-with-buf-cli     cd   ..\n   touch   buf.gen.yaml\n  更新您的內容buf.gen.yaml以包含 Go 和 Connect-Go 插件：     version  :   v1\n   managed  :\n     enabled  :   true\n     go_package_prefix  :\n       default  :   github.com/bufbuild/buf-tour/gen\n   plugins  :\n     -   plugin  :   buf.build/protocolbuffers/go\n       out  :   gen\n       opt  :   paths=source_relative\n     -   plugin  :   buf.build/bufbuild/connect-go\n       out  :   gen\n       opt  :   paths=source_relative\n     buf   generate   proto\n     getting-started-with-buf-cli\n   ├──   buf.gen.yaml\n   ├──   gen\n   │     ├──   google\n   │     │     └──   type\n   │     │         └──   datetime.pb.go\n   │     └──   pet\n   │         └──   v1\n   │             ├──   pet.pb.go\n   │             └──   petv1connect\n   │                 └──   pet.connect.go\n   └──   proto\n       ├──   buf.yaml\n       ├──   google\n       │     └──   type\n       │         └──   datetime.proto\n       └──   pet\n           └──   v1\n               └──   pet.proto\n  protoc  gRCP 呼叫的四種類型  \n     Unary  類似傳統類型的RESTful API，client發送request而Server回應Response。  Server Streaming  Client發送一次request，而server可以回傳多次資料。  Client Streaming  Client發送多次資料，直到告知server資料傳完後，server在給予Response。  Bi Dirctional Streaming  兩邊都用串流的方式傳送資料。  gRPC工具  grpcurl  grpcui  postman  參考   Google Protocol Buffers  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":238,"path":239,"dir":218,"title":240,"description":240,"keywords":241,"body":246},"content:5.ddia:chapter1.md","/ddia/chapter1","Chapter 01 可靠性、可伸縮性和可維護性",[242,243,244,245],"關於資料系統的思考","可靠性","可伸縮性","可維護性","  資料密集型應用系統設計(Designing Data-Intensive Applications)  第一章：可靠性、可伸縮性和可維護性  現在多數系統都是  資料密集型（data-intensive）  的，而非 計算密集型（compute-intensive）  資料密集型應用通常由標準組件構建而成，標準組件提供了很多通用的功能；例如，許多應用程式都需要：   儲存資料，以便自己或其他應用程式之後能再次找到 （  資料庫，即 databases ）  記住開銷昂貴操作的結果，加快讀取速度（  快取，即 caches ）  允許使用者按關鍵字搜尋資料，或以各種方式對資料進行過濾（  搜尋索引，即 search indexes ）  向其他程序傳送訊息，進行非同步處理（  流處理，即 stream processing ）  定期處理累積的大批次資料（  批處理，即 batch processing ）  關於資料系統的思考  近些年來，出現了許多新的資料儲存工具與資料處理工具。它們針對不同應用場景進行最佳化，因此不再適合生硬地歸入傳統類別【1】。類別之間的界限變得越來越模糊，例如：資料儲存可以被當成訊息佇列用（Redis），訊息佇列則帶有類似資料庫的持久保證（Apache Kafka）。  其次，越來越多的應用程式有著各種嚴格而廣泛的要求，單個工具不足以滿足所有的資料處理和儲存需求。取而代之的是，總體工作被拆分成一系列能被單個工具高效完成的任務，並透過應用程式碼將它們縫合起來。  例如，如果將快取（應用管理的快取層，Memcached 或同類產品）和全文搜尋（全文搜尋伺服器，例如 Elasticsearch 或 Solr）功能從主資料庫剝離出來，那麼使快取 / 索引與主資料庫保持同步通常是應用程式碼的責任。  圖 1-1 給出了這種架構可能的樣子（細節將在後面的章節中詳細介紹）。    可靠性  人們對可靠軟體的典型期望包括：   應用程式表現出使用者所期望的功能。  允許使用者犯錯，允許使用者以出乎意料的方式使用軟體。  在預期的負載和資料量下，效能滿足要求。  系統能防止未經授權的訪問和濫用。  如果所有這些在一起意味著 “正確工作”，那麼可以把可靠性粗略理解為 “即使出現問題，也能繼續正確工作”。   造成錯誤的原因叫做   故障（fault）   **故障（fault）**不同於   失效（failure） -  故障為部分狀態偏離標準，失效則為整個系統掛掉，因此最好設計容錯機制，以防因故障而失效。  我們可以透過故意引發故障來確保容錯機制不斷執行並接受考驗，從而提高故障自然發生時系統能正確處理的信心。範例：Netflix 公司的   Chaos Monkey 【4】  能預料並應對故障的系統特性可稱為 **容錯（fault-tolerant）**或   韌性（resilient）  硬體故障**（hardware faults）**    為了減少系統的故障率，第一反應通常都是增加單個硬體的冗餘度 ，例如：磁碟可以組建 RAID，伺服器可能有雙路電源和熱插拔 CPU，資料中心可能有電池和柴油發電機作為後備電源，某個元件掛掉時冗餘元件可以立刻接管。這種方法雖然不能完全防止由硬體問題導致的系統失效，但它簡單易懂，通常也足以讓機器不間斷執行很多年。  **但是隨著資料量和應用計算需求的增加，越來越多的應用開始大量使用機器，這會相應地增加硬體故障率。**此外，在類似亞馬遜 AWS的一些雲服務平臺上，虛擬機器例項不可用卻沒有任何警告也是很常見的，因為雲平臺的設計就是優先考慮 靈活性（flexibility） 和 彈性（elasticity），而不是單機可靠性。   如果在硬體冗餘的基礎上進一步引入軟體容錯機制，那麼系統在容忍整個（單臺）機器故障的道路上就更進一步了。這樣的系統也有運維上的便利 ，例如：如果需要重啟機器（例如應用作業系統安全補丁），單伺服器系統就需要計劃停機。而允許機器失效的系統則可以一次修復一個節點，無需整個系統停機。  軟體錯誤  是內部的  系統性錯誤（systematic error） ，例子包括：   接受特定的錯誤輸入，便導致所有應用伺服器例項崩潰的 BUG。例如 2012 年 6 月 30 日的閏秒，由於 Linux 核心中的一個錯誤，許多應用同時掛掉了。  失控程序會用盡一些共享資源，包括 CPU 時間、記憶體、磁碟空間或網路頻寬。  系統依賴的服務變慢，沒有響應，或者開始返回錯誤的響應。  級聯故障，一個元件中的小故障觸發另一個元件中的故障，進而觸發更多的故障。  雖然軟體中的系統性故障沒有速效藥，但我們還是有很多小辦法，例如：   仔細考慮系統中的假設和互動  徹底的測試  程序隔離  允許程序崩潰並重啟  測量、監控並分析生產環境中的系統行為  如果系統能夠提供一些保證（例如在一個訊息佇列中，進入與發出的訊息數量相等），那麼系統就可以在執行時不斷自檢，並在出現 **差異（discrepancy）**時警報  人為錯誤  人為錯誤是導致服務中斷的首要原因，但還是有些方法可以增加系統可靠度：   以最小犯錯機會的方式設計系統，讓做對事情更容易，讓做錯事情更困難。  將人們最容易犯錯的地方與可能導致失效的地方   解耦（decouple） 。特別是提供一個功能齊全的非生產環境  沙箱（sandbox） ，使人們可以在不影響真實使用者的情況下，使用真實資料安全地探索和實驗。  在各個層次進行徹底的測試，從單元測試、全系統整合測試到手動測試。自動化測試特別適合用來覆蓋正常情況中少見的  邊緣場景（corner case） 。  允許從人為錯誤中簡單快速地恢復，以最大限度地減少失效情況帶來的影響。 例如，快速回滾配置變更，分批發布新程式碼（以便任何意外錯誤只影響一小部分使用者），並提供資料重算工具（以備舊的計算出錯）。  配置詳細和明確的監控，比如效能指標和錯誤率。 在其他工程學科中這指的是 遙測（telemetry）（一旦火箭離開了地面，遙測技術對於跟蹤發生的事情和理解失敗是至關重要的）。監控可以向我們發出預警訊號，並允許我們檢查是否有任何地方違反了假設和約束。當出現問題時，指標資料對於問題診斷是非常寶貴的。  良好的管理實踐與充分的培訓 —— 一個複雜而重要的方面，但超出了本書的範圍。  可伸縮性  **可伸縮性（Scalability）**是用來描述系統應對負載增長能力的術語。  服務**降級（degradation）**的一個常見原因是負載增加  描述負載  負載可以用一些稱為 **負載引數（load parameters）**的數字來描述。引數的最佳選擇取決於系統架構，它可能是每秒向 Web 伺服器發出的請求、資料庫中的讀寫比率、聊天室中同時活躍的使用者數量、快取命中率或其他東西。除此之外，也許平均情況對你很重要，也許你的瓶頸是少數極端場景。  描述效能  當負載增加時會發生什麼，可以從兩個角度來看   增加負載引數並保持系統資源（CPU、記憶體、網路頻寬等）不變時，系統性能將受到什麼影響？  增加負載引數並希望保持效能不變時，需要增加多少系統資源？  對於 Hadoop 這樣的批處理系統，通常關心的是   吞吐量（throughput） ，即每秒可以處理的記錄數量，或者在特定規模資料集上執行作業的總時間。  對於線上系統，通常更重要的是服務的   響應時間（response time） ，即客戶端傳送請求到接收響應之間的時間。  就算是相同需求，響應時間也會略有不同，因此需要將響應時間視為一個可以測量的數值   分佈（distribution） ，而不是單個數值。  如果想知道**典型（typical）**響應時間，使用中位數會比平均值更好。為了弄清楚異常值有多糟糕，可以看更高的百分位點，例如95%、99%、99.9%。  響應時間的高百分位點（也稱為   尾部延遲 ，即   tail latencies ）非常重要，因為它們直接影響使用者的服務體驗。  這是因為請求響應最慢的客戶往往也是資料最多的客戶，也可以說是最有價值的客戶 —— 因為他們掏錢了  另一方面，最佳化第 99.99 百分位點（一萬個請求中最慢的一個）被認為太昂貴了，不能為亞馬遜的目標帶來足夠好處。減小高百分位點處的響應時間相當困難，因為它很容易受到隨機事件的影響，這超出了控制範圍，而且效益也很小。  百分位點通常用於   服務級別目標（SLO, service level objectives）  和   服務級別協議（SLA, service level agreements） ，即定義服務預期效能和可用性的合約。 SLA 可能會宣告，如果服務響應時間的中位數小於 200 毫秒，且 99.9 百分位點低於 1 秒，則認為服務工作正常（如果響應時間更長，就認為服務不達標）。這些指標為客戶設定了期望值，並允許客戶在 SLA 未達標的情況下要求退款。   排隊延遲（queueing delay）  通常佔了高百分位點處響應時間的很大一部分。由於伺服器只能並行處理少量的事務（如受其 CPU 核數的限制），所以只要有少量緩慢的請求就能阻礙後續請求的處理，這種效應有時被稱為   頭部阻塞（head-of-line blocking）  。  應對負載的方法    縱向伸縮 （scaling up，也稱為垂直伸縮，即 vertical scaling，轉向更強大的機器）   橫向伸縮 （scaling out，也稱為水平伸縮，即 horizontal scaling，將負載分佈到多臺小機器上）  跨多臺機器分配負載也稱為 “  無共享（shared-nothing） ” 架構。可以在單臺機器上執行的系統通常更簡單，但高階機器可能非常貴，所以非常密集的負載通常無法避免地需要橫向伸縮。現實世界中的優秀架構需要將這兩種方法務實地結合，因為使用幾臺足夠強大的機器可能比使用大量的小型虛擬機器更簡單也更便宜。   有些系統是   彈性（elastic）  的，這意味著可以在 檢測到負載增加時自動增加計算資源  而其他系統則是手動伸縮（人工分析容量並決定向系統新增更多的機器）  如果負載   極難預測（highly unpredictable） ，則彈性系統可能很有用，但手動伸縮系統更簡單，並且意外操作可能會更少（請參閱 “  分割槽再平衡 ”）。  跨多臺機器部署   無狀態服務（stateless services）  非常簡單，但  將帶狀態的資料系統從單節點變為分散式配置則可能引入許多額外複雜度 。出於這個原因，常識告訴我們應該將資料庫放在單個節點上（縱向伸縮），直到伸縮成本或可用性需求迫使其改為分散式。  一個良好適配應用的可伸縮架構，是圍繞著   假設（assumption）  建立的：哪些操作是常見的？哪些操作是罕見的？這就是所謂負載引數。如果假設最終是錯誤的，那麼為伸縮所做的工程投入就白費了，最糟糕的是適得其反。在早期創業公司或非正式產品中，通常支援產品快速迭代的能力，要比可伸縮至未來的假想負載要重要的多。  可維護性  避免自己的系統變成  遺留（legacy）  系統的三個設計原則：  一、可操作性（Operability）  便於運維團隊保持系統平穩執行。   一個優秀運維團隊的典型職責如下（或者更多）：   監控系統的執行狀況，並在服務狀態不佳時快速恢復服務。  跟蹤問題的原因，例如系統故障或效能下降。  及時更新軟體和平臺，比如安全補丁。  瞭解系統間的相互作用，以便在異常變更造成損失前進行規避。  預測未來的問題，並在問題出現之前加以解決（例如，容量規劃）。  建立部署、配置、管理方面的良好實踐，編寫相應工具。  執行複雜的維護任務，例如將應用程式從一個平臺遷移到另一個平臺。  當配置變更時，維持系統的安全性。  定義工作流程，使運維操作可預測，並保持生產環境穩定。  鐵打的營盤流水的兵，維持組織對系統的瞭解。   資料系統可以透過各種方式使日常任務更輕鬆：   透過良好的監控，提供對系統內部狀態和執行時行為的   可見性（visibility） 。  為自動化提供良好支援，將系統與標準化工具相整合。  避免依賴單臺機器（在整個系統繼續不間斷執行的情況下允許機器停機維護）。  提供良好的文件和易於理解的操作模型（“如果做 X，會發生 Y”）。  提供良好的預設行為，但需要時也允許管理員自由覆蓋預設值。  有條件時進行自我修復，但需要時也允許管理員手動控制系統狀態。  行為可預測，最大限度減少意外。  二、簡單性（Simplicity）  從系統中消除儘可能多的   複雜度（complexity） ，使新工程師也能輕鬆理解系統（注意這和使用者介面的簡單性不一樣）。  一個陷入複雜泥潭的軟體專案有時被描述為   爛泥潭（a big ball of mud）  **複雜度（complexity）**有各種可能的症狀，例如：狀態空間激增、模組間緊密耦合、糾結的依賴關係、不一致的命名和術語、解決效能問題的 Hack、需要繞開的特例等等。  簡化系統並不一定意味著減少功能；它也可以意味著消除   額外的（accidental）  的複雜度。 Moseley 和 Marks把   額外複雜度  定義為：由具體實現中湧現，而非（從使用者視角看，系統所解決的）問題本身固有的複雜度。消除  額外複雜度  的最好工具之一是   抽象（abstraction）  三、可演化性（evolvability）  使工程師在未來能輕鬆地對系統進行更改，當需求變化時為新應用場景做適配。也稱為   可擴充套件性（extensibility） 、**可修改性（modifiability）**或   可塑性（plasticity） 。   敏捷（agile）  工作模式為適應變化提供了一個框架。敏捷社群還開發了對在頻繁變化的環境中開發軟體很有幫助的技術工具和模式，如 **測試驅動開發（TDD, test-driven development）**和   重構（refactoring） 。  修改資料系統並使其適應不斷變化需求的容易程度，是與   簡單性  和   抽象性  密切相關的：簡單易懂的系統通常比複雜系統更容易修改。但由於這是一個非常重要的概念，我們將用一個不同的詞來指代資料系統層面的敏捷性：   可演化性（evolvability）",{"id":248,"path":249,"dir":218,"title":250,"description":250,"keywords":251,"body":257},"content:5.ddia:chapter3.md","/ddia/chapter3","Chapter 03 數據儲存與檢索",[252,253,254,255,256],"引言","驅動資料庫的資料結構","B樹","事務處理還是分析？","本章小結","  Designing Data-Intensive Applications Ch3   ddia/ch3.md at master · Vonng/ddia  引言  數據庫最基本兩件事：   儲存數據  檢索數據  本章會討論   資料庫如何儲存資料  如何找到資料  儲存引擎依據負載進最佳化，分成兩種   事務型負載最佳化  Online Transaction Processing (OLTP) 儲存引擎，用於高併發的交易性應用，需要支援併發的讀取或寫入操作。  分析性負載最佳化  Online Analytical Processing (OLAP) 儲存引擎，用於針對大數據集進行分析查詢，支援複雜的聚集計算和多維分析。  兩大類資料庫引擎   page-oriented  頁面導向資料庫被用於儲存表格，其中每個表格被分為好幾個磁碟頁面。磁碟頁面是資料庫系統與磁碟交互的最小單位，通常大小為 4KB 或 8KB。  log-structured  日誌導向資料庫最初是由 Google 發明，用於處理 Web 搜索的索引數據。這種資料庫引擎將所有修改操作寫入一個追蹤寫入（write-ahead log, WAL）中，然後將實際數據讀取到記憶體中，並在記憶體中進行修改。當修改完成時，這些修改操作會被追加到 WAL 中，然後再以某種方式寫入磁碟。這種方式允許寫入操作非常快速，並且可以維護良好的寫入吞吐量，從而使其成為許多大型分佈式數據庫的理想選擇。  驅動資料庫的資料結構  最簡單的資料庫     #!/bin/bash\n   db_set   () {\n     echo   \"  $1  ,  $2  \"   >>   database\n   }\n   \n   db_get   () {\n     grep   \"^  $1  ,\"   database   |   sed   -e   \"s/^  $1  ,//\"   |   tail   -n   1\n   }\n  這個簡單的程式實現鍵值儲存和讀取，每次set 時會在檔案尾巴追加記錄，讀取時會從最後一行往上找直到找到key   $ db_set 123456 '{\"name\":\"London\",\"attractions\":[\"Big Ben\",\"London Eye\"]}'\n\n$ db_set 42 '{\"name\":\"San Francisco\",\"attractions\":[\"Golden Gate Bridge\"]}'\n\n$ db_get 42\n{\"name\":\"San Francisco\",\"attractions\":[\"Golden Gate Bridge\"]}\n  db_set 有非常好的效能，因為在檔尾追加寫入是非常高效的，許多資料庫的內部使用了log structed，也是用  僅追加(append-only)  db_get 的效能則很糟, O(n)，為了改善這個問題，我們需要一個數據結構 Index  Index 是一個「額外」的資料，能改變查詢的效能，但是在寫入時會增加開銷，所以寫入效能很難超過單純的追加寫入檔案  權衡選什麼索引就是DBA的專業  Hash Index  為了簡化，書中假設要儲存的資料是 key-value Data  假如資料要存進檔案，那 Index 最簡單的作法就是 存下每筆資料在檔案的 Offset    查詢資料時，只要從index取得 offset，再去檔案尋找(seek)即可。  感覺很簡單，實際上 Bitcask 就是這麼做的。  這種結構特別適合在很多寫操作的場景，像是貓咪影片的點擊次數  如果檔案太大的話，就開新的檔案，然後有時間再把舊的檔案壓縮    健值更新日誌 (統計貓咪影片的播放次數)  檔案很多的話，可以合併     同時執行壓縮和分段合併  為每個檔案儲存自己的 hash index  其它實現細節：   檔案格式  書中提到，在儲存數據時使用二進制格式會比使用文本格式更快，因為文本格式需要進行解析和序列化，而二進制格式可以直接使用。這是許多資料庫的優化技巧之一。  刪除記錄  當資料被刪除時，為了避免 hash index 中的資料不一致，可以先標記它們為被刪除的狀態，稱為墓碑（tombstone）。當 hash index 查找到被標記為墓碑的資料時，就知道這個資料已經被刪除，並且不會再被回傳。  崩潰恢復  如果資料庫重新啟動，因為記憶體中的雜湊對映表丟失，所以必須重新構建。這可以通過在啟動時重新讀取每個數據檔案並重建對映表來實現。Bitcask 會把 index cache 起來  部分寫入記錄  資料庫隨時可能崩潰，包括在將記錄追加到日誌的過程中。 Bitcask 檔案包含校驗和，允許檢測和忽略日誌中的這些損壞部分。  併發控制  由於寫操作是以嚴格的順序追加到日誌中的，所以常見的實現是隻有一個寫入執行緒。也因為資料檔案段是僅追加的或者說是不可變的，所以它們可以被多個執行緒同時讀取。  僅追加日誌似乎很浪費：為什麼不直接在檔案裡更新，原因如下   順序寫入比隨機讀取更快，因為它允許操作系統以更高效的方式編組寫入操作。  併發和崩潰恢復容易。  合併舊段資料可以防止碎片化問題  hash index 也有其侷限性：   memory 放不下 index 時，hash index 在 disk 上表現很糟  範圍查詢效率不高，無法輕鬆掃描 kitty00000 ~ kitty99999  SSTables and LSM tree  在之前的 hash index 結構，寫入檔案的 key 值順序，是照寫入時間先後的  SSTable(Sorted String Table) 則是要求寫入的順序照 key 的順序  用SSTable 的好處是   合併檔案可以更高效，同時讀取多個檔案合併  可以不用存下所有的 key offset 對應，因為 key 是排序的，只要先找到大概的位置，再掃描檔案即可  index 的空間節省，IO也節省     具有記憶體索引的 SSTable   構建和維護SSTables  如何讓資料能夠預先排好序呢？畢竟我們接收到的寫入請求是沒有順序的。  雖然在硬碟上維護有序結構也是可能的，但在記憶體內則容易多  方便排序的資料結構   紅黑樹  AVL 樹  我們可以讓我們的儲存引擎以如下方式工作：   有新寫入時，將其新增到記憶體中的平衡樹資料結構。  當   記憶體表  大於某個閾值（通常為幾兆位元組）時，將其作為 SSTable 檔案寫入硬碟。當該 SSTable 被寫入硬碟時，新的寫入可以在一個新的記憶體表例項上繼續進行。  收到讀取請求時，首先嘗試在記憶體表中找到對應的鍵，如果沒有就在最近的硬碟段中尋找，如果還沒有就在下一個較舊的段中繼續尋找，以此類推。  時不時地，在後臺執行一個合併和壓縮過程，以合併段檔案並將已覆蓋或已刪除的值丟棄掉。  只剩一個問題，資料庫崩潰，則最近的寫入（在記憶體表中，但尚未寫入硬碟）將丟失。  解法：硬碟上儲存一個單獨的日誌檔，在寫入記憶體錢先寫入日誌檔，用於崩潰後回復記憶體   用SSTables製作LSM樹  LSM-Tree（Log Structured-Merge Tree）是一種非常流行的樹型資料結構，用於實現許多現代資料庫系統。LSM-Tree 將數據分為多個層，每層使用不同的資料結構（如 SSTable）來進行儲存和檢索。當資料寫入時，它會先被寫入具有較快寫入速度的記憶體中，然後當記憶體中的資料達到一定閾值時，會將其寫入下一層。這樣可以避免過多的硬碟寫入，同時也可以提高查詢效率。      LSM Read 實作方式  在 LSM-Tree 中，當我們需要查詢資料時，會首先在記憶體中查找，如果找不到，就繼續在下一層的 SSTable 中查找，直到找到該筆資料或者所有的 SSTable 都被查詢過為止。此外，LSM-Tree 通常還會使用 Bloom Filters 來進一步加速查詢。  Bloom Filters 是一種資料結構，常用於判斷某個元素是否存在於一個集合中。它是由 Burton Bloom 於 1970 年提出的。  相較於傳統的B-Tree，LSM-Tree的優點在於：   寫入效率高，因為數據先被寫入記憶體中，而不是直接寫入磁碟中，當記憶體中的數據達到一定閾值時，再進行一次性的寫入操作。  可以進行批量寫入和刪除操作，因為數據被分為多個層，可以使用批量寫入和刪除操作來進行優化。  可以進行崩潰恢復，因為數據被分為多個層，可以在數據崩潰時進行恢復操作。  LSM-Tree 的缺點包括：   查詢效率不穩定，因為數據被分為多個層，所以查詢效率可能會隨著層數的增加而下降，尤其是在 SSTable 中有很多墓碑（tombstone）時。  LSM-Tree 的儲存格式比較複雜，需要將數據分為多個層，每層使用不同的資料結構進行儲存，這導致它比較難以實現。  在寫入時，需要先將數據寫入記憶體中，然後再進行一次性的寫入操作。這樣會導致寫入操作的延遲性較高。  總體而言，LSM-Tree 是一種非常有效的數據儲存和檢索方式，但它也有一些缺點，需要在實際使用中加以注意。  效能最佳化  當查詢不存在的鍵時，需要檢查記憶體表和從最近到最早的所有段檔案，那樣很慢。  解決方法：   使用布隆過濾器(Bloom Filters)來最佳化查詢不存在的鍵時的訪問  考慮使用 size-tiered 和 leveled compaction 來確定 SSTables 被壓縮和合並的順序和時間  LSM 樹的基本思想是將一系列在後臺合併的 SSTables 儲存起來，即使資料集比可用記憶體大得多，它仍能繼續正常工作。資料按排序順序儲存，可高效地執行範圍查詢，並且因為硬碟寫入是連續的，所以 LSM 樹可以支援非常高的寫入吞吐量。  Bloom Filter（布隆過濾器）是用來檢驗一個元素是否存在於特定集合中的概念。它在空間複雜度方面比 hash table 更優秀，但使用它時需要注意偽陽性(false positive)的問題  false positive：沒有就是沒有，有代表有可能有  B樹  日誌結構索引已經很常見，但它們不是最常用的索引。B 樹是一種最常見的索引結構，從 1970 年被引入以來，僅不到 10 年就變得“無處不在”，被廣泛使用在關係資料庫和非關係資料庫中。  像 SSTables 一樣，B 樹保持按鍵排序的鍵值對，這允許高效的鍵值查詢和範圍查詢。  B 樹將資料庫分解成固定大小的塊或分頁，通常大小為 4KB，並且一次只能讀取或寫入一個頁面。每個頁面都可以使用地址或位置來標識，這允許一個頁面引用另一個頁面，類似於指標，只是是在硬碟而不是在記憶體中。我們可以使用這些頁面引用來構建一個頁面樹，如圖 3-6 所示。     使用 B 樹索引查詢一個鍵   B樹由根頁面、子頁面和葉子頁面組成  子頁面負責連續鍵範圍，根頁面上的鍵表示相鄰子頁面管理的鍵的邊界  查找鍵值時，從根頁面開始，按範圍查找子頁面，直到葉子頁面  分支因子是每個頁面中對子頁面引用的數量，範例上是6個，通常是幾百     更新 B 樹中的鍵值，需搜尋包含該鍵的葉子頁面，更改值，再將該頁面寫回硬碟（引用仍有效）。  新增鍵需找到可包含它的頁面，如空間不足，則分成兩半滿頁面，並更新父頁面。  演算法確保樹平衡，n 個鍵的 B 樹深度為 O(log n)。多數資料庫可用三到四層樹，分支因子為 500 的 4KB 頁面的四層樹，可儲存 256TB 資料。  讓B樹更可靠   B 樹的基本寫入操作，  如何覆寫硬碟上的頁面以及如何處理拆分頁面等情況。  討論了預寫式日誌（WAL）檔案以及併發控制的問題。  日誌結構化的方法相對於 B 樹的優勢。  B 樹的基本寫入操作是用新資料覆寫硬碟上的頁面，而不會改變頁面的位置。這表示當頁面被覆寫時，對該頁面的所有引用不會改變。這與日誌結構索引（如 LSM 樹）形成鮮明對比，後者只是追加到檔案，從不修改檔案中已有的內容。  覆寫硬碟上的頁面就像對實際硬體進行操作。在磁性硬碟驅動器上，這意味著將磁頭移動到正確的位置，等待旋轉盤上的正確位置出現，然後用新的資料覆寫適當的扇區。固態硬碟上，由於 SSD 必須一次擦除和重寫相當大的儲存晶片塊，因此會發生更複雜的事情。  有時候，需要覆寫多個不同的頁面。例如，因為插入導致頁面過滿而拆分頁面，則需要寫入新拆分的兩個頁面，並覆寫其父頁面以更新對兩個子頁面的引用。這是一個危險的操作，因為如果資料庫在系列操作進行到一半時崩潰，那麼最終將導致一個損壞的索引。  B 樹實現中通常會有預寫式日誌（WAL，即 write-ahead log，也稱為重做日誌）檔案，以處理異常崩潰的情況。每次對 B 樹的修改都必須先寫入該檔案，然後才能應用到樹本身的頁面。當資料庫在崩潰後恢復時，這個日誌將被用來使 B 樹恢復到一致的狀態。  當多個執行緒要同時訪問 B 樹時，還需要仔細的併發控制，否則執行緒可能會看到樹處於不一致的狀態。通常是透過使用鎖存器（latches，輕量級鎖）保護樹的資料結構來完成。日誌結構化的方法在這方面更簡單，因為它們在後臺進行所有的合併，不干擾新接收到的查詢，並且能夠時不時地將段檔案切換為新的（該切換是原子操作）。  B樹的最佳化  B樹存在已久，多年來已開發出許多優化設計，包括：   使用寫時複製方案，例如LMDB，而非覆寫頁面並維護WAL以支援崩潰恢復。經修改的頁面被寫入不同位置，並在樹中建立父頁面的新版本以指向新位置。這種方法對於併發控制也很有用。  縮短鍵的大小，而非儲存整個鍵，以節省頁面空間。在樹內部的頁面上，鍵只需提供足夠的資訊來充當鍵範圍之間的邊界。在頁面中包含更多的鍵允許樹具有更高的分支因子，因此也就允許更少的層級。  不要求相鄰鍵範圍的頁面也放在硬碟上相鄰的區域，但這樣隨機存取的速度很慢。因此，許多B樹的實現在佈局樹時會盡量使葉子頁面按順序出現在硬碟上，但隨著樹的增長，要維持這個順序是很困難的。  新增指標到樹中，例如每個葉子頁面引用其左右兄弟頁面，使得不用跳回父頁面即可按順序掃描鍵。  B樹的變體如分形樹借用了一些日誌結構的思想來減少硬碟查詢。  比較B樹和LSM樹   通常，LSM樹的寫入速度較快，B樹的讀取速度較快。  LSM樹具有較高的寫入吞吐量，較低的寫放大和碎片，對固態硬碟較為友好。  LSM樹可能在壓縮過程中干擾讀寫操作，且在高寫入吞吐量下壓縮性能受限  B樹為許多工作負載提供了始終如一的良好效能，並適用於事務隔離等應用。  B樹和LSM樹的比較中，B樹實現通常較為成熟，但LSM樹在效能特徵方面也很有吸引力。經驗表明，LSM樹的寫入速度通常更快，而B樹的讀取速度更快。LSM樹上的讀取相對較慢，因為需要檢查多個資料結構和SSTables的不同壓縮層級。  然而，基準測試結果通常取決於工作負載細節，所以需要針對特定工作負載進行測試以進行有效比較。在評估儲存引擎效能時，需要考慮幾個因素。  LSM樹具有更高寫入吞吐量、較低的寫入放大和碎片化，並且可以將資料壓縮得更好，因此在硬碟上產生的檔案較小。不過，壓縮過程可能干擾到正在進行的讀寫操作，導致性能波動和較高的響應時間。在高寫入吞吐量下，壓縮性能可能受限，導致硬碟上未合併段的數量不斷增加，從而影響讀取速度。  B樹的優勢在於每個鍵在索引中只存在一個位置，並且通常具有較快的讀取速度。此外，B樹在需要強大事務語義的資料庫中非常適用，因為可以直接在B樹索引中的鍵範圍上應用鎖。然而，B樹可能具有更高的寫入放大和碎片化，導致磁碟空間使用增加和寫入吞吐量降低。  B樹在資料庫架構中具有深厚基礎，而LSM樹在新型資料庫中越來越受歡迎。要確定哪種儲存引擎最適合特定使用場景，需要根據實際工作負載進行測試。  其他索引結構  名詞解釋   主鍵索引：在關聯式資料庫、文件資料庫或圖形資料庫中，主鍵唯一識別一行、一個文檔或一個頂點。其他紀錄可以通過主鍵（或ID）引用該行/文檔/頂點，索引用於解析這些引用。  次級索引：允許在資料庫表格上建立額外的索引，以提高查詢性能。次要索引可以從鍵值索引構建，主要區別在於鍵不是唯一的。這可以通過使索引中的每個值成為匹配行標識符的列表或通過將行標識符附加到鍵上使其唯一來解決。  heap file：存儲行數據的無特定順序的文件。堆文件避免了多個次要索引存在時的數據重複問題：每個索引僅引用堆文件中的位置，實際數據存儲在一個地方。  Clustered 索引：將索引行直接存儲在索引中的一種方法，可以提高查詢性能。例如，MySQL的InnoDB存儲引擎中，表的主鍵始終是聚簇索引，次要索引引用主鍵（而不是堆文件位置）。  包含列的索引：Clustered and non clustered index 的過渡，只保存部份需要用到的資料  多列索引：同時查詢多個表列或文檔字段的索引。這對於需要根據多個條件查找數據的情況非常有用。  串接索引：將多個字段組合成一個鍵的多列索引。串接索引的鍵是按照指定的順序將字段附加在一起的。它可以用來查找具有特定條件的所有數據，但如果只查詢其中一個字段，它可能無法提供幫助。  多維索引：用於查詢多個列的一般方法，特別適用於地理空間數據。  R樹：專門用於地理空間數據的空間索引。  全文搜索：用於模糊查詢的技術，支持對詞彙、語法變化和近義詞等進行搜索。  目前，我們只討論了鍵值索引，它們就像關係模型中的   主鍵索引 。  次級索引（secondary indexes）也很常見。在關係資料庫中，你可以使用   CREATE INDEX  命令在同一個表上建立多個次級索引。  儲存Index 中的值  索引的鍵是查詢欄位，而值可以是行本身或是儲存在別處行的參照。後者儲存在 heap file 中  heap file 資料沒有特定順序，這種方法常見，因為可以避免在有多個次級 index 時複製資料。  Clustered Index 將整個資料列的所有資料存入索引中，查詢可直接在索引樹上完成，速度較快，但只能建立在唯一的鍵上。相反地，非聚集式 index 將索引資料存入索引樹中，而將資料列放置在另一個文件中，因此查詢需要先在索引樹上完成，再到文件中查詢資料列。  cover index 介於 clustered index and non clustered index 之間，包含查詢所需的所有欄位，可不必查詢表格本身即可回答查詢，因此可大幅提高查詢性能。  多列 index  又叫複合 index，對查詢有多種條件時，能加速，要注意 key 的順序是重要的，和下 where 欄位的順序一致的話，查詢是最快的。  多維 index  用於加速多維資料的查詢，例如帶有時間和地點兩個維度的天氣資料。它通常使用 R 樹資料結構來實現，具有高效的範圍查詢和空間查詢功能。在設計多維 index 時，必須仔細選擇索引的維度，以便在查詢時獲得最佳效能。  B 樹或 LSM 樹索引無法高效處理這種查詢：它可以返回一個經度範圍內的所有餐廳（但緯度可能是任意值），或者返回在同一緯度範圍內的所有餐廳（但經度可能是任意值），但不能同時滿足兩個條件。  全文搜尋和模糊索引  到目前為止所討論的所有索引都假定你有確切的資料，並允許你查詢鍵的確切值或具有排序順序的鍵的值範圍。他們不允許你做的是搜尋  類似 的鍵，如拼寫錯誤的單詞。這種模糊的查詢需要不同的技術，如全文搜尋引擎等。全文搜尋引擎允許用戶搜索相似的鍵，而不僅僅是確切的鍵值。  模糊索引（fuzzy indexes）類似於全文搜尋，但允許在查詢過程中包含近似匹配，以處理拼寫錯誤、拼音相似性等問題。為實現模糊索引，可以使用像Levenshtein距離、Damerau-Levenshtein距離和Jaro-Winkler距離等編輯距離度量，或使用如三元組或四元組的n-gram方法來度量相似性。   在記憶體中儲存一切  記憶體資料庫在效能、資料模型和擴展性方面具有優勢：   效能：記憶體資料庫通過直接從記憶體讀取和寫入資料，可以提供更高的讀寫速度，從而提高整體效能。這比傳統的基於硬碟的資料庫更快，因為後者需要在硬碟上查找和操作資料，這會消耗更多的時間。  資料模型：記憶體資料庫可以較容易地支援多種資料結構（如優先順序佇列和集合），從而提供更好的應用支援。這使得開發人員可以更靈活地設計和實現資料模型，以滿足不同的應用需求。  擴展性：記憶體資料庫可以通過反快取方法在記憶體不足的情況下將最近最少使用的資料從記憶體轉移到硬碟，並在需要時重新將其載入到記憶體中。這使得記憶體資料庫能夠支援比可用記憶體更大的資料集，同時保持高效能。  隨著 RAM 成本的降低，將資料集完全儲存在記憶體中變得更加可行。此外，非易失性儲存器（NVM）技術的發展有望為未來的資料存儲帶來重大變革，因為它們結合了記憶體和硬碟的特點，並可以在不同的應用場景中提供更好的性能。  總之，記憶體資料庫在資料庫領域具有顯著優勢，特別是在處理較小資料集時。隨著 RAM 成本降低和非易失性儲存器技術的發展，記憶體資料庫將在資料庫領域發揮越來越重要的作用。   事務處理還是分析？  早期資料庫寫入對應商業交易。後來資料庫應用於非金錢相關領域，仍使用\"事務\"一詞。事務處理允許客戶端低延遲讀寫，稱為線上事務處理（OLTP）。  資料庫越來越多地用於資料分析，這些分析查詢被稱為線上分析處理（OLAP）。OLTP主要是查詢少量記錄，終端使用者操作。OLAP則主要在大批次記錄上聚合，供內部資料分析師使用。  起初，事務處理和分析查詢使用相同資料庫，但企業趨勢是在單獨的資料倉庫上執行分析。   表 3-1 比較事務處理和分析系統的特點     屬性  事務處理系統 OLTP  分析系統 OLAP    主要讀取模式  查詢少量記錄，按鍵讀取  在大批次記錄上聚合   主要寫入模式  隨機訪問，寫入要求低延時  批次匯入（ETL）或者事件流   主要使用者  終端使用者，透過 Web 應用  內部資料分析師，用於決策支援   處理的資料  資料的最新狀態（當前時間點）  隨時間推移的歷史事件   資料集尺寸  GB ~ TB  TB ~ PB  資料倉庫  資料倉庫是一個獨立的資料庫，用於儲存企業內所有OLTP（線上事務處理）系統中的只讀資料副本。企業可能擁有多個交易處理系統，如終端客戶網站、實體商店收銀系統、倉庫庫存追踪等。這些OLTP系統對業務運作至關重要，要求高可用和低延遲，所以一般不允許業務分析人員直接在這些資料庫上執行分析查詢。  資料倉庫允許分析人員查詢資料，而不影響OLTP操作。資料倉庫從OLTP資料庫中提取資料，轉換為適合分析的格式，然後載入資料倉庫。這個過程稱為抽取-轉換-載入（ETL）。     圖 3-8 ETL 至資料倉庫的簡化提綱  資料倉庫可針對分析類的訪問模式進行最佳化。雖然資料倉庫和關係型OLTP資料庫都有SQL查詢介面，但它們針對非常不同的查詢模式進行最佳化。許多資料庫供應商專注於支援事務處理負載或分析工作負載，而不是兩者兼顧。  一些資料庫（如Microsoft SQL Server和SAP HANA）在同一產品中支援事務處理和資料倉庫。還有一些資料倉庫供應商，如Teradata、Vertica等，它們的產品通常使用昂貴的商業許可證銷售。開源SQL-on-Hadoop專案正與商業資料倉庫系統競爭，例如Apache Hive、Spark SQL、Cloudera Impala等。   星型和雪花型：分析的模式  星型和雪花型模式是分析型資料庫中常見的資料模型。在星型模式中，資料庫中心是一個事實表，它記錄了特定事件（例如客戶購買的產品）。事實表的每一行都包含一個事件，並通過外部鍵引用其他表（稱為維度表）。這些維度表包含了事件發生的物件、內容、地點、時間、方式和原因等資訊。星型模式之所以被稱為星型，是因為當我們將表之間的關係視覺化時，事實表位於中心，被維度表包圍，連線就像星星的光芒。     圖 3-9 用於資料倉庫的星型模式的示例  雪花模式是星型模式的一個變體，其中維度被進一步分解成子維度。這意味著維度表可以再引用其他表，將資料進一步細分。雖然雪花模式比星型模式更規範化，但分析師通常更喜歡使用星型模式，因為它更簡單。   列式儲存  列式存儲是一種在資料庫中儲存資料的方式，它將表中的每一列資料存儲在一起，而不是將同一行的所有值相鄰存儲。這與常見的行式存儲方式不同，行式存儲方式會將表中同一行的所有值相鄰存儲。  在資料倉庫和大規模分析查詢中，列式存儲具有明顯優勢。當查詢只涉及表中少數幾列時，列式存儲可以有效地減少IO操作，提高查詢性能。這是因為查詢引擎只需要讀取和解析查詢中涉及的列，而不是整行數據。這在大型事實表（可能包含數百列）的資料倉庫查詢中特別有用。     圖 3-10 按列儲存關係型資料，而不是行   列壓縮  透過壓縮資料，降低對硬碟吞吐量的需求。列式儲存通常適合壓縮，因為在列式儲存中，每一列的值序列通常具有重複性，這有利於壓縮。根據列中的資料，可以使用不同的壓縮技術。  點陣圖編碼：在資料倉庫中特別有效的壓縮技術。點陣圖編碼將具有 n 個不同值的列轉換為 n 個獨立的點陣圖，每個不同值對應一個位圖，每行對應一個位元位。如果該行具有該值，則該位為 1，否則為 0。     圖 3-11 壓縮的點陣圖索引儲存佈局  對於稀疏的點陣圖（其中包含許多零），可以使用遊程編碼（一種無損資料壓縮技術）進一步壓縮。這可以使列的編碼非常緊湊。  記憶體頻寬和向量化處理  資料倉庫查詢中，兩個主要性能瓶頸為   硬碟到記憶體頻寬  記憶體到CPU的頻寬  解決方法：   列式儲存佈局可以降低從硬碟載入的資料量，從而提高效率。  查詢引擎可以將壓縮後的列資料放入CPU的L1快取，然後在緊密的迴圈中遍歷。這樣的迴圈相對於包含大量函式呼叫和條件判斷的程式碼執行速度更快。  列壓縮允許更多的行同時放入有限的L1快取。  向量化處理是一種可以直接在壓縮列資料塊上操作的技術。例如，按位 \"與\" 和 \"或\" 運算子可以被設計成在壓縮列資料塊上執行。   列式儲存中的排序順序  列式儲存中資料排序順序的概念和其對查詢效率的影響。   在列式儲存中，資料的行順序不是非常重要。可以按插入順序儲存，但也可以根據某種排序順序排列資料以作為索引機制。  對每一列分別進行排序是沒有意義的，因為這樣就無法重建出完整的行。所以需要對整行資料進行統一操作，即使實際儲存方式是按列的。  資料庫管理員可以根據常用查詢的需求來選擇用於排序的列。例如，如果查詢通常涉及日期範圍，則可以使用日期作為第一個排序鍵，這樣查詢引擎只需掃描特定日期範圍的行，而不需要掃描所有行。  對資料進行排序還有助於壓縮列。如果主要排序列的值重複程度較高，則排序後可以用簡單的運行長度編碼來進行壓縮。  C-Store 和 Vertica 等資料庫系統中的一個擴充套件是，既然不同查詢受益於不同的排序順序，為什麼不以多種不同方式儲存相同資料？這樣可以在處理查詢時，選擇最適合查詢模式的排序版本。  總之，列式儲存中的排序順序對於查詢效率和資料壓縮具有重要影響。不同的排序順序可以優化查詢性能並提高資料壓縮率。   寫入列式儲存  在資料倉庫中，列式儲存、壓縮和排序對於大型只讀查詢有幫助。但是，寫入列式儲存比較困難。由於行由列中的位置標識，插入新行可能需要重寫所有列檔案。  一個解決方案是使用LSM樹。寫操作先進入記憶體中的儲存，被加入已排序結構，然後批次寫入硬碟上的列檔案。查詢操作需要檢查硬碟上的列資料和記憶體中的最近寫入，將兩者合併。查詢最佳化器會隱藏這些細節，使得修改後的資料能立即反映在查詢中。   聚合：資料立方體和物化檢視  為了提高資料倉庫的查詢性能，可以利用資料立方體和物化檢視進行數據聚合。這兩種技術具有不同的特點和用途：   物化檢視：\n   將查詢結果的實際副本儲存起來，加速常用聚合函式，如 COUNT、SUM、AVG 等。  與虛擬檢視不同，虛擬檢視只是查詢的捷徑，不儲存任何實際數據。  需要在底層數據變化時進行更新，這會增加寫入成本，在 OLTP 資料庫中不太常用。  資料立方體：\n   物化檢視的一個特例，按照不同維度分組的聚合網格，也被稱為 OLAP 立方。  允許根據不同維度對數據進行彙總，例如根據日期和產品對銷售額進行彙總。  當事實具有多個維度時，可以擴展到多維超立方體，例如日期、產品、商店、促銷和客戶等五個維度。  優點：讓某些查詢變得非常快，因為這些查詢已經被有效地預先計算了。  缺點：缺乏查詢原始數據的靈活性，因為價格等某些範圍條件不是立方體的維度。  資料倉庫通常會保留儘可能多的原始數據，並將聚合數據（如資料立方體）僅作為某些查詢的效能提升手段。     本章小結  在本章中，我們詳細討論了資料庫如何處理資料的儲存和檢索。資料儲存在資料庫後，查詢時資料庫會進行檢索。我們了解了針對事務處理（OLTP）和線上分析（OLAP）兩種不同使用場景的儲存引擎，以及他們之間的區別。   OLTP系統：\na. 面向終端使用者，處理大量請求。\nb. 每個查詢通常只訪問少量記錄，使用索引進行查詢。\nc. 硬碟查詢時間是瓶頸。  OLAP系統：\na. 面向業務分析人員，查詢量較少。\nb. 每個查詢開銷高，需要短時間內掃描大量記錄。\nc. 硬碟頻寬是瓶頸，列式儲存有助於提高效能。  兩派主流的儲存引擎：\na. 日誌結構學派：例如Bitcask、SSTables、LSM樹、LevelDB、Cassandra、HBase、Lucene等。這些技術通過將隨機訪問寫入轉換為硬碟上的順序寫入，提高寫入吞吐量。\nb. 就地更新學派：例如B樹，用於關係資料庫和非關係型資料庫。將硬碟視為一組可覆寫的固定大小的頁面。  複雜的索引結構與記憶體內資料庫：介紹了一些更複雜的索引結構，以及針對所有資料都放在記憶體裡而最佳化的資料庫。  資料倉庫的高階架構：\na. 當查詢需要在大量行中順序掃描時，索引的重要性降低。\nb. 非常緊湊地編碼資料變得非常重要，以減少查詢需要從硬碟讀取的資料量。\nc. 列式儲存有助於實現這一目標，提高查詢效能。  作為一名應用程式開發人員，了解儲存引擎內部的知識將有助於您更好地了解哪種工具最適合特定應用程式。在調整資料庫最佳化引數時，這種理解讓您能夠預測增減某個值所產生的效果。  了解資料庫儲存引擎的內部運作對於選擇最適合您需求的資料庫系統至關重要。以下是一些建議幫助您選擇資料庫：   評估您的工作負載類型：確定您的應用程式是否更偏向OLTP或OLAP，以選擇針對特定需求最佳化的資料庫。  考慮資料庫的可擴展性：根據您的應用程式的未來需求和成長，確保資料庫可以滿足這些需求。  評估資料庫的性能：根據您的應用程式需求，選擇性能最佳的資料庫，特別是在讀取和寫入操作方面。  瞭解資料庫的安全性和完整性：選擇具有內建安全性和完整性機制的資料庫，以確保您的數據安全無虞。  考慮資料庫的支持和社區：選擇具有良好支持和活躍開發者社區的資料庫，這將有助於您解決問題和獲取技術支援。  儘管本章無法使您成為特定儲存引擎的調參專家，但至少能讓您獲得足夠的概念和詞彙，以便您能夠閱讀和理解所選資料庫的文檔。掌握資料庫儲存引擎的基本知識對於您作為應用程式開發人員來說是非常有價值的。  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":259,"path":260,"dir":218,"title":261,"description":261,"keywords":262,"body":266},"content:5.ddia:chapter4.md","/ddia/chapter4","Chapter 04 編碼與演化",[263,264,265],"編碼資料的格式bo","資料流的型別","小結","  \n  tr, th, td {\n    border: none!important;\n  }\n  .nolinebreak {\n    white-space: nowrap;\n  }\n  .movepadding {\n    padding-left: 2%!important;\n  }\n  當資料的  格式 (format)或  模式 (schema)發生變化時，通常需要對應用程式程式碼進行相應的更改(例如，為記錄新增新欄位，然後修改程式開始讀寫該欄位)。但在大型應用程式中，程式碼變更通常不會立即完成：  \n     \n       服務端 (server-side)： \n      可能需要執行   滾動升級 (rolling upgrade)，一次將新版本部署到少數幾個節點，檢查新版本是否執行正常，然後逐漸部完所有的節點。 \n   \n    \n       客戶端 (client-side)： \n      升不升級就要看使用者的心情了。使用者可能相當長一段時間裡都不會去升級軟體。 \n    這也表示，新舊版本的程式碼或是新舊資料格式可能會在系統中同時共處。系統想要繼續順利執行，就需要保持  雙向相容性 ：  \n     \n       向後相容 (backward compatibility)： \n      新的程式碼可以讀取由舊的程式碼寫入的資料。較容易處理，因為作者知道舊程式碼所使用的資料格式(一般最簡單的方法，就是保留舊程式碼即可讀取舊資料)。 \n   \n    \n       向前相容 (forward compatibility)： \n      舊的程式碼可以讀取由新的程式碼寫入的資料。較不易處理，因為舊版的程式需要忽略新版資料格式中新增的部分。 \n      編碼資料的格式bo  程式通常(至少)使用兩種形式的資料：   資料以物件、結構體、列表、陣列、散列表、樹等方式儲存到  記憶體 中。這些資料結構針對 CPU 的高效訪問和操作進行了最佳化(通常使用指標)。  資料寫入檔案，或透過網路傳送，則必須將其轉換為某種自包含的位元組序列(例如，JSON 文件)。這個位元組序列表示會與通常在記憶體中使用的資料結構不同。  要在兩種表示之間進行某種型別的翻譯。從記憶體中表示到位元組序列的轉換稱為  編碼 (Encoding)(也稱為  序列化 (serialization)或  編組 (marshalling))，反過來稱為  解碼 (Decoding)2(  解析 (Parsing)，  反序列化 (deserialization)，  反編組  (unmarshalling))    語言特定的格式  許多程式語言都內建了將記憶體物件編碼為位元組序列的支援。   Java 有 java.io.Serializable。  Ruby 有 Marshal。  Python 有 pickle。  第三方類別庫像是 Kryo for Java ....等。  編碼庫很方便，可以用很少的程式碼實現記憶體物件的儲存與恢復。但也有一些深層次的問題：   與特定的程式語言深度繫結，其他語言很難讀取這種資料，且很難將系統與其他組織的系統(可能用的是不同的語言)進行整合。  為了恢復相同物件型別的資料，解碼過程需要 例項化任意類。這會有安全性問題，若攻擊者可以讓應用程式解碼任意的位元組序列，他們就能例項化任意的類。  容易出現向前向後相容性帶來的麻煩問題。  效率(編碼或解碼所花費的 CPU 時間，以及編碼結構的大小)。例如，Java 的內建序列化由於其糟糕的效能和臃腫的編碼而臭名昭著。    JSON、XML和CSV  JSON，XML 和 CSV 屬於文字格式，因此具有人類可讀性。但也存在一些微妙的問題：   數字(numbers)編碼有很多模糊之處。在 XML 和 CSV 中，無法區分數字和純數字組成的字串(除了引用外部模式)。JSON 雖然區分字串與數字，但並不區分整數和浮點數，並且不能指定精度。  處理大數字時是個問題。例如大於$2^{53}$的整數無法使用 IEEE 754 雙精度浮點數精確表示因此在使用浮點數(例如 JavaScript)的語言進行分析時，這些數字會變得不準確。  JSON 和 XML 不支援二進位制資料(即不帶 字元編碼(character encoding)的位元組序列)。  XML 和 JSON 都有可選的模式支援。這些模式語言相當強大，相對學習和實現起來都比較複雜。  CSV 沒有任何模式，因此每行和每列的含義完全由應用程式自行定義。如果應用程式變更添加了新的行或列，那麼這種變更必須透過手工處理。    二進位制編碼  小資料集合的編碼造成的效能影響可以忽略不計；但一旦達到 TB 級別，資料格式的選型就會產生巨大的影響。二進位制串是很有用的功能，人們透過使用 Base64 將二進位制資料編碼為文字來繞過此限制。其特有的模式標識著這個值應當被解釋為 Base64 編碼的二進位制資料。   {\n    \"userName\": \"Martin\",\n    \"favoriteNumber\": 1337,\n    \"interests\": [\"daydreaming\", \"hacking\"]\n}\n     MessagePack  下圖為 MessagePack 編碼後的格式定義：\n    第 1 個位元組為 83(1000 0011)，1000 表示資料型別為 fixmap，0011 表示有 3 個項目。  第 2 ~ 10 個位元組表示欄位 \"userName\"。\n   第 2 個位元組為 a8(1010 1000)，101 表示資料型別為 fixstr，01000 表示長度為 8。  第 3 ~ 10 個位元組表示 userName 的 ASCII 編碼。  第 11 ~ 17 個位元組表示值 \"Martin\"。  第 18 ~ 32 個位元組表示欄位 \"favoriteNumber\"。  第 33 ~ 35 個位元組表示值 1337。\n   第 33 個位元組為 cd(1100 1101)，表示資料型別為 uint16。  第 34 ~ 35 表示 1337(05 39) 的十六進制編碼。  第 36 ~ 45 個位元組表示欄位 \"interests\"。  第 46 ~ 66 個位元組表示為一個陣列集合的資料。\n   第 46 個位元組為 92(1001 0010)，1001 表示資料型別為 fixarray，0010 表示有 2 個項目。  第 47 ~ 58 個位元組表示值 \"daydreaming\"。  第 59 ~ 66 個位元組表示值 \"hacking\"。  詳細教學可參考  MessagePack官網 。     Thrift  下圖為 Thrift BinaryProtocol 編碼後的格式定義：\n    第 1 ~ 13 個位元組表示值 \"Martin\"。\n   第 1 個位元組為 0b 表示為資料型別為 string。  第 2 ~ 3 個位元組為 00 01 表示為第 1 個項目。  第 4 ~ 7 個位元組為 00 00 00 06 表示為長度為 6。  第 8 ~ 13 個位元組表示 Martin 的 ASCII 編碼。  第 14 ~ 24 個位元組表示值 1337。\n   第 14 個位元組為 0a 表示為資料型別為 int64。  第 15 ~ 16 個位元組為 00 02 表示為第 2 個項目。  第 17 ~ 24 個位元組表示 1337 的十六進制編碼。  第 25 ~ 59 個位元組表示 1 個陣列集合。\n   第 25 個位元組為 0f 表示為資料型別為 list。  第 26 ~ 27 個位元組為 00 03 表示為第 3 個項目。  第 28 個位元組為 0b 表示為集合內的資料型別為 string。  第 29 ~ 32 個位元組為 00 00 00 02 表示集合含有 2 個項目。  第 33 ~ 36 個位元組為 00 00 00 0b 表示為長度為 11。  第 37 ~ 47 個位元組為 daydreaming 的 ASCII 編碼。  第 48 ~ 51 個位元組為 00 00 00 07 表示為長度為 7。  第 52 ~ 58 個位元組為 hacking 的 ASCII 編碼。  第 59 個位元組為此集合的結束標記。  詳細教學可參考  Thrift Binary protocol encoding 。  下圖為 Thrift CompactProtocol 編碼後的格式定義：\n    第 1 ~ 8 個位元組表示值 \"Martin\"。\n   第 1 個位元組為 18(0001 1000)。0001 表示 1 個項目，1000 表示為資料型別為 string。  第 2 個位元組為 06 表示為長度為 6。  第 3 ~ 8 個位元組表示 Martin 的 ASCII 編碼。  第 9 ~ 11 個位元組表示值 1337。\n   第 9 個位元組為 16(0001 0110)。0001 表示 1 個項目，0110 表示為資料型別為 int64。  第 10 ~ 11 個位元組表示 1337 的十六進制編碼(先作 ZigZag，再作 varint)。  第 12 ~ 34 個位元組表示值一個陣列集合。\n   第 12 個位元組為 19(0001 1001)。0001 表示 1 個項目，1001 表示為資料型別為 list。  第 13 個位元組為 28(0010 1000)。0010 表示 2 個項目，1000 表示為資料型別為 string。  第 14 ~ 25 個位元組表示 daydreaming 的長度 及 ASCII 編碼。  第 26 ~ 33 個位元組表示 hacking 的長度 及 ASCII 編碼。  第 34 個位元組為此集合的結束標記。  詳細教學可參考  Thrift Compact protocol encoding 。     Protocol Buffers  下圖為 Protocol Buffers 編碼後的格式定義：\n      Avro  下圖為 Thrift CompactProtocol 編碼後的格式定義：\n      Writer模式與Reader模式  \n     \n       Writer 模式 ： \n      應用程式想要編碼一些資料(將其寫入檔案或資料庫，透過網路傳送等)時，它使用它知道的任何版本的模式編碼資料。 \n   \n    \n       Reader 模式 ： \n      應用程式想要解碼一些資料(從一個檔案或資料庫讀取資料，從網路接收資料等)時，它希望資料在某個模式中。 \n    Avro 的關鍵思想是 Writer 模式和 Reader 模式不必是相同的 - 他們只需要相容。當資料解碼(讀取)時，Avro 庫透過並排檢視 Writer 模式和 Reader 模式並將資料從 Writer 模式轉換到 Reader 模式來解決差異。  Writer 模式和 Reader 模式的欄位順序不同，這是沒有問題的，因為模式解析透過欄位名匹配欄位。如果讀取資料的程式碼遇到出現在 Writer 模式中但不在 Reader 模式中的欄位，則忽略它。如果讀取資料的程式碼需要某個欄位，但是 Writer 模式不包含該名稱的欄位，則使用在 Reader 模式中宣告的預設值填充。       Writer模式到底是什麼  對於一段特定的編碼資料，Reader 如何知道其 Writer 模式？這取決於 Avro 使用的上下文。例如：   有很多記錄的大檔案。  支援獨立寫入的記錄的資料庫。  透過網路連線傳送記錄。    模式的優點   可以比各種 “二進位制 JSON” 變體更緊湊，因為它們可以省略編碼資料中的欄位名稱。  模式是一種有價值的文件形式，因為模式是解碼所必需的，所以可以確定它是最新的。  維護一個模式的資料庫允許你在部署任何內容之前檢查模式更改的向前和向後相容性。  對於靜態型別程式語言的使用者來說，從模式生成程式碼的能力是有用的，因為它可以在編譯時進行型別檢查。    資料流的型別  想要將某些資料傳送到不共享記憶體的另一個程序，就需要將它編碼為一個位元組序列。而資料可以透過多種方式從一個流程流向另一個流程，下列是一些常見的方式：   透過資料庫(詳細參閱 資料庫中的資料流)。  透過服務呼叫(詳細參閱 服務中的資料流：REST與RPC)。  透過非同步訊息傳遞(詳細參閱 訊息傳遞中的資料流)。    資料庫中的資料流  在資料庫中，寫入資料庫的過程對資料進行編碼，從資料庫讀取的過程對資料進行解碼。假若今天有一個程序訪問資料庫，在這種情況下，當程序更新為後續版本，就必須考慮將資料庫中的內容儲存為能向未來的自身程序傳送訊息。因此向後相容性顯然是必要的，否則你未來的程序將無法解碼你以前程序的資料。    當較舊版本的應用程式更新以前由較新版本的應用程式編寫的資料時，如果不小心，資料可能會丟失。    在不同的時間寫入不同的值  資料庫通常允許任何時候更新任何值。這意味著在一個單一的資料庫中，可能有一些值是五毫秒前寫的，而一些值是五年前寫的。  將資料重寫(遷移)到一個新的模式當然是可能的，但是在一個大資料集上執行是一個昂貴的事情，所以大多數資料庫如果可能的話就避免它。大多數關係資料庫都允許簡單的模式更改，例如新增一個預設值為空的新列，而不重寫現有資料。讀取舊行時，對於磁碟上的編碼資料缺少的任何列，資料庫將填充空值。  因此，模式演變允許整個資料庫看起來好像是用單個模式編碼的，即使底層儲存可能包含用各種歷史版本的模式編碼的記錄。    歸檔儲存  也許你不時為資料庫建立一個快照，例如備份或載入到資料倉庫。在這種情況下，即使源資料庫中的原始編碼包含來自不同時代的模式版本的混合，資料轉儲通常也將使用最新模式進行編碼。既然你不管怎樣都要複製資料，那麼你可以對這個資料複製進行一致的編碼。  由於資料轉儲是一次寫入的，而且以後是不可變的，所以 Avro 物件容器檔案等格式非常適合。這也是一個很好的機會，可以將資料編碼為面向分析的列式格式，例如列壓縮(Parquet)。    服務中的資料流：REST與RPC  透過網路進行通訊的方式最常見的安排兩個角色：  \n     \n       伺服器 ： \n      透過網路公開 API，也就是所謂的服務。 \n   \n    \n       客戶端 ： \n      可以連線到伺服器以向該 API 發出請求。 \n    Web 以這種方式工作：客戶(Web 瀏覽器)向 Web 伺服器發出請求，透過 GET 請求下載 HTML、CSS、JavaScript、影象等，並透過 POST 請求提交資料到伺服器。  API 則包含一組標準的協議和資料格式(HTTP、URL、SSL/TLS、HTML 等)。由於網路瀏覽器、網路伺服器和網站作者大多同意這些標準，因此可以使用任何網路瀏覽器訪問任何網站。  也由於 Web 瀏覽器不是唯一的客戶端型別，所以伺服器的響應通常不是用於顯示給人的 HTML，而是便於客戶端應用程式進一步處理的編碼資料(例如 JSON)。雖然 HTTP 可能被用作傳輸協議，但頂層實現的 API 是特定於應用程式的，客戶端和伺服器需要就該 API 的細節達成一致。  伺服器本身可以是另一個服務的客戶端(例如，典型的 Web 應用伺服器充當資料庫的客戶端)。這種方法通常用於將大型應用程式按照功能區域分解為較小的服務，這樣當一個服務需要來自另一個服務的某些功能或資料時，就會向另一個服務發出請求。這種構建應用程式的方式傳統上被稱為  面向服務的體系結構 (service-oriented architecture，SOA)，最近被改進和更名為  微服務架構 。  這類服務類似於資料庫，它們通常允許客戶端提交和查詢資料。並公開了一個特定於應用程式的 API，只允許由服務的業務邏輯(應用程式程式碼)預定的輸入和輸出。這種限制提供了一定程度的封裝，限制了對客戶可以做什麼和不可以做什麼。面向服務 / 微服務架構的設計目標是使服務獨立部署來讓應用程式更易於更改和維護。每個服務應該由一個開發團隊擁有，而不必與其他團隊協調，因此伺服器和客戶端使用的資料編碼必須在不同版本的服務 API 之間相容。    Web服務  服務使用 HTTP 作為底層通訊協議時，可稱之為 Web 服務。它不僅在 Web 上使用，而且在幾個不同的環境中使用：   執行在使用者裝置上的客戶端應用程式，透過 HTTP 向服務發出請求。  一個服務向同一組織擁有的另一個服務提出請求，這些服務通常位於同一資料中心內，作為面向服務 / 微服務架構的一部分。(支援這種用例的軟體有時被稱為  中介軟體 (middleware))  一個服務透過網際網路向不同組織所擁有的服務提出請求。這用於不同組織後端系統之間的資料交換。此類別包括由線上服務(如信用卡處理系統)提供的公共 API，或用於共享訪問使用者資料的 OAuth。  兩種流行的 Web 服務方法：  \n     \n       REST ： \n      是一個基於 HTTP 原則的設計。強調簡單的資料格式，使用 URL 來標識資源，並使用 HTTP 功能進行快取控制，身份驗證和內容型別協商。 \n   \n    \n       SOAP ： \n      用於製作網路 API 請求，使用稱為 Web 服務描述語言(WSDL，詳細教學可參考  WSDL教學 )的基於 XML 的協議。WSDL 支援程式碼生成，客戶端可以使用本地類和方法呼叫(編碼為 XML 訊息並由框架再次解碼)訪問遠端服務。雖然它最常用於 HTTP，但其目的是獨立於 HTTP，並避免使用大多數 HTTP 功能。 \n    WSDL文件範例如下：   \u003Cdefinitions name = \"HelloService\"\n   targetNamespace = \"http://www.examples.com/wsdl/HelloService.wsdl\"\n   xmlns = \"http://schemas.xmlsoap.org/wsdl/\"\n   xmlns:soap = \"http://schemas.xmlsoap.org/wsdl/soap/\"\n   xmlns:tns = \"http://www.examples.com/wsdl/HelloService.wsdl\"\n   xmlns:xsd = \"http://www.w3.org/2001/XMLSchema\">\n\n   \u003Cmessage name = \"SayHelloRequest\">\n      \u003Cpart name = \"firstName\" type = \"xsd:string\"/>\n   \u003C/message>\n\n   \u003Cmessage name = \"SayHelloResponse\">\n      \u003Cpart name = \"greeting\" type = \"xsd:string\"/>\n   \u003C/message>\n\n   \u003CportType name = \"Hello_PortType\">\n      \u003Coperation name = \"sayHello\">\n         \u003Cinput message = \"tns:SayHelloRequest\"/>\n         \u003Coutput message = \"tns:SayHelloResponse\"/>\n      \u003C/operation>\n   \u003C/portType>\n\n   \u003Cbinding name = \"Hello_Binding\" type = \"tns:Hello_PortType\">\n      \u003Csoap:binding style = \"rpc\"\n         transport = \"http://schemas.xmlsoap.org/soap/http\"/>\n      \u003Coperation name = \"sayHello\">\n         \u003Csoap:operation soapAction = \"sayHello\"/>\n         \u003Cinput>\n            \u003Csoap:body\n               encodingStyle = \"http://schemas.xmlsoap.org/soap/encoding/\"\n               namespace = \"urn:examples:helloservice\"\n               use = \"encoded\"/>\n         \u003C/input>\n\n         \u003Coutput>\n            \u003Csoap:body\n               encodingStyle = \"http://schemas.xmlsoap.org/soap/encoding/\"\n               namespace = \"urn:examples:helloservice\"\n               use = \"encoded\"/>\n         \u003C/output>\n      \u003C/operation>\n   \u003C/binding>\n\n   \u003Cservice name = \"Hello_Service\">\n      \u003Cdocumentation>WSDL File for HelloService\u003C/documentation>\n      \u003Cport binding = \"tns:Hello_Binding\" name = \"Hello_Port\">\n         \u003Csoap:address\n            location = \"http://www.examples.com/SayHello/\" />\n      \u003C/port>\n   \u003C/service>\n\u003C/definitions>\n    遠端過程呼叫(RPC)的問題  遠端過程呼叫(RPC)的思想，RPC 模型試圖向遠端網路服務發出請求，看起來與在同一程序中呼叫函式或方法相同。但根本上是有缺陷的。因為網路請求與本地函式呼叫還是有不同之處：     本地函式呼叫  網路請求    可預測的，成功或失敗取決於受你控制的引數  不可預測的，請求或響應可能由於網路問題會丟失   返回/不返回結果、丟擲異常  返回/不返回結果、丟擲異常、或者因為超時造成返回時已沒有結果   不會發生響應丟失的情況  能會發生請求實際上已經完成，只是響應丟失的情況   執行時間大致相同  執行時間不穩定(會有網路擁塞或者遠端服務超載的問題)   可以高效地將引用(指標)傳遞給本地記憶體中的物件  所有引數都需要被編碼成可以透過網路傳送的一系列位元組    RPC的當前方向  上述的編碼在基礎上構建了各種 RPC 框架：   Thrift 和 Avro 帶有 RPC 支援  gRPC 是使用 Protocol Buffers 的 RPC 實現  Finagle 也使用 Thrift  Rest.li 使用 JSON over HTTP。  新一代的 RPC 框架更加明確的是，遠端請求與本地函式呼叫不同。   Finagle 和 Rest.li 使用 futures(promises)來封裝可能失敗的非同步操作。  gRPC 支援流，其中一個呼叫不僅包括一個請求和一個響應，還可以是隨時間的一系列請求和響應。    訊息傳遞中的資料流  RPC 和資料庫之間的非同步訊息傳遞系統。   與 RPC 類似，因為客戶端的請求(通常稱為訊息)以低延遲傳送到另一個程序。  與資料庫類似，不是透過直接的網路連線傳送訊息，而是透過稱為訊息代理(也稱為訊息佇列或面向訊息的中介軟體)的中介來臨時儲存訊息。  與直接 RPC 相比，使用訊息代理有幾個優點：   如果收件人不可用或過載，可以充當緩衝區，從而提高系統的可靠性。  可以自動將訊息重新發送到先前已經崩潰的程序，從而防止訊息丟失。  避免發件人需要知道收件人的 IP 地址和埠號(這在虛擬機器經常出入的雲部署中特別有用)。  它允許將一條訊息傳送給多個收件人。  將發件人與收件人邏輯分離(發件人只是釋出郵件，不關心使用者)。  與 RPC 相比，差異在於訊息傳遞通訊通常是單向的：傳送者通常不期望收到其訊息的回覆。一個程序可能傳送一個響應，但這通常是在一個單獨的通道上完成的。這種通訊模式是非同步的：傳送者不會等待訊息被傳遞，而只是傳送它，然後忘記它。    訊息代理  訊息代理的使用方式如下：一個程序將訊息傳送到指定的佇列或主題，代理確保將訊息傳遞給那個佇列或主題的一個或多個消費者或訂閱者。在同一主題上可以有許多生產者和許多消費者。  訊息代理通常不會執行任何特定的資料模型 —— 訊息只是包含一些元資料的位元組序列，因此你可以使用任何編碼格式。如果編碼是向後和向前相容的，你可以靈活地對釋出者和消費者的編碼進行獨立的修改，並以任意順序進行部署。    分散式的Actor框架  Actor 模型是單個程序中併發的程式設計模型。邏輯被封裝在 actor 中，而不是直接處理執行緒。actor 通常代表一個客戶或實體，它可能有一些本地狀態(不與其他任何角色共享)，它透過傳送和接收非同步訊息與其他角色通訊。不保證訊息傳送：在某些錯誤情況下，訊息將丟失。由於每個角色一次只能處理一條訊息，因此不需要擔心執行緒，每個角色可以由框架獨立排程。分散式的 Actor 框架實質上是將訊息代理和 actor 程式設計模型整合到一個框架中。  三個流行的分散式 actor 框架處理訊息編碼如下：   Akka 使用 Java 的內建序列化，不提供前向或後向相容性。 但是，你可以用類似 Prototol Buffers 的東西替代它，從而獲得滾動升級的能力。  Orleans 預設使用不支援滾動升級部署的自定義資料編碼格式；要部署新版本的應用程式，你需要設定一個新的叢集，將流量從舊叢集遷移到新叢集，然後關閉舊叢集。像 Akka 一樣，可以使用自定義序列化外掛。  Erlang OTP 中，對記錄模式進行更改是非常困難的(儘管系統具有許多為高可用性設計的功能)。 滾動升級是可能的，但需要仔細計劃。 一個新的實驗性的 maps 資料型別(2014 年在 Erlang R17 中引入的類似於 JSON 的結構)可能使得這個資料型別在未來更容易。    小結",{"id":268,"path":269,"dir":218,"title":270,"description":270,"keywords":271,"body":277},"content:5.ddia:chapter5.md","/ddia/chapter5","Chapter 05 複製",[252,272,273,274,275,276,265],"領導者與追隨者","同步複製與非同步複製","複製落後的問題","多領導複製","無領導複製","  \n  tr, th, td {\n    border: none!important;\n  }\n  .nolinebreak {\n    white-space: nowrap;\n  }\n  .movepadding {\n    padding-left: 2%!important;\n  }\n  引言   複製資料的目的：   使資料與使用者在地理上接近（減少延遲）  提高系統可用性（即使部分故障）  提高讀取吞吐量（伸縮讀請求機器數量）  複製資料系統的挑戰：   假設資料集非常小  假設每臺機器可以儲存整個資料集的副本  處理資料的變更  變更複製演算法：   單領導者（single leader）  多領導者（multi leader）  無領導者（leaderless）  複製權衡：   同步複製 vs 非同步複製  處理失敗的副本  複製算法歷史：   70 年代研究  分散式資料庫變為主流  複製延遲問題：   最終一致性（eventual consistency）  讀己之寫（read-your-writes）  單調讀（monotonic read）  領導者與追隨者   副本（replica）：儲存資料庫複製的節點。   確保所有資料落在所有副本上的問題：\n向資料庫的寫入操作需要傳播到所有副本。  基於領導者的複製（leader-based replication）：   領導者（leader）：負責接收寫入操作。  追隨者（followers）：負責拉取日誌並更新本地資料庫副本。  複製過程：   客戶端將寫入請求傳送給領導者。  領導者將新資料寫入本地儲存。  領導者將資料變更傳送給所有追隨者（複製日誌/變更流）。  追隨者按照相同處理順序更新本地資料庫副本。  讀取操作：客戶端可以向領導者或任一追隨者進行查詢。  基於領導者的複製應用範例：   關係資料庫：PostgreSQL（9.0 版本開始）、MySQL、Oracle Data Guard、SQL Server 的 AlwaysOn 可用性組。  非關係資料庫：MongoDB、RethinkDB、Espresso。  分散式訊息代理：Kafka、RabbitMQ 高可用佇列。  網路檔案系統：DRBD 等塊複製裝置。  \n      圖 5-1 基於領導者的（主/從）複製  同步複製與非同步複製   複製細節：複製可以是同步（synchronously）或非同步（asynchronously）。   同步複製：主庫在報告寫入成功前，需要等待從庫確認已收到寫入操作。  非同步複製：主庫傳送訊息，但不等待從庫響應。  同步複製的優缺點：   優點：從庫保證有與主庫一致的最新資料副本。  缺點：同步從庫無響應時，主庫無法處理寫入操作。  半同步複製（semi-synchronous）：   一個從庫是同步的，其他的從庫則是非同步的。  同步從庫不可用或緩慢時，將一個非同步從庫改為同步執行。  完全非同步複製：   主庫失效且不可恢復時，尚未複製給從庫的寫入會丟失。  優點：主庫可以繼續處理寫入，即使所有從庫都落後。  鏈式複製（chain replication）：   同步複製的一種變體，旨在不丟資料並提供良好效能和可用性。  已在一些系統中實現，例如 Microsoft Azure Storage。  \n      圖 5-2 基於領導者的複製：一個同步從庫和一個非同步從庫  複製的一致性與共識（consensus）：   第九章將詳細探討共識理論。  本章主要討論實踐中的資料庫常用的簡單複製形式。  設定新從節點：   獲取主節點一致性快照。  將快照複製到新的從節點。  從節點連線到主節點並拉取快照後的所有資料變更。  從節點趕上主庫後，可以繼續及時處理主節點資料變化。  處理節點宕機：   以基於領導者的複製實現高可用。  從節點失效：追趕恢復   重新連線到主節點。  請求並處理斷開期間的所有資料變更。  主節點失效：故障切換   確認主庫失效。  選擇新的主節點。  重新配置系統以啟用新的主節點。  故障切換過程中可能出現的問題：   非同步複製導致資料損失。  與其他外部儲存協調時的問題。  腦裂問題。  超時配置的困難。  儘管有些軟體支援自動故障切換，但許多運維團隊仍更願意手動執行故障切換。   分散式系統中的基本問題包括節點故障、不可靠的網路、副本一致性、永續性、可用性和延遲。這些問題將在第八章和第九章中深入討論。  複製日誌的實現可以分為以下幾種：   基於語句的複製：主節點記錄每個寫入請求並將語句日誌傳送給從庫。但這種方式存在諸多問題，如非確定性函式、自增列、副作用等。  傳輸預寫式日誌（WAL）：主庫將日誌通過網路傳送給從庫。此方法使複製與儲存引擎緊密耦合，升級資料庫軟體可能需要停機。  邏輯日誌複製（基於行）：對複製和儲存引擎使用不同的日誌格式，使主庫和從庫能夠執行不同版本的資料庫軟體或儲存引擎。邏輯日誌格式更容易解析，有利於資料變更捕獲（change data capture）。  基於觸發器的複製：通過資料庫中的觸發器和儲存過程，將資料更改記錄到單獨的表中，再使用外部程式讀取該表並將資料變更複製到另一個系統。儘管開銷較大且容易出錯，但基於觸發器的複製具有很高的靈活性。  以上四種複製方式各有優缺點，具體應用需根據實際情況選擇合適的複製方法。  複製落後的問題  能夠容忍節點故障只是人們採用複製的原因之一。  包括容錯、可伸縮性和降低延遲。\n基於領導者的複製方法可用於讀多寫少的場景，通過增加從節點來分散讀請求以達到讀取伸縮。  然而，這種方法主要適用於非同步複製，因為完全同步的配置容易受到節點故障和網路中斷的影響，導致整個系統無法寫入。最後可能會遇到最終一致性問題。  當應用程式讀取從節點時，可能會看到過時的資訊，導致不一致。\n這種不一致是暫時的，但在某些情況下，如系統負載過高或網路問題，延遲可能達到幾分鐘。  這不僅是理論問題，還會在應用設計中產生實際影響。\n本節將探討複製延遲時可能出現的問題以及解決方案。  讀己之寫  用戶提交資料後可能會立即查看。  然而，如果使用異步複製，新資料可能尚未同步到副本中，導致用戶看不到剛剛提交的資料，造成用戶不滿。  \n      圖 5-3 使用者寫入後從舊副本中讀取資料。需要寫後即讀 (read-after-write) 的一致性來防止這種異常  「寫後讀一致性」的概念，它確保用戶在提交更新後重新加載頁面時能看到自己的更新。這並不保證其他用戶立即看到這些更新，但可確保用戶的輸入已被妥善儲存。  在基於領導者的複製系統中實現寫後讀一致性的方法：   對可能被使用者修改的內容，總是從主節點讀取。  跟蹤上次更新時間，決定是否從主節點讀取。監控從節點的複製延遲，避免讀取過於滯後的從節點。  客戶端記住最近一次寫入的時間戳，確保讀取時所有變更已傳播到從節點。  考慮數據中心分佈，確保需要主節點的請求路由到正確的資料中心。  使用多個裝置的使用者需提供跨裝置的寫後讀一致性的挑戰。以下是兩個重點：   跨裝置元資料的中心化儲存：由於不同裝置上的程式無法知道其他裝置的操作，因此需要對元資料進行中心化儲存，以記住使用者的更新時間戳。  跨資料中心的請求路由：當副本分布在不同的資料中心時，確保來自不同裝置的請求路由到同一資料中心變得困難。解決方法是將所有使用者裝置的請求路由到同一個資料中心。  單調讀取  這段描述了在使用非同步從庫讀取資料時，可能出現的時光倒流現象。\n當使用者從不同從節點進行多次讀取時，可能會看到不一致的結果，  例如先看到一條評論，然後該評論消失。這種現象可能會讓使用者感到困惑。  \n      圖 5-4 使用者首先從新副本讀取，然後從舊副本讀取。時間看上去回退了。為了防止這種異常，我們需要單調的讀取。  介於強一致性和最終一致性之間的保證。  單調讀確保使用者在連續讀取過程中不會看到時間回退，即使讀取到的是舊資料。\n實現單調讀的方法之一是讓每個使用者始終從同一副本讀取資料。  簡單來說，單調讀保證了使用者讀取資料的連續性，避免了時間回退。  一致性前綴讀取  複製延遲異常如何違反因果律。  當第三個人聽到 Cake 夫人和 Poons 先生的對話時，由於從庫延遲的差異，他們聽到的對話順序顛倒了。\n這使得觀察者感覺 Cake 夫人在問題被提出之前就已經回答了，顯得具有超能力。  這樣的現象可能會讓人感到困惑。  \n      圖 5-5 如果某些分割槽的複製速度慢於其他分割槽，那麼觀察者可能會在看到問題之前先看到答案。  系統會為每個寫入操作分配一個全局唯一的時間戳。\n這些時間戳保證了操作的全局順序。  當用戶發起讀取請求時，系統會返回小於或等於該請求時間戳的最新數據。\n這樣，即使某些節點的數據尚未同步，用戶也能獲得一個一致的數據快照。  此外，這種策略還能保證讀取操作的因果一致性，即用戶能夠觀察到他們之前的寫入操作所引起的變化。  總之，一致性前綴讀取是一種在分布式系統中確保數據讀取一致性的有效策略。\n通過使用全局唯一的時間戳對寫入操作進行排序，並在讀取時返回小於或等於請求時間戳的最新數據，這個策略確保了用戶在讀取數據時能夠獲得一個一致的數據快照，同時保證了讀取操作的因果一致性。  複製落後的解決方案  確保資料一致性和正確性非常重要。\n當複製延遲變大時，我們需要關注應用程式的行為，確保使用者體驗不受影響。  應用程式可以在資料庫層面提供更強的保證，而事務就是一個很好的解決方案。\n儘管在分散式資料庫中，一些系統放棄了事務，但事務仍然是一個有力的工具。  後續章節(第7章、第9章)將更詳細地討論事務和其他替代方案。  多領導複製  目前為止，我們專注在單一主節點的複製架構，但還有其他選擇。單一主節點的問題在於所有寫入都必須通過它，而多領導者配置允許多個節點接受寫入。在這種情況下，每個主節點也同時是其他主節點的從節點。  多領導複製的適用場景  在單個數據中心內部使用多個主節點的配置沒有太大意義，因為其導致的複雜性已經超過了能帶來的好處。但在一些情況下，這種配置也是合理的。  多資料中心操作  討論了一種多主節點配置，用於在多個資料中心分散數據庫副本。這種配置可提高容錯能力和地理親近性。每個資料中心都有一個主庫，並在資料中心之間互相複製更改。這樣可以在本地資料中心內使用常規的主從複製。  \n      圖 5-6 跨多個數據中心的多主複製  我們來比較一下在運維多個數據中心時，單領導和多領導的適應情況   效能   單領導：寫入需穿越網際網路，增加寫入時間。  多領導：寫入在本地資料中心進行，降低網路延遲影響。  容忍資料中心停機   單領導：需故障切換，從庫成為主庫。  多領導：各資料中心獨立運作，故障資料中心恢復後自動複製。  容忍網路問題   單領導：對資料中心間連線問題敏感，寫入為同步操作。  多領導：採非同步複製，對網路問題有更高的承受能力。  一些資料庫支援多領導配置，並且可以透過外部工具實現。\n儘管多領導複製具有優點，但也存在寫衝突問題。  此外，由於多領導複製在很多資料庫中是改裝功能，可能會有一些配置上的缺陷，並可能與其他資料庫功能產生意外反應。\n因此，多領導複製被認為是一個高風險領域，應該盡量避免使用。  客戶端的離線操作  另一種適用多領導複製的場景，即需要在斷網狀態下仍能使用的應用程式\n例如日曆應用程式。\n在這種情況下，每個裝置都有一個本地資料庫，並存在非同步的多主複製過程來同步日曆副本。\n這種設定類似於資料中心之間的多領導複製，但網路連線極不可靠。  雖然有一些工具可以幫助實現多領導複製，但實際應用中仍然有很多難點需要克服。  其中一個工具是CouchDB。  協作編輯  這種應用允許多人同時編輯同一份文件，例如 Etherpad 和 Google Docs。  為了避免編輯衝突，應用程式必須先取得文件的鎖定，然後才能進行編輯。\n但為了加速協作，可能會將更改的單位設定得非常小，並避免鎖定。  這種方法允許多個使用者同時進行編輯，但需要解決衝突。\n這種協作模式相當於主從複製模型下在主節點上執行事務操作。  處理寫入衝突  容易遇到寫衝突的問題。\n例如，兩個使用者同時編輯同一個維基頁面，且對同一個標題進行修改，這就可能發生衝突。  這時需要解決衝突，以保證數據的一致性。\n多領導者的資料庫同步上 通常被認為有風險，應儘量避免．  \n      圖 5-7 兩個主節點同時更新同一記錄引起的寫入衝突  同步與非同步衝突檢測  在單領導資料庫中，兩個寫入操作會發生阻塞，必須等待第一個操作完成才能進行第二個。  而在多領導配置中，兩個操作都能成功進行，但是衝突的檢測需要在稍後的時間進行，可能導致解決衝突的過程較為困難。  如果想要同步衝突檢測，可以等待所有副本接受寫入後再告訴使用者寫入成功，但是這樣會失去多領導複製的優勢。\n如果需要同步衝突檢測，建議使用單領導複製。  避免衝突  最簡單策略，即確保所有寫入特定記錄的操作都透過同一個主庫進行。\n這樣可以避免多個主庫同時寫入同一個記錄而導致衝突。  然而，如果需要更改指定的主庫，例如因為某個資料中心出現故障，就需要處理不同主庫同時寫入的可能性。\n這需要在應用程式中實現一些特殊處理。  漸趨一致的狀態  如何處理多個複本之間的數據一致性問題。\n當單個主資料庫進行寫操作時，最後一次寫操作將決定該欄位的最終值。  但在多主配置中，由於沒有明確的寫入順序，最終值很難確定。\n因此，必須以一種收斂的方式解決衝突，以確保所有複本的最終值都是相同的。  有多種方法可以實現這個目標，其中包括：   使用唯一 ID 來選擇勝利者並丟棄其他寫入，這種方法稱為最後寫入勝利。然而，這種方法容易造成資料丟失。  為每個副本分配一個唯一的 ID，以 ID 編號較高的寫入為優先。同樣，這種方法也可能導致資料丟失。  將寫入的值合併在一起，例如按字母順序排序後合併。  使用顯式資料結構記錄衝突，然後編寫解決衝突的程式碼來保留所有資訊。  自訂解決衝突的邏輯   寫入時執行\n指當資料庫系統在複製更改日誌中發現衝突時，會立即呼叫衝突處理程式碼。  讀取時執行\n將所有的不同版本都儲存在資料庫中。\n當應用程式下一次讀取這些資料時，會將這些不同版本的資料都返回給應用程式。\n應用程式可以讓使用者解決衝突或自動解決衝突，然後將結果寫回資料庫。\n這是一種常見的解決衝突的方法，例如 CouchDB 就是這樣做的。   自動衝突解決\n衝突解決規則可能很容易變得越來越複雜，自定義程式碼可能也很容易出錯。\n亞馬遜是一個經常被引用的例子，由於衝突解決處理程式而產生了令人意外的效果：一段時間以來，購物車上的衝突解決邏輯將保留新增到購物車的物品，但不包括從購物車中移除的物品。\n因此，顧客有時會看到物品重新出現在他們的購物車中，即使他們之前已經被移走【37】。  已經有一些有趣的研究來自動解決由於資料修改引起的衝突。有幾項研究值得一提：   無衝突複製資料型別（Conflict-free replicated datatypes，CRDT）【32,38】是可以由多個使用者同時編輯的集合、對映、有序列表、計數器等一系列資料結構，它們以合理的方式自動解決衝突。一些 CRDT 已經在 Riak 2.0 中實現【39,40】。  可合併的持久資料結構（Mergeable persistent data structures）【41】顯式跟蹤歷史記錄，類似於 Git 版本控制系統，並使用三向合併功能（而 CRDT 使用雙向合併）。  操作轉換（operational transformation）  42  是 Etherpad 【30】和 Google Docs 【31】等協同編輯應用背後的衝突解決演算法。它是專為有序列表的並發編輯而設計的，例如構成文字文件的字元列表。\n這些演算法在資料庫中的實現還很年輕，但很可能將來它們會被整合到更多的複製資料系統中。自動衝突解決方案可以使應用程式處理多主資料同步更為簡單。  怎樣才算衝突？  有些衝突是明顯的，例如同時修改同一欄位的寫操作，但有些衝突可能不太容易察覺，  例如在會議室預訂系統中避免同一房間的重疊預訂，雖然可以在預訂時再次檢查，但在多領導不同主庫時還是可能發生衝突．  接下來的章節將進一步討論如何解決這些衝突，\n包括在第七章中介紹更多衝突案例，以及在第十二章中討論檢測和解決衝突的可伸縮方法。  Multi-Leader 複製的拓樸  即資料如何從一個節點傳播到另一個節點。\n當有兩個主庫時，唯一合理的拓撲是將所有寫入都發送到對方。  但如果有兩個以上的主庫時，就有多種不同的拓撲結構可選擇。  \n      圖 5-8 三種可以在多主複製中使用的拓撲示例。  常見的三種拓撲結構   環狀拓墣  星狀拓墣  All to all 拓墣  其中，全部到全部的拓撲結構容錯性較好，因為它可以避免單點故障，但可能存在訊息超前的問題。\n而環形和星形拓撲結構的容錯性較差，一旦某個節點出現故障，可能會中斷複製訊息流，需要手動重新配置。  此外，在環形和星形拓撲中，為了避免無限複製迴圈，每個節點都被賦予一個唯一的識別符號。  \n      圖 5-9 使用多主複製時，寫入可能會以錯誤的順序到達某些副本。  多主複製系統中的一個因果關係問題，  例如當不同的節點以不同順序處理寫入時可能會發生衝突。\n為了解決這個問題，可以使用**版本向量(version vectors)**技術進行排序。  但是，有些多主複製系統的衝突檢測技術可能不夠好，因此在使用這些系統時應該仔細閱讀文件並進行測試，以確保系統能提供所需的保證。  無領導複製  本章節討論了不同的複製方法，如單主複製和多主複製，它們的共同點是都有一個主庫來處理寫請求。  然而，無主複製方法不同，因為它不依賴主庫。  無主複製系統如 Dynamo、Riak、Cassandra 和 Voldemort 允許客戶端直接向副本寫入資料，或通過協調者節點進行寫入。\n無主複製設計對資料庫的使用方式具有重要影響。  當節點失效時寫入資料庫  假設有三個副本的資料庫。當其中一個副本不可用時，基於領導者的配置可能需要進行故障切換。  然而，在無主配置中，故障轉移不存在。\n客戶端會將寫入傳送到所有副本，而無需擔心其中一個副本錯過了寫入。  只要有兩個副本確認寫入，就認為寫入成功。  \n     圖 5-10 法定寫入，法定讀取，並在節點中斷後讀修復。  作者提到了節點重新連線後的數據同步問題。  為了解決可能讀取到過時數據的問題，客戶端會向多個節點發送讀請求。\n然後，通過版本號確定各節點返回的數據哪個是最新的，以避免使用到舊的數據資料。  利用讀取來修復和反熵  在密集型應用的資料複製過程中，有兩種常用的方法來確保所有資料在各個副本中一致：   利用讀取來修復：客戶端在讀取多個節點時，檢測並修正舊的數據資料(傳送新值給該節點)，適用於經常被讀取的值。  反熵過程：一個後台程序在副本間不斷檢查並複製缺失的資料，不依賴特定的順序，可能有一定延遲。  然而，並非所有系統都實現了這兩種機制。如果沒有反熵過程，很少被讀取的值可能會丟失，降低了永續性。  讀取和寫入的法定票數演算(Quorums)  我們討論了資料密集型應用中的資料副本。  以三個副本的情況為例，只要至少有兩個副本完成寫入，該寫入就算成功。為了確保讀取到的資料是最新的，我們需要從至少兩個副本讀取。\n通常，n 代表副本數，w 代表寫入成功需要的節點數，r 代表讀取需要查詢的節點數。  只要 r 和 w 的和大於 n，就能確保讀取到最新的資料。\n這種讀寫方法被稱為法定人數的讀寫。  在 Dynamo 風格的資料庫中，n、w 和 r 的值都是可配置的，可以根據需求進行調整。   叢集中可能有多於 n 個的節點（叢集的機器數可能多於副本數目）。但是任何給定的值只能儲存在 n 個節點上。這允許對資料集進行分割槽，從而可以支援比單個節點的儲存能力更大的資料集。我們將在 第六章 繼續討論分割槽。   如果 w \u003C n ，當節點不可用時，我們仍然可以處理寫入。  如果 r \u003C n ，當節點不可用時，我們仍然可以處理讀取。  對於 n = 3，w = 2，r = 2，我們可以容忍一個不可用的節點。  對於 n = 5，w = 3，r = 3，我們可以容忍兩個不可用的節點。 這個案例如 圖 5-11 所示。  通常，讀取和寫入操作始終並行傳送到所有 n 個副本。引數 w 和 r 決定我們等待多少個節點，即在我們認為讀或寫成功之前，有多少個節點需要報告成功。  \n     圖 5-11 如果 w + r > n ，讀取 r 個副本，至少有一個副本必然包含了最近的成功寫入。  在進行資料寫入或讀取時，如果可用節點少於所需的 w 或 r 值，將會出現錯誤。\n節點失效可能有多種原因，如節點關閉、操作錯誤或網路問題等。  我們只需關注節點是否成功響應，而無需區分錯誤類型。  Quorum 一致性的限制  當有 n 個副本，並滿足 w + r > n 的條件時，通常每次讀取都能獲得最新寫入的值。\n為確保 w + r > n，並在節點故障時保持可靠性，r 和 w 通常被選為大於 n/2 的數字。\n設計分散式算法時，可以靈活選擇其他讀寫節點數量。  當 w 和 r 設定較小，以使 w + r \u003C= n 時，讀取和寫入操作僅需要少量成功響應。\n這樣的設定可以提高可用性和降低延遲，但可能導致讀取到較舊的資料。\n只有當可達副本數量低於 w 或 r 時，資料庫才無法進行讀寫。  雖然法定人數 (w + r > n) 似乎可以保證讀取返回最新的寫入值，但實際上仍可能出現邊緣情況，導致讀取到舊的 數據資料。\n這些邊緣情況包括寫入和讀取落在不同節點上、寫入衝突、寫入和讀取同時進行、寫入部分成功或節點故障等。  因此，在實踐中，Dynamo 風格的資料庫通常對可容忍最終一致性的用例進行最佳化。\n雖然可以通過調整 w 和 r 的值來減少讀取到陳舊值的機率，但將其視為絕對保證是不明智的。  為了獲得更強有力的保證，可能需要使用  交易(Translation)  或 共識方法(Consensus Algorithm) 。  監控舊值  在監控資料庫健康狀況時，了解複製延遲和陳舊讀取對於確保數據準確性非常重要。  對於基於領導者的複製，可以通過比較主從庫的位置來測量延遲解決舊數據資料的判斷。  但是無主複製系統的監控更為困難，無主寫入順序是不固定的，讓監控更加困難．\n如果沒有反熵，落後程度就會沒有上限．  目前對於無主複製的監測有一定的研究，但尚未普及。  將陳舊測量值納入標準度量集是有益的，\n因為最終一致性是個模糊的保證，從維運角度來看，最終\"量化\"仍然是件很重要的事情。  寬鬆的Quorums和提示移交  使用合理配置的法定人數可以讓資料庫在不需要故障切換的情況下容忍節點故障。\n這對於需要高可用性、低延遲並能容忍偶爾讀取到舊資料的應用非常有吸引力。  然而，法定人數在網路中斷時可能無法如預期那樣具有容錯性。  如果客戶端與資料庫節點失去連接，則剩餘的可用節點可能不足以達到法定人數，導致客戶端無法正常使用資料庫。\n如果在網路中斷期間客戶端能連線到部分資料庫節點，但無法達到法定節點數量，設計人員需考慮：   對無法滿足法定 w 或 r 個節點數的請求是否返回錯誤？  或是接受寫入，寫到部分可達節點，而非常見制定的 n 個節點？「寬鬆的Quorums」  簡而言之，如何在網路中斷時保證資料庫正常運行是設計人員需要考慮的問題。\n寬鬆的法定人數（sloppy quorum）在設計資料密集型應用的過程中的作用。  當網路出現問題時，寬鬆的法定人數可以提高寫入可用性，允許寫入操作在任何可用的節點上完成。\n但這種方法不能確保讀取到最新的數據，因為最新的數據可能已經暫時寫入了不在主節點集合中的節點。  提示移交（hinted handoff）機制可在網路問題解決後將這些暫時寫入的數據傳送到主節點。  寬鬆的Quorums 模式 在不同的 Dynamo 實現中是可選的，並且其預設設置因實現而異。  多資料中心營運  無領導複製在多資料中心操作中的適用性，特別是在容忍衝突、網路中斷和延遲尖峰方面。Cassandra 和 Voldemort 運用無主模型來實現多資料中心支援，  將副本分布在各個資料中心，並允許配置每個資料中心的副本數量。  客戶端通常僅等待本地資料中心內的法定節點確認，以減少跨資料中心鏈路延遲和中斷的影響。  Riak 則將通訊限制在單一資料中心範圍內，並在後台非同步執行跨資料中心的複製。  檢測並發寫入  Dynamo 風格的資料庫可能會遇到衝突問題，因為多個客戶端可以同時寫入相同的鍵。  由於網路延遲和部分節點故障，事件可能以不同順序到達不同節點，導致衝突。  例如，圖 5-12 顯示了兩個客戶機 A 和 B 同時寫入三節點資料儲存中的鍵 X：   節點 1 接收來自 A 的寫入，但由於暫時中斷，未接收到來自 B 的寫入。  節點 2 首先接收來自 A 的寫入，然後接收來自 B 的寫入。  節點 3 首先接收來自 B 的寫入，然後從 A 寫入。  \n     圖 5-12 並發寫入 Dynamo 風格的資料儲存：沒有明確定義的順序。  如何達成一致性。為了達成一致性，副本應該趨於相同的值。  雖然理想情況下，資料庫應該自動處理複製衝突，但實際上可能需要應用程式開發人員具備一定的資料庫內部知識來避免資料丟失。  本章還將更深入地探討解決衝突的方法。  後寫者贏(丟棄並發的寫入)  為了實現最終收斂，可以使用最後寫入勝利LWW(Last Write Win)方法，即選擇具有最大時間戳的寫入作為最新的，並丟棄具有較早時間戳的寫入。  但是，LWW會以永續性為代價，可能導致部分寫入丟失。\n在某些情況下，例如快取，這可能是可以接受的，但如果資料丟失不可接受，則LWW可能不是最佳選擇。  要安全地在資料庫中使用LWW，應確保每個鍵只寫入一次，並將其視為不可變，以避免對同一個鍵進行並發更新。  happens-before 和並發性  判斷兩個操作是否並發的關鍵在於一個操作是否在另一個操作之前發生。\n當兩個操作互不知道對方時，它們是並發的。  在這種情況下，需要解決潛在的衝突。總結來說，操作的並發性可以分為三種情況：   A 在 B 之前  B 在 A 之前  A 和 B 並發   並發性、時間和相對性\n如果兩個操作 “同時” 發生，似乎應該稱為並發 —— 但事實上，它們在字面時間上重疊與否並不重要。由於分散式系統中的時鐘問題，現實中是很難判斷兩個事件是否是 同時 發生的，這個問題我們將在 第八章 中詳細討論。  為了定義並發性，確切的時間並不重要：如果兩個操作都意識不到對方的存在，就稱這兩個操作 並發，而不管它們實際發生的物理時間。人們有時把這個原理和物理學中的狹義相對論聯絡起來【54】，該理論引入了資訊不能> 比光速更快的思想。因此，如果兩個事件發生的時間差小於光透過它們之間的距離所需要的時間，那麼這兩個事件不可能相互影響。  在計算機系統中，即使光速原則上允許一個操作影響另一個操作，但兩個操作也可能是 並發的。例如，如果網路緩慢或中斷，兩個操作間可能會出現一段時間間隔，但仍然是並發的，因為網路問題阻止一個操作意識到另一個操作的存在。  擷取 happens-before 先後關係  用於確定兩個操作是否為並發的，或者一個在另一個之前。\n該例子中，兩個客戶端同時將商品加入購物車。  這個過程涉及五次寫入操作，每次客戶端嘗試將新商品添加到購物車時，伺服器都會分配新的版本號。\n在這個過程中，不同客戶端的操作可能互相影響，最後伺服器將保留並發值。  簡單來說，該演算法是為了確定操作之間的並發性，並根據操作的順序和版本號來合併購物車內容。  \n     圖 5-13 在同時編輯購物車時捕獲兩個客戶端之間的因果關係。  \n     圖 5-14 圖 5-13 中的因果依賴關係圖。  該演算法的工作原理如下   伺服器為每個鍵維護一個版本號，寫入時遞增版本號，並將新版本號與值一起儲存。  客戶端讀取鍵時，伺服器返回所有未覆蓋值及最新版本號；客戶端需先讀取再寫入。  客戶端寫入鍵時，附帶讀取的版本號，並將之前讀取的所有值合併在一起。  伺服器收到寫入時，覆蓋相同或更低版本號的值，並以更高版本號儲存所有值。  寫入時包含讀取的版本號有助於確定寫入基於的狀態。\n無版本號的寫入與其他寫入並發，不會覆蓋內容，而只會作為隨後讀取的一個值返回。  合併並發寫入的值  當多個客戶端同時進行資料寫入時，如何解決衝突並合併資料。  以購物車為例，作者提出一種將並發值做並集的合併方法。\n然而，若要允許用戶移除購物車中的項目，這種方法可能無法產生正確結果。  為解決這個問題，系統應留下刪除標記（墓碑），以表示某個項目已被移除。\n另外，為簡化合併過程，有一些資料結構（如CRDT）可自動執行合併操作。  版本向量  在圖 5-13 的例子中，僅使用了一個副本。  當有多個副本而無主庫時，我們需要修改算法。\n我們將使用版本向量來捕捉多個副本之間的依賴關係，每個副本都有自己的版本號。  當副本處理寫入時，版本號會增加，並追踪其他副本的版本號。\n這有助於確定覆蓋哪些值以及保留哪些值。  版本向量允許區分覆蓋寫入和並發寫入，並確保從一個副本讀取並寫回到另一個副本是安全的。\n然而，應用程式可能需要合併並發值。\n只要能正確合併，就不會丟失資料。   版本向量和向量時鐘\n版本向量有時也被稱為向量時鐘，即使它們不完全相同。其中的差別很微妙 —— 細節請參閱參考資料【57,60,61】。簡而言之，在比較副本的狀態時，版本向量才是正確的資料結構。  小結  在本章中，我們考察了複製的問題。複製可以用於幾個目的：   高可用性  即使在一臺機器（或多臺機器，或整個資料中心）停機的情況下也能保持系統正常執行  斷開連線的操作  允許應用程式在網路中斷時繼續工作  延遲  將資料放置在地理上距離使用者較近的地方，以便使用者能夠更快地與其互動  可伸縮性  透過在副本上讀，能夠處理比單機更大的讀取量  儘管是一個簡單的目標 - 在幾臺機器上保留相同資料的副本，但複製卻是一個非常棘手的問題。它需要仔細考慮並 發和所有可能出錯的事情，並處理這些故障的後果。至少，我們需要處理不可用的節點和網路中斷（這還不包括更隱蔽的故障，例如由於軟體錯誤導致的靜默資料損壞）。  我們討論了複製的三種主要方法：   單主複製  客戶端將所有寫入操作傳送到單個節點（主庫），該節點將資料更改事件流傳送到其他副本（從庫）。讀取可以在任何副本上執行，但從庫的讀取結果可能是陳舊的。  多主複製  客戶端將每個寫入傳送到幾個主庫節點之一，其中任何一個主庫都可以接受寫入。主庫將資料更改事件流傳送給彼此以及任何從庫節點。  無主複製  客戶端將每個寫入傳送到幾個節點，並從多個節點並行讀取，以檢測和糾正具有陳舊資料的節點。  每種方法都有優點和缺點。單主複製是非常流行的，因為它很容易理解，不需要擔心衝突解決。在出現故障節點、網路中斷和延遲峰值的情況下，多主複製和無主複製可以更加健壯，其代價是難以推理並且僅提供非常弱的一致性保證。  複製可以是同步的，也可以是非同步的，這在發生故障時對系統行為有深遠的影響。儘管在系統執行平穩時非同步複製速度很快，但是要弄清楚在複製延遲增加和伺服器故障時會發生什麼，這一點很重要。如果主庫失敗後你將一個非同步更新的從庫提升為新的主庫，那麼最近提交的資料可能會丟失。  我們研究了一些可能由複製延遲引起的奇怪效應，我們也討論了一些有助於決定應用程式在複製延遲時的行為的一致性模型：   寫後讀一致性  使用者應該總是能看到自己提交的資料。  單調讀  使用者在看到某個時間點的資料後，他們不應該再看到該資料在更早時間點的情況。  一致字首讀  使用者應該看到資料處於一種具有因果意義的狀態：例如，按正確的順序看到一個問題和對應的回答。  最後，我們討論了多主複製和無主複製方法所固有的並發問題：因為他們允許多個寫入並發發生，這可能會導致衝突。我們研究了一個數據庫可以使用的演算法來確定一個操作是否發生在另一個操作之前，或者它們是否並發發生。我們還談到了透過合併並發更新來解決衝突的方法。  在下一章中，我們將繼續考察資料分佈在多臺機器間的另一種不同於 複製 的形式：將大資料集分割成 分割槽。",{"id":279,"path":280,"dir":281,"title":282,"description":7,"keywords":283,"body":7},"content:introduction:getting-started.md","/introduction/getting-started","introduction","Getting Started",[],1700391216492]